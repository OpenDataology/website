<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenDataology – Documentation</title>
    <link>/docs/</link>
    <description>Recent content in Documentation on OpenDataology</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Introduction</title>
      <link>/docs/started/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/started/introduction/</guid>
      <description>
        
        
        &lt;p&gt;The OpenDataology project is dedicated to making deployments of machine learning (ML)
workflows on Kubernetes simple, portable and scalable. Our goal is not to
recreate other services, but to provide a straightforward way to deploy
best-of-breed open-source systems for ML to diverse infrastructures. Anywhere
you are running Kubernetes, you should be able to run OpenDataology.&lt;/p&gt;
&lt;h2 id=&#34;getting-started-with-opendataology&#34;&gt;Getting started with OpenDataology&lt;/h2&gt;
&lt;p&gt;Read the &lt;a href=&#34;/docs/started/architecture/&#34;&gt;architecture overview&lt;/a&gt; for an
introduction to the architecture of OpenDataology and to see how you can use OpenDataology
to manage your ML workflow.&lt;/p&gt;
&lt;p&gt;Follow &lt;a href=&#34;/docs/started/installing-OpenDataology/&#34;&gt;Installing OpenDataology&lt;/a&gt; to set up
your environment and install OpenDataology.&lt;/p&gt;
&lt;p&gt;Watch the following video which provides an introduction to OpenDataology.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/cTZArDgbIWw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;Introduction to OpenDataology&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;what-is-opendataology&#34;&gt;What is OpenDataology?&lt;/h2&gt;
&lt;p&gt;OpenDataology is &lt;em&gt;the machine learning toolkit for Kubernetes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To use OpenDataology, the basic workflow is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and run the OpenDataology deployment binary.&lt;/li&gt;
&lt;li&gt;Customize the resulting configuration files.&lt;/li&gt;
&lt;li&gt;Run the specified script to deploy your containers to your specific
environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can adapt the configuration to choose the platforms and services that you
want to use for each stage of the ML workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;data preparation&lt;/li&gt;
&lt;li&gt;model training,&lt;/li&gt;
&lt;li&gt;prediction serving&lt;/li&gt;
&lt;li&gt;service management&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can choose to deploy your Kubernetes workloads locally, on-premises, or to
a cloud environment.&lt;/p&gt;
&lt;h2 id=&#34;the-opendataology-mission&#34;&gt;The OpenDataology mission&lt;/h2&gt;
&lt;p&gt;Our goal is to make scaling machine learning (ML) models and deploying them to
production as simple as possible, by letting Kubernetes do what it&amp;rsquo;s great at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy, repeatable, portable deployments on a diverse infrastructure
(for example, experimenting on a laptop, then moving to an on-premises
cluster or to the cloud)&lt;/li&gt;
&lt;li&gt;Deploying and managing loosely-coupled microservices&lt;/li&gt;
&lt;li&gt;Scaling based on demand&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because ML practitioners use a diverse set of tools, one of the key goals is to
customize the stack based on user requirements (within reason) and let the
system take care of the &amp;ldquo;boring stuff&amp;rdquo;. While we have started with a narrow set
of technologies, we are working with many different projects to include
additional tooling.&lt;/p&gt;
&lt;p&gt;Ultimately, we want to have a set of simple manifests that give you an easy to
use ML stack &lt;em&gt;anywhere&lt;/em&gt; Kubernetes is already running, and that can self
configure based on the cluster it deploys into.&lt;/p&gt;
&lt;h2 id=&#34;history&#34;&gt;History&lt;/h2&gt;
&lt;p&gt;OpenDataology started as an open sourcing of the way Google ran &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt; internally, based on a pipeline called &lt;a href=&#34;https://www.tensorflow.org/tfx/&#34;&gt;TensorFlow Extended&lt;/a&gt;.
It began as just a simpler way to run TensorFlow jobs on Kubernetes, but has since expanded to be a multi-architecture, multi-cloud framework for running end-to-end machine learning workflows.&lt;/p&gt;
&lt;h2 id=&#34;roadmaps&#34;&gt;Roadmaps&lt;/h2&gt;
&lt;p&gt;To see what&amp;rsquo;s coming up in future versions of OpenDataology, refer to the &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/blob/master/ROADMAP.md&#34;&gt;OpenDataology roadmap&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following components also have roadmaps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/master/ROADMAP.md&#34;&gt;OpenDataology Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfserving/blob/master/ROADMAP.md&#34;&gt;KF Serving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/katib/blob/master/ROADMAP.md&#34;&gt;Katib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/common/blob/master/ROADMAP.md&#34;&gt;Training Operator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;getting-involved&#34;&gt;Getting involved&lt;/h2&gt;
&lt;p&gt;There are many ways to contribute to OpenDataology, and we welcome contributions!&lt;/p&gt;
&lt;p&gt;Read the &lt;a href=&#34;/docs/about/contributing/&#34;&gt;contributor&amp;rsquo;s guide&lt;/a&gt; to get started on the code, and learn about the community on the &lt;a href=&#34;/docs/about/community/&#34;&gt;community page&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Overview</title>
      <link>/docs/distributions/gke/deploy/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/overview/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to deploy OpenDataology and a series of OpenDataology components on GKE (Google Kubernetes Engine).
If you want to use OpenDataology Pipelines only, refer to &lt;a href=&#34;/docs/components/pipelines/installation/overview/&#34;&gt;Installation Options for OpenDataology Pipelines&lt;/a&gt;
for choosing an installation option.&lt;/p&gt;
&lt;h2 id=&#34;deployment-structure&#34;&gt;Deployment Structure&lt;/h2&gt;
&lt;p&gt;As a high level overview, you need to create one Management cluster which allows you to manage Google Cloud resources via &lt;a href=&#34;https://cloud.google.com/config-connector/docs/overview&#34;&gt;Config Connector&lt;/a&gt;. Management cluster can create, manage and delete multiple OpenDataology clusters, while being independent from OpenDataology clusters&amp;rsquo; activities. Below is a simplified view of deployment structure. Note that Management cluster can live in a different Google Cloud project from OpenDataology clusters, admin should assign owner permission to Management cluster&amp;rsquo;s service account. It will be explained in detail during Deployment steps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/gke/full-deployment-structure.png&#34; 
alt=&#34;Full OpenDataology deployment structure&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deployment-steps&#34;&gt;Deployment steps&lt;/h2&gt;
&lt;p&gt;Follow the steps below to set up OpenDataology environment on Google Cloud. Some of these steps are one-time only, for example: OAuth Client can be shared by multiple OpenDataology clusters in the same Google Cloud project.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/project-setup/&#34;&gt;Set up Google Cloud project&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/oauth-setup/&#34;&gt;Set up OAuth Client&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/management-setup/&#34;&gt;Deploy Management Cluster&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli/&#34;&gt;Deploy OpenDataology Cluster&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you encounter any issue during the deployment steps, refer to &lt;a href=&#34;/docs/distributions/gke/troubleshooting-gke/&#34;&gt;Troubleshooting deployments on GKE&lt;/a&gt; to find common issues
and debugging approaches. If this issue is new, file a bug to &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints&#34;&gt;OpenDataology/gcp-blueprints&lt;/a&gt; for GKE related issue, or file a bug to the corresponding component in &lt;a href=&#34;https://github.com/OpenDataology/&#34;&gt;OpenDataology on GitHub&lt;/a&gt; if the issue is component specific.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;p&gt;Once you finish deployment, you will be able to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;manage a running Kubernetes cluster with multiple OpenDataology components installed.&lt;/li&gt;
&lt;li&gt;get a &lt;a href=&#34;https://cloud.google.com/endpoints/docs&#34;&gt;Cloud Endpoint&lt;/a&gt; which is accessible via &lt;a href=&#34;https://cloud.google.com/iap&#34;&gt;IAP (Identity-aware Proxy)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;enable &lt;a href=&#34;/docs/components/multi-tenancy/&#34;&gt;Multi-user feature&lt;/a&gt; for resource and access isolation.&lt;/li&gt;
&lt;li&gt;take advantage of GKE&amp;rsquo;s
&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler&#34;&gt;Cluster Autoscaler&lt;/a&gt;
to automatically resize the number of nodes in a node pool.&lt;/li&gt;
&lt;li&gt;choose GPUs and &lt;a href=&#34;https://cloud.google.com/tpu/&#34;&gt;Cloud TPU&lt;/a&gt; to accelerate your workload.&lt;/li&gt;
&lt;li&gt;use &lt;a href=&#34;https://cloud.google.com/logging/docs/&#34;&gt;Cloud Logging&lt;/a&gt; to help debugging and troubleshooting.&lt;/li&gt;
&lt;li&gt;access to many managed services offered by Google Cloud.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/gke/full-kf-home.png&#34; 
alt=&#34;Full OpenDataology Central Dashboard&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Repeat &lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli/&#34;&gt;Deploy OpenDataology Cluster&lt;/a&gt; if you want to deploy multiple clusters.&lt;/li&gt;
&lt;li&gt;Run a full ML workflow on OpenDataology, using the &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/e42d9d2609369b96973c821dca11fe5b2565e705/samples/contrib/OpenDataology-e2e-mnist/OpenDataology-e2e-mnist.ipynb&#34;&gt;end-to-end MNIST tutorial&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Overview</title>
      <link>/docs/external-add-ons/serving/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/serving/overview/</guid>
      <description>
        
        
        &lt;p&gt;OpenDataology supports two model serving systems that allow multi-framework model
serving: &lt;em&gt;KFServing&lt;/em&gt; and &lt;em&gt;Seldon Core&lt;/em&gt;. Alternatively, you can use a
standalone model serving system. This page gives an overview of the options, so
that you can choose the framework that best supports your model serving
requirements.&lt;/p&gt;
&lt;h2 id=&#34;multi-framework-serving-with-kfserving-or-seldon-core&#34;&gt;Multi-framework serving with KFServing or Seldon Core&lt;/h2&gt;
&lt;p&gt;KFServing and Seldon Core are both open source systems that allow
multi-framework model serving. The following table compares
KFServing and Seldon Core. A check mark (&lt;strong&gt;✓&lt;/strong&gt;) indicates that the system
(KFServing or Seldon Core) supports the feature specified in that row.&lt;/p&gt;
&lt;div class=&#34;table-responsive&#34;&gt;
  &lt;table class=&#34;table table-bordered&#34;&gt;
    &lt;thead class=&#34;thead-light&#34;&gt;
      &lt;tr&gt;
        &lt;th&gt;Feature&lt;/th&gt;
        &lt;th&gt;Sub-feature&lt;/th&gt;
        &lt;th&gt;KFServing&lt;/th&gt;
        &lt;th&gt;Seldon Core&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Framework&lt;/td&gt;
        &lt;td&gt;TensorFlow&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/tensorflow&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;XGBoost&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/xgboost&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/servers/xgboost.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;scikit-learn&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/sklearn/v2&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/servers/sklearn.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;NVIDIA Triton Inference Server&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/triton&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/examples/nvidia_mnist.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;ONNX&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1alpha2/onnx&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;PyTorch&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/torchserve&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Graph&lt;/td&gt;
        &lt;td&gt;Transformers&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/blob/master/docs/samples/v1beta1/transformer/torchserve_image_transformer&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/examples/transformer_spam_model.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;Combiners&lt;/td&gt;
        &lt;td&gt;Roadmap&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/examples/openvino_ensemble.html&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;Routers including &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-armed_bandit&#34;&gt;MAB&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;Roadmap&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/analytics/routers.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Analytics&lt;/td&gt;
        &lt;td&gt;Explanations&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/explanation/alibi&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Scaling&lt;/td&gt;
        &lt;td&gt;Knative&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/autoscaling&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;GPU AutoScaling&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/autoscaling&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;HPA&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/blob/master/test/benchmark/README.md&#34;&gt;HPA vs KPA&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/graph/scaling.html#autoscaling-seldon-deployments&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Custom&lt;/td&gt;
        &lt;td&gt;Container&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1alpha2/custom&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;Language Wrappers&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/python/index.html&#34;&gt;Python&lt;/a&gt;, &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/java/README.html&#34;&gt;Java&lt;/a&gt;, &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/R/README.html&#34;&gt;R&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;Multi-Container&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/graph/inference-graph.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Rollout&lt;/td&gt;
        &lt;td&gt;Canary&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://github.com/OpenDataology/kfserving/tree/master/docs/samples/v1beta1/rollout&#34;&gt;sample&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt; &lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/examples/istio_canary.html&#34;&gt;docs&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;Shadow&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Istio&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt;&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;&amp;check;&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KFServing and Seldon Core share some technical features, including
explainability (using &lt;a href=&#34;https://github.com/SeldonIO/alibi&#34;&gt;Seldon Alibi
Explain&lt;/a&gt;) and payload logging, as well
as other areas.&lt;/li&gt;
&lt;li&gt;A commercial product,
&lt;a href=&#34;https://www.seldon.io/tech/products/deploy/&#34;&gt;Seldon Deploy&lt;/a&gt;, supports both
KFServing and Seldon in production.&lt;/li&gt;
&lt;li&gt;KFServing is part of the OpenDataology project ecosystem. Seldon Core is an
external project supported within OpenDataology.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KFServing:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/kfserving/&#34;&gt;OpenDataology documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfserving&#34;&gt;GitHub repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/about/community/&#34;&gt;OpenDataology Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Seldon Core
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/external-add-ons/serving/seldon/&#34;&gt;OpenDataology documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/&#34;&gt;Seldon Core documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/SeldonIO/seldon-core&#34;&gt;GitHub repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.seldon.io/projects/seldon-core/en/latest/developer/community.html&#34;&gt;Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tensorflow-serving&#34;&gt;TensorFlow Serving&lt;/h2&gt;
&lt;p&gt;For TensorFlow models you can use TensorFlow Serving for
&lt;a href=&#34;/docs/external-add-ons/serving/tfserving_new&#34;&gt;real-time prediction&lt;/a&gt;.
However, if you plan to use multiple frameworks, you should consider KFServing
or Seldon Core as described above.&lt;/p&gt;
&lt;h2 id=&#34;nvidia-triton-inference-server&#34;&gt;NVIDIA Triton Inference Server&lt;/h2&gt;
&lt;p&gt;NVIDIA Triton Inference Server is a REST and GRPC service for deep-learning
inferencing of TensorRT, TensorFlow, Pytorch, ONNX and Caffe2 models. The server is
optimized to deploy machine learning algorithms on both GPUs and
CPUs at scale. Triton Inference Server was previously known as TensorRT Inference Server.&lt;/p&gt;
&lt;p&gt;You can use NVIDIA Triton Inference Server as a
&lt;a href=&#34;/docs/external-add-ons/serving/tritoninferenceserver&#34;&gt;standalone system&lt;/a&gt;,
but you should consider KFServing as described above. KFServing includes support
for NVIDIA Triton Inference Server.&lt;/p&gt;
&lt;h2 id=&#34;bentoml&#34;&gt;BentoML&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://bentoml.org&#34;&gt;BentoML&lt;/a&gt; is an open-source platform for high-performance ML model
serving. It makes building production API endpoint for your ML model easy and supports
all major machine learning training frameworks, including Tensorflow, Keras, PyTorch,
XGBoost, scikit-learn and etc.&lt;/p&gt;
&lt;p&gt;BentoML comes with a high-performance API model server with adaptive micro-batching
support, which achieves the advantage of batch processing in online serving. It also
provides model management and model deployment functionality, giving ML teams an
end-to-end model serving workflow, with DevOps best practices baked in.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/external-add-ons/serving/bentoml&#34;&gt;BentoML guide for OpenDataology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bentoml/BentoML&#34;&gt;BentoML GitHub repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bentoml.org&#34;&gt;BentoML documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bentoml.org/en/latest/quickstart.html&#34;&gt;Quick start guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://join.slack.com/t/bentoml/shared_invite/enQtNjcyMTY3MjE4NTgzLTU3ZDc1MWM5MzQxMWQxMzJiNTc1MTJmMzYzMTYwMjQ0OGEwNDFmZDkzYWQxNzgxYWNhNjAxZjk4MzI4OGY1Yjg&#34;&gt;Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: KServe</title>
      <link>/docs/external-add-ons/kserve/kserve/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/kserve/kserve/</guid>
      <description>
        
        
        &lt;img src=&#34;/docs/external-add-ons/kserve/pics/kserve.png&#34; alt=&#34;KServe&#34; width=&#34;640px&#34;&gt;
&lt;p&gt;KServe enables serverless inferencing on Kubernetes and provides performant, high abstraction interfaces for common machine learning (ML) frameworks like TensorFlow, XGBoost, scikit-learn, PyTorch, and ONNX to solve production model serving use cases.&lt;/p&gt;
&lt;h3 id=&#34;kfserving-is-now-kservehttpskservegithubiowebsite07blogarticles2021-09-27-kfserving-transition&#34;&gt;&lt;a href=&#34;https://kserve.github.io/website/0.7/blog/articles/2021-09-27-kfserving-transition/&#34;&gt;KFServing is now KServe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The KFServing GitHub repository has been transferred to an independent KServe GitHub organization under the stewardship of the OpenDataology Serving Working Group leads.&lt;/p&gt;
&lt;h3 id=&#34;kserve-docshttpskservegithubiowebsite07&#34;&gt;&lt;a href=&#34;https://kserve.github.io/website/0.7/&#34;&gt;KServe Docs&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The majority of KServe docs will be available on the new docs website and it is recommended to refer to the docs on the KServe website rather than this website&lt;/p&gt;
&lt;p&gt;You can use KServe to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Provide a Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Custom Resource Definition&lt;/a&gt; for serving ML models on arbitrary frameworks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encapsulate the complexity of autoscaling, networking, health checking, and server configuration to bring cutting edge serving features like GPU autoscaling, scale to zero, and canary rollouts to your ML deployments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable a simple, pluggable, and complete story for your production ML inference server by providing prediction, pre-processing, post-processing and explainability out of the box.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our strong community contributions help KServe to grow. We have a Technical Steering Committee driven by Bloomberg, IBM Cloud, Seldon, Amazon Web Services (AWS) and NVIDIA.  Please browse the &lt;a href=&#34;https://github.com/KServe/KServe&#34;&gt;KServe GitHub repo&lt;/a&gt; and &lt;a href=&#34;https://github.com/KServe/KServe/issues&#34;&gt;raise issues&lt;/a&gt; to give us feedback!&lt;/p&gt;
&lt;h2 id=&#34;install-with-opendataology&#34;&gt;Install with OpenDataology&lt;/h2&gt;
&lt;p&gt;KServe works with OpenDataology 1.5. Kustomize installation files are &lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/master/contrib/kserve&#34;&gt;located in the manifests repo&lt;/a&gt;.
Check the examples running KServe on Istio/Dex in the &lt;a href=&#34;https://github.com/KServe/KServe/tree/master/docs/samples/istio-dex&#34;&gt;&lt;code&gt;KServe/KServe&lt;/code&gt;&lt;/a&gt; repository. For installation on major cloud providers with OpenDataology, follow their installation docs.&lt;/p&gt;
&lt;p&gt;OpenDataology 1.5 includes KServe v0.7 which promoted the core InferenceService API from v1alpha2 to v1beta1 stable and added ModelMesh component to the release. Additionally, LFAI Trusted AI Projects on AI Fairness, AI Explainability and Adversarial Robustness have been integrated with KServe, and we have made KServe available on OpenShift as well. To know more, please read the &lt;a href=&#34;https://kserve.github.io/website/blog/articles/2021-10-11-KServe-0.7-release/&#34;&gt;release blog&lt;/a&gt; and follow the &lt;a href=&#34;https://github.com/KServe/KServe/releases/tag/v0.7.0&#34;&gt;release notes&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;standalone-kserve&#34;&gt;Standalone KServe&lt;/h2&gt;
&lt;h3 id=&#34;quickstart-installhttpskservegithubiowebsite07get_started&#34;&gt;&lt;a href=&#34;https://kserve.github.io/website/0.7/get_started/&#34;&gt;Quickstart Install&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;KServe Quickstart Environments are for experimentation use only. For production installation, see our &lt;a href=&#34;https://kserve.github.io/website/0.7/admin/serverless/&#34;&gt;Administrator&amp;rsquo;s Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;learn-more&#34;&gt;Learn more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=lj_X2ND2BBI&#34;&gt;OpenDataology 101: What is KFserving?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/16oqz6dhY5BR0u74pi9mDThU97Np__AFb/view&#34;&gt;KFServing 101 slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kccncna19.sched.com/event/UaZo/introducing-kfserving-serverless-model-serving-on-kubernetes-ellis-bigelow-google-dan-sun-bloomberg&#34;&gt;Kubecon Introducing KFServing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sE_A54T2n6k&#34;&gt;Serving Machine Learning Models at Scale Using KServe - Yuzhui Liu, Bloomberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0YmM_h7PvpI&#34;&gt;KServe (OpenDataology KFServing) Live Coding Session&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0H-HvK8zIUI&#34;&gt;TFiR: Let’s Talk About IBM’s ModelMesh, KServe And Other Open Source AI/ML Technologies&lt;/a&gt; | Animesh Singh |&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=la3Y0lXuKRM&#34;&gt;KubeCon 2021: Serving Machine Learning Models at Scale Using KServe&lt;/a&gt; | Animesh Singh |&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kserve-key-links&#34;&gt;&lt;strong&gt;KServe Key Links&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kserve.github.io/website/&#34;&gt;&lt;u&gt;Website&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kserve/kserve/&#34;&gt;&lt;u&gt;Github&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://OpenDataology.slack.com/join/shared_invite/zt-n73pfj05-l206djXlXk5qdQKs4o1Zkg#/&#34;&gt;&lt;u&gt;Slack(#OpenDataology-kfserving)&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Migration</title>
      <link>/docs/external-add-ons/kserve/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/kserve/migration/</guid>
      <description>
        
        
        &lt;p&gt;The migration job will by default delete the leftover KFServing installation after migrating the InferenceServices from
&lt;code&gt;serving.OpenDataology.org&lt;/code&gt; to &lt;code&gt;serving.kserve.io&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;migrating-from-opendataology-based-kfserving&#34;&gt;Migrating from OpenDataology-based KFServing&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install OpenDataology-based KServe 0.7 using the &lt;a href=&#34;https://github.com/kserve/kserve/blob/master/install/v0.7.0/kserve_OpenDataology.yaml&#34;&gt;install YAML&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This will not affect existing services yet.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/kserve/kserve/master/install/v0.7.0/kserve_OpenDataology.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the &lt;a href=&#34;https://github.com/kserve/kserve/blob/master/hack/kserve_migration/kserve_migration_job_OpenDataology.yaml&#34;&gt;KServe Migration YAML&lt;/a&gt; for OpenDataology-based installations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This will begin the migration. Any errors here may affect your existing services.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you do not want to delete the KFServing resources after migrating, download and edit the env &lt;code&gt;REMOVE_KFSERVING&lt;/code&gt;
in the YAML before applying it&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/kserve/kserve/master/hack/kserve_migration/kserve_migration_job_OpenDataology.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Clean up the migration resources&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete ClusterRoleBinding cluster-migration-rolebinding
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete ClusterRole cluster-migration-role
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete ServiceAccount cluster-migration-svcaccount -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the models web app to use the new InferenceService API group &lt;code&gt;serving.kserve.io&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change the deployment image to &lt;code&gt;kserve/models-web-app:v0.7.0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit deployment kfserving-models-web-app -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the cluster role to be able to access the new InferenceService API group &lt;code&gt;serving.kserve.io&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Edit the &lt;code&gt;apiGroups&lt;/code&gt; from &lt;code&gt;serving.OpenDataology.org&lt;/code&gt; to &lt;code&gt;serving.kserve.io&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This is a temporary fix until the next OpenDataology release includes these changes&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit clusterrole kfserving-models-web-app-cluster-role
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Models UI</title>
      <link>/docs/external-add-ons/kserve/webapp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/kserve/webapp/</guid>
      <description>
        
        
        &lt;p&gt;The Models web app is responsible for allowing the user to manipulate the Model Servers in their OpenDataology cluster. To achieve this it provides a user friendly way to handle the lifecycle of &lt;code&gt;InferenceService&lt;/code&gt; CRs.&lt;/p&gt;
&lt;p&gt;The web app currently works with &lt;code&gt;v1beta1&lt;/code&gt; versions of &lt;code&gt;InferenceService&lt;/code&gt; objects.&lt;/p&gt;
&lt;p&gt;The web app is also exposing information from the underlying Knative resources,
like Conditions from the Knative Configurations, Route and Revisions as well as
live logs from the Model server pod.&lt;/p&gt;
&lt;h2 id=&#34;installation-and-access&#34;&gt;Installation and Access&lt;/h2&gt;
&lt;p&gt;Refer &lt;a href=&#34;https://github.com/kserve/models-web-app/#development&#34;&gt;https://github.com/kserve/models-web-app/#development&lt;/a&gt; for installation&lt;/p&gt;
&lt;p&gt;The web app includes the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;Deployment&lt;/code&gt; for running the backend server, and serving the static frontend files&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;Service&lt;/code&gt; for configuring the incluster network traffic&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;ServiceAccount&lt;/code&gt; and &lt;code&gt;ClusterRole{Binding}&lt;/code&gt; to give the necessary
permissions to the web app&amp;rsquo;s Pod&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;VirtualService&lt;/code&gt; for exposing the app via the cluster&amp;rsquo;s Istio Ingress
Gateway&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;opendataology&#34;&gt;OpenDataology&lt;/h3&gt;
&lt;p&gt;The web app is included as a part of the OpenDataology &lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/v1.5-branch/contrib/kserve/models-web-app&#34;&gt;1.5
release&lt;/a&gt; manifests.
It is &lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/v1.5-branch/apps/centraldashboard/upstream/base/configmap.yaml#L30&#34;&gt;exposed&lt;/a&gt; via the
Central Dashboard, out of the box.&lt;/p&gt;
&lt;h3 id=&#34;standalone&#34;&gt;Standalone&lt;/h3&gt;
&lt;p&gt;In this case all the resources of the web app will be installed in the
&lt;code&gt;kserve&lt;/code&gt; namespace. Users can access the web app either via the
&lt;code&gt;knative-ingress-gateway.knative-serving&lt;/code&gt; Istio Ingress Gateway or by
port-forwarding the backend.&lt;/p&gt;
&lt;h4 id=&#34;port-forwarding&#34;&gt;Port forwarding&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# set the following ENV vars in the app&amp;#39;s Deployment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit -n kserve deployments.apps kserve-models-web-app
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# APP_PREFIX: /&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# APP_DISABLE_AUTH: &amp;#34;True&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# APP_SECURE_COOKIES: &amp;#34;False&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# expose the app under localhost:5000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl port-forward -n kserve svc/kserve-models-web-app 5000:80
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;authorization&#34;&gt;Authorization&lt;/h2&gt;
&lt;h3 id=&#34;subjectaccessreviews&#34;&gt;SubjectAccessReviews&lt;/h3&gt;
&lt;p&gt;The web app has a mechanism for performing authentication and authorization
checks, to ensure that user actions are compliant with the cluster&amp;rsquo;s RBAC,
which is only enabled in the &lt;em&gt;OpenDataology&lt;/em&gt; manifests of the app. This mechanism
can be toggled by leveraging the &lt;code&gt;APP_DISABLE_AUTH: &amp;quot;True&amp;quot; | &amp;quot;False&amp;quot;&lt;/code&gt; ENV Var.&lt;/p&gt;
&lt;p&gt;This mechanism is only enabled in the &lt;em&gt;OpenDataology&lt;/em&gt; manifests since in a OpenDataology
installation all requests that end up in the web app&amp;rsquo;s Pod will also contain a custom
header that denotes the user. In a OpenDataology installation there&amp;rsquo;s an authentication
component in front of the cluster that ensures only logged in users can
access the cluster&amp;rsquo;s services. In the standalone mode such a
component might not always be deployed.&lt;/p&gt;
&lt;p&gt;The web app will be using the value from this custom header to extract the name
of the &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/authentication/&#34;&gt;K8s
user&lt;/a&gt;
that made the request. Then it will create a
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/authorization/#determine-whether-a-request-is-allowed-or-denied&#34;&gt;SubjectAccessReview&lt;/a&gt;
to check if the user has permissions to perform the specific action, for
example deleting an InferenceService in a namespace.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Tip&lt;/h4&gt;

    If you are port-forwarding the app via &lt;strong&gt;kubectl port-forward&lt;/strong&gt; then you will
need to set &lt;strong&gt;APP_DISABLE_AUTH=&amp;ldquo;True&amp;rdquo;&lt;/strong&gt; in the web app&amp;rsquo;s Deployment. When
port-forwarding the authentication header will not be set, which will result in the
web app raising &lt;strong&gt;401&lt;/strong&gt; errors.

&lt;/div&gt;

&lt;h3 id=&#34;namespace-selection&#34;&gt;Namespace selection&lt;/h3&gt;
&lt;p&gt;Both in &lt;em&gt;standalone&lt;/em&gt; and in &lt;em&gt;OpenDataology&lt;/em&gt; setups the user needs to be able to
select a Namespace in order to interact with the InferenceServices in it.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;standalone&lt;/em&gt; mode the web app will show a dropdown that will show all the
namespaces to the user and allow them to select any of them. The backend will
make a LIST request to the API Server to get all the namespaces. In this case
the only authorization check that takes place is in the K8s API Server that
ensures the &lt;a href=&#34;https://github.com/kserve/models-web-app/blob/release-0.7/config/base/rbac.yaml&#34;&gt;web app Pod&amp;rsquo;s
ServiceAccount&lt;/a&gt;
has permissions to list namespaces.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;OpenDataology&lt;/em&gt; mode the &lt;a href=&#34;/docs/components/central-dash/overview/&#34;&gt;Central
Dashboard&lt;/a&gt; is responsible for the
Namespace selection. Once the user selects a namespace then the Dashboard will
inform the iframed Models web app about the newly selected namespace. The
Models web app itself won&amp;rsquo;t expose a dropdown namespace selector in this mode.&lt;/p&gt;
&lt;h2 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h2&gt;
&lt;p&gt;Currently users can do the following workflows via this web app:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See a list of the existing InferenceService CRs in a Namespace&lt;/li&gt;
&lt;li&gt;Create a new InferenceService by providing a YAML&lt;/li&gt;
&lt;li&gt;Inspect an InferenceService
&lt;ul&gt;
&lt;li&gt;View the live status of the InferenceService&lt;/li&gt;
&lt;li&gt;Inspect the K8s Conditions of the underlying Knative resources&lt;/li&gt;
&lt;li&gt;View the logs of the created Model server Pod, for that InferenceService&lt;/li&gt;
&lt;li&gt;Inspect the YAML contents as they are stored in the K8s API Server&lt;/li&gt;
&lt;li&gt;View some basic metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;listing&#34;&gt;Listing&lt;/h3&gt;
&lt;p&gt;The main page of the app provides a list of all the InferenceServices that are
deployed in the selected Namespace. The frontend periodically polls the backend
for the latest state of InferenceServices.&lt;/p&gt;
&lt;img src=&#34;/docs/external-add-ons/kserve/pics/webapp-list.png&#34; alt=&#34;Models web app main page&#34;&gt;
&lt;h3 id=&#34;creating&#34;&gt;Creating&lt;/h3&gt;
&lt;p&gt;The page for creating a new InferenceService. The user can paste the YAML
object of the InferenceService they wish to create.&lt;/p&gt;
&lt;p&gt;Note that the backend will override the provided &lt;code&gt;.metadata.namespace&lt;/code&gt; field of
the submitted object, to prevent users from trying to create InferenceServices
in other namespaces.&lt;/p&gt;
&lt;img src=&#34;/docs/external-add-ons/kserve/pics/webapp-new.png&#34; alt=&#34;Models web app create page&#34;&gt;
&lt;h3 id=&#34;deleting&#34;&gt;Deleting&lt;/h3&gt;
&lt;p&gt;Users can delete an existing InferenceService by clicking on the
&lt;i class=&#34;fas fa-trash&#34;&gt;&lt;/i&gt; icon next to an InferenceService, in the main page
that lists all the namespaced resources.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    The backend is using &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#foreground-cascading-deletion&#34;&gt;foreground cascading
deletion&lt;/a&gt;
when deleting an InferenceService. This means that the InferenceService CR will
be deleted from the K8s API Server only once the underlying resources have been
deleted.

&lt;/div&gt;

&lt;h3 id=&#34;inspecting&#34;&gt;Inspecting&lt;/h3&gt;
&lt;p&gt;Users can click on the name of an InferenceService, from the main page, and
view a more detailed summary of the CR&amp;rsquo;s state. In this page users can inspect:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The overview of the InferenceService&amp;rsquo;s status (OVERVIEW)&lt;/li&gt;
&lt;li&gt;A user friendly representation of the CR&amp;rsquo;s spec (DETAILS)&lt;/li&gt;
&lt;li&gt;Metrics from the underlying resources (METRICS)&lt;/li&gt;
&lt;li&gt;Logs from the created Pods (LOGS)&lt;/li&gt;
&lt;li&gt;The YAML file as is in the K8s API Server (YAML)&lt;/li&gt;
&lt;/ol&gt;
&lt;img src=&#34;/docs/external-add-ons/kserve/pics/webapp-overview.png&#34; alt=&#34;Models web app overview page&#34;&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    &lt;p&gt;To gather the logs the backend will:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Filter all the pods that have a &lt;code&gt;serving.knative.dev/revision&lt;/code&gt; label&lt;/li&gt;
&lt;li&gt;Get the logs from the &lt;code&gt;kserve-container&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;/div&gt;

&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;As mentioned in the above sections the web app allows users to inspect the
metrics from the InferenceService. This tab will &lt;strong&gt;not&lt;/strong&gt; be enable by default.
In order to expose it the users will need to install Grafana and Prometheus.&lt;/p&gt;
&lt;p&gt;Currently the frontend is expecting to find a Grafana exposed in the &lt;code&gt;/grafana&lt;/code&gt;
prefix. This Grafana instance will need to have specific dashboards in order
for the app to embed them in iframes. We are working on making this more
generic to allow people to expose their own graphs.&lt;/p&gt;
&lt;p&gt;You can install Grafana and Prometheus, for the web app to consume, by
installing&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the &lt;code&gt;monitoring-core.yaml&lt;/code&gt; and
&lt;code&gt;monitoring-metrics-prometheus.yaml&lt;/code&gt; files from the &lt;a href=&#34;https://github.com/knative/serving/releases/tag/v0.18.0&#34;&gt;Knative 0.18
release&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;the following yaml files for exposing Grafana outside the cluster, by
allowing &lt;strong&gt;anonymous access&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&#34;nav nav-tabs&#34; id=&#34;grafana-installation-yamls&#34; role=&#34;tablist&#34;&gt;&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link active&#34; href=&#34;#grafana-installation-yamls-0&#34; role=&#34;tab&#34; aria-controls=&#34;grafana-installation-yamls-0&#34; aria-selected=&#34;true&#34;&gt;ConfigMap&lt;/a&gt;&lt;/li&gt;
	  
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#grafana-installation-yamls-1&#34; role=&#34;tab&#34; aria-controls=&#34;grafana-installation-yamls-1&#34;&gt;VirtualService&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#grafana-installation-yamls-2&#34; role=&#34;tab&#34; aria-controls=&#34;grafana-installation-yamls-2&#34;&gt;AuthorizationPolicy&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;div class=&#34;tab-content&#34; id=&#34;grafana-installation-yamls&#34;&gt;&lt;div id=&#34;grafana-installation-yamls-0&#34; class=&#34;tab-pane show active&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;grafana-installation-yamls-0&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ConfigMap&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;grafana-custom-config&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;knative-monitoring&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;serving.knative.dev/release&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v0.11.0&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;custom.ini&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    # You can customize Grafana via changing the context of this field.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    [auth.anonymous]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    # enable anonymous access
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    enabled = true
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    [security]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    allow_embedding = true
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    [server]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    root_url = &amp;#34;/grafana&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;    serve_from_sub_path = true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;grafana-installation-yamls-1&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;grafana-installation-yamls-1&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;VirtualService&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;grafana&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;knative-monitoring&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;gateways&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;OpenDataology/OpenDataology-gateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hosts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;http&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;match&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;uri&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;prefix&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/grafana/&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;route&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;destination&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;host&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;grafana.knative-monitoring.svc.cluster.local&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;port&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;number&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;30802&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;grafana-installation-yamls-2&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;grafana-installation-yamls-2&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;security.istio.io/v1beta1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;AuthorizationPolicy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;models-web-app&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;action&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ALLOW&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;rules&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;source&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;principals&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;selector&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;matchLabels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomize.component&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kserve-models-web-app&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;app.kubernetes.io/component&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kserve-models-web-app&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    If you installed the app in the &lt;em&gt;standalone&lt;/em&gt; mode then you will need to instead
use the &lt;strong&gt;knative-serving/knative-ingress-gateway&lt;/strong&gt; Ingress Gateway and deploy
the AuthorizationPolicy in the &lt;strong&gt;kserve&lt;/strong&gt; namespace instead.

&lt;/div&gt;

&lt;p&gt;After applying these YAMLs, based on your installation mode, and ensuring the
Grafana instance is exposed under &lt;code&gt;/grafana&lt;/code&gt; the web app will show the
&lt;code&gt;METRICS&lt;/code&gt; tab.&lt;/p&gt;
&lt;img src=&#34;/docs/external-add-ons/kserve/pics/webapp-metrics.png&#34; alt=&#34;Models web app metrics page&#34;&gt;
&lt;h2 id=&#34;configurations&#34;&gt;Configurations&lt;/h2&gt;
&lt;p&gt;The following is a list of ENV var that can configure different aspects of the
application.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ENV Var&lt;/th&gt;
&lt;th&gt;Default value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;APP_PREFIX&lt;/td&gt;
&lt;td&gt;&amp;ldquo;/models&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Controls the app&amp;rsquo;s prefix, by setting the &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base&#34;&gt;base-url&lt;/a&gt; element&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;APP_DISABLE_AUTH&lt;/td&gt;
&lt;td&gt;&amp;ldquo;False&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Controls whether the app should use SubjectAccessReviews to ensure the user is authorized to perform an action&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;APP_SECURE_COOKIES&lt;/td&gt;
&lt;td&gt;&amp;ldquo;True&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Controls whether the app should use &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#Secure&#34;&gt;Secure&lt;/a&gt; CSRF cookies. By default the app expects to be exposed with https&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CSRF_SAMESITE&lt;/td&gt;
&lt;td&gt;&amp;ldquo;Strict&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Controls the &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#SameSite&#34;&gt;SameSite value&lt;/a&gt; of the CSRF cookie&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;USERID_HEADER&lt;/td&gt;
&lt;td&gt;&amp;ldquo;OpenDataology-userid&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Header in each request that will contain the username of the logged in user&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;USERID_PREFIX&lt;/td&gt;
&lt;td&gt;&amp;quot;&amp;quot;&lt;/td&gt;
&lt;td&gt;Prefix to remove from the &lt;code&gt;USERID_HEADER&lt;/code&gt; value to extract the logged in user name&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Set up Project</title>
      <link>/docs/distributions/gke/deploy/project-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/project-setup/</guid>
      <description>
        
        
        &lt;p&gt;In order to create GKE cluster and deploy OpenDataology on it, you need to set up a Google Cloud project
and enable necessary APIs for the deployment.&lt;/p&gt;
&lt;h2 id=&#34;set-up-project-and-api-scopes&#34;&gt;Set up project and API scopes&lt;/h2&gt;
&lt;p&gt;Follow these steps to set up your Google Cloud project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select or create a project on the
&lt;a href=&#34;https://console.cloud.google.com/cloud-resource-manager&#34;&gt;Google Cloud Console&lt;/a&gt;. If you plan to use different Google Cloud projects for &lt;strong&gt;Management Cluster&lt;/strong&gt; and &lt;strong&gt;OpenDataology Clusters&lt;/strong&gt;: create &lt;strong&gt;one Management project&lt;/strong&gt; for Management Cluster, and create &lt;strong&gt;one or more OpenDataology projects&lt;/strong&gt; for OpenDataology Clusters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure that you have the
&lt;a href=&#34;https://cloud.google.com/iam/docs/understanding-roles#primitive_role_definitions&#34;&gt;Owner role&lt;/a&gt;
for the project in Cloud IAM (Identity and Access Management).
The deployment process creates various service accounts with
appropriate roles in order to enable seamless integration with
Google Cloud services. This process requires that you have the
owner role for the project in order to deploy OpenDataology.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure that billing is enabled for your project. Refer to
&lt;a href=&#34;https://cloud.google.com/billing/docs/how-to/modify-project&#34;&gt;Enable billing for a project&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open following pages on the Google Cloud Console and ensure that the
specified APIs are enabled for all projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/compute.googleapis.com&#34;&gt;Compute Engine API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/container.googleapis.com&#34;&gt;Kubernetes Engine API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/iam.googleapis.com&#34;&gt;Identity and Access Management (IAM) API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/api/servicemanagement.googleapis.com&#34;&gt;Service Management API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.developers.google.com/apis/library/cloudresourcemanager.googleapis.com&#34;&gt;Cloud Resource Manager API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.developers.google.com/apis/library/ml.googleapis.com&#34;&gt;AI Platform Training &amp;amp; Prediction API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/iap.googleapis.com&#34;&gt;Cloud Identity-Aware Proxy API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/cloudbuild.googleapis.com&#34;&gt;Cloud Build API&lt;/a&gt; (It&amp;rsquo;s required if you plan to use &lt;a href=&#34;https://www.OpenDataology.org/docs/external-add-ons/fairing/&#34;&gt;Fairing&lt;/a&gt; in your OpenDataology cluster)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/sqladmin.googleapis.com&#34;&gt;Cloud SQL Admin API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/krmapihosting.googleapis.com&#34;&gt;Config Controller (KRM API Hosting API)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/endpoints.googleapis.com&#34;&gt;Google Cloud Endpoints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://console.cloud.google.com/apis/library/servicecontrol.googleapis.com&#34;&gt;Service Control API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also enable these APIs by running the following command in Cloud Shell:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud services &lt;span style=&#34;color:#204a87&#34;&gt;enable&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  compute.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  container.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  iam.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  servicemanagement.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  cloudresourcemanager.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  ml.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  iap.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  sqladmin.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  meshconfig.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  krmapihosting.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  servicecontrol.googleapis.com &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  endpoints.googleapis.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Cloud Build API is optional, you need it if using Fairing.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# gcloud services enable cloudbuild.googleapis.com&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you are using the
&lt;a href=&#34;https://cloud.google.com/free/docs/gcp-free-tier&#34;&gt;Google Cloud Free Program&lt;/a&gt; or the
12-month trial period with $300 credit, note that the free tier does not offer enough
resources for default full OpenDataology installation. You need to
&lt;a href=&#34;https://cloud.google.com/free/docs/gcp-free-tier#how-to-upgrade&#34;&gt;upgrade to a paid account&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more information, see the following issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/website/issues/1065&#34;&gt;OpenDataology/website #1065&lt;/a&gt;
reports the problem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/issues/3936&#34;&gt;OpenDataology/OpenDataology #3936&lt;/a&gt;
requests a OpenDataology configuration to work with a free trial project.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read the Google Cloud &lt;a href=&#34;https://cloud.google.com/compute/quotas&#34;&gt;Resource quotas&lt;/a&gt;
to understand quotas on resource usage that Compute Engine enforces, and
to learn how to check and increase your quotas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initialize your project to prepare it for Anthos Service Mesh installation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;PROJECT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;YOUR_PROJECT_ID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl --request POST &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --header &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Authorization: Bearer &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;gcloud auth print-access-token&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --data &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://meshconfig.googleapis.com/v1alpha1/projects/&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PROJECT_ID&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:initialize
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Refer to &lt;a href=&#34;https://cloud.google.com/service-mesh/docs/archive/1.4/docs/gke-install-new-cluster#setting_credentials_and_permissions&#34;&gt;Anthos Service Mesh documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;If you encounter a &lt;code&gt;Workload Identity Pool does not exist&lt;/code&gt; error, refer to the following issue:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OpenDataology/website/issues/2121&#34;&gt;OpenDataology/website #2121&lt;/a&gt;
describes that creating and then removing a temporary Kubernetes cluster may
be needed for projects that haven&amp;rsquo;t had a cluster set up beforehand.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You do not need a running GKE cluster. The deployment process creates a
cluster for you.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/oauth-setup&#34;&gt;Set up an OAuth credential&lt;/a&gt; to use
&lt;a href=&#34;https://cloud.google.com/iap/docs/&#34;&gt;Cloud Identity-Aware Proxy (Cloud IAP)&lt;/a&gt;.
Cloud IAP is recommended for production deployments or deployments with access
to sensitive data.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/management-setup&#34;&gt;Set up Management Cluster&lt;/a&gt; to deploy and manage OpenDataology clusters.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli&#34;&gt;Deploy OpenDataology&lt;/a&gt; using kubectl, kustomize and kpt.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Create or access an IBM Cloud Kubernetes cluster</title>
      <link>/docs/distributions/ibm/create-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/create-cluster/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to create a Kubernetes cluster with IBM Cloud Kubernetes Service.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ibm.com/cloud/kubernetes-service&#34;&gt;IBM Cloud Kubernetes Service&lt;/a&gt; provides powerful tools and services to help deploy highly available containerized apps in Kubernetes clusters and to automate, isolate, secure, manage, and monitor your workloads across zones or regions.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;IBMid&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To get started, first go to &lt;a href=&#34;https://ibm.biz/Bdqgck&#34;&gt;IBM Cloud&lt;/a&gt; to create your &lt;code&gt;IBMid&lt;/code&gt; if you do not have one.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installing the IBM Cloud CLI&lt;/p&gt;
&lt;p&gt;Follow the instructions in this &lt;a href=&#34;https://cloud.ibm.com/docs/cli?topic=cli-getting-started#overview&#34;&gt;Getting started with the IBM Cloud CLI&lt;/a&gt; guide to install the IBM Cloud CLI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installing the IBM Cloud Kubernetes Service plug-in with the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud plugin install container-service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Refer to this &lt;a href=&#34;https://cloud.ibm.com/docs/cli?topic=containers-kubernetes-service-cli&#34;&gt;link&lt;/a&gt; for more info on IBM Cloud Kubernetes Service CLI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Authenticating with IBM Cloud&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud login
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Use your registered email and password for your &lt;code&gt;IBMid&lt;/code&gt; to log in to IBM Cloud.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;connecting-to-an-existing-cluster&#34;&gt;Connecting to an existing cluster&lt;/h2&gt;
&lt;p&gt;If you have an existing cluster, use it to install OpenDataology as far as it meets the minimum system requirement.&lt;/p&gt;
&lt;p&gt;Get the Kubeconfig file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster config --cluster &lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_NAME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From here on, go to &lt;a href=&#34;/docs/ibm/deploy/install-OpenDataology-on-iks&#34;&gt;Install OpenDataology on IKS&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2 id=&#34;create-and-setup-a-new-cluster&#34;&gt;Create and setup a new cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Use a &lt;code&gt;classic&lt;/code&gt; provider if you want to try out OpenDataology.&lt;/li&gt;
&lt;li&gt;Use a &lt;code&gt;vpc-gen2&lt;/code&gt; provider if you are familiar with Cloud networking and want to deploy OpenDataology on a secure environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A &lt;code&gt;classic&lt;/code&gt; provider exposes each cluster node to the public internet and therefore has
a relatively simpler networking setup. Services exposed using Kubernetes &lt;code&gt;NodePort&lt;/code&gt; need to be secured using
authentication mechanism.&lt;/p&gt;
&lt;p&gt;To create a cluster with &lt;code&gt;vpc-gen2&lt;/code&gt; provider, follow the
&lt;a href=&#34;/docs/ibm/create-cluster-vpc&#34;&gt;Create a cluster on IKS with a &lt;code&gt;vpc-gen2&lt;/code&gt; provider&lt;/a&gt;
guide.&lt;/p&gt;
&lt;p&gt;The next section will explain how to create and set up a new IBM Cloud Kubernetes Service (IKS)&lt;/p&gt;
&lt;h3 id=&#34;setting-environment-variables&#34;&gt;Setting environment variables&lt;/h3&gt;
&lt;p&gt;Choose the region and the worker node provider for your cluster, and set the environment variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;1.21
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_ZONE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;dal13
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_PROVIDER&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; specifies the Kubernetes version for the cluster. Run &lt;code&gt;ibmcloud ks versions&lt;/code&gt; to see the supported
Kubernetes versions. If this environment variable is not set, the cluster will be created with the default version set
by IBM Cloud Kubernetes Service. Refer to
&lt;a href=&#34;https://www.OpenDataology.org/docs/started/k8s/overview/#minimum-system-requirements&#34;&gt;Minimum system requirements&lt;/a&gt;
and choose a Kubernetes version compatible with the OpenDataology release to be deployed.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CLUSTER_ZONE&lt;/code&gt; identifies the regions or location where cluster will be created. Run &lt;code&gt;ibmcloud ks locations&lt;/code&gt; to
list supported IBM Cloud Kubernetes Service locations. For example, choose &lt;code&gt;dal13&lt;/code&gt; to create your cluster in the
Dallas (US) data center.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WORKER_NODE_PROVIDER&lt;/code&gt; specifies the kind of IBM Cloud infrastructure on which the Kubernetes worker nodes will be
created. The &lt;code&gt;classic&lt;/code&gt; type supports worker nodes with GPUs. There are other worker nodes providers including
&lt;code&gt;vpc-classic&lt;/code&gt; and &lt;code&gt;vpc-gen2&lt;/code&gt; where zone names and worker flavors will be different. Run
&lt;code&gt;ibmcloud ks zones --provider classic&lt;/code&gt; to list zone names for &lt;code&gt;classic&lt;/code&gt; provider and set the &lt;code&gt;CLUSTER_ZONE&lt;/code&gt;
accordingly.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CLUSTER_NAME&lt;/code&gt; must be lowercase and unique among any other Kubernetes
clusters in the specified &lt;code&gt;${CLUSTER_ZONE}&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: Refer to &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-clusters&#34;&gt;Creating clusters&lt;/a&gt; in the IBM
Cloud documentation for additional information on how to set up other providers and zones in your cluster.&lt;/p&gt;
&lt;h3 id=&#34;choosing-a-worker-node-flavor&#34;&gt;Choosing a worker node flavor&lt;/h3&gt;
&lt;p&gt;The worker node flavor name varies from zones and providers. Run
&lt;code&gt;ibmcloud ks flavors --zone ${CLUSTER_ZONE} --provider ${WORKER_NODE_PROVIDER}&lt;/code&gt; to list available flavors.&lt;/p&gt;
&lt;p&gt;For example, the following are some worker node flavors supported in the &lt;code&gt;dal13&lt;/code&gt; zone with a &lt;code&gt;classic&lt;/code&gt; node provider.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks flavors --zone dal13 --provider classic
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;For more information about these flavors, see &amp;#39;https://ibm.biz/flavors&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name                      Cores   Memory   Network Speed   OS             Server Type   Storage      Secondary Storage   Provider
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b2c.16x64                 16      64GB     1000Mbps        UBUNTU_16_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b2c.32x128                32      128GB    1000Mbps        UBUNTU_16_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b2c.4x16                  4       16GB     1000Mbps        UBUNTU_16_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b2c.56x242                56      242GB    1000Mbps        UBUNTU_16_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b2c.8x32                  8       32GB     1000Mbps        UBUNTU_16_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b3c.16x64                 16      64GB     1000Mbps        UBUNTU_18_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b3c.32x128                32      128GB    1000Mbps        UBUNTU_18_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b3c.4x16                  4       16GB     1000Mbps        UBUNTU_18_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b3c.56x242                56      242GB    1000Mbps        UBUNTU_18_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b3c.8x32                  8       32GB     1000Mbps        UBUNTU_18_64   virtual       25GB         100GB               classic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Choose a flavor that will work for your applications. For the purpose of the OpenDataology deployment, the recommended
configuration for a cluster is at least 8 vCPU cores with 16GB memory. Hence you can either choose the &lt;code&gt;b3c.8x32&lt;/code&gt; flavor
to create a one-worker-node cluster or choose the &lt;code&gt;b3c.4x16&lt;/code&gt; flavor to create a two-worker-node cluster. Keep in mind
that you can always scale the cluster by adding more worker nodes should your application scales up.&lt;/p&gt;
&lt;p&gt;Now, set the environment variable with the worker node flavor of your choice:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_FLAVOR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;b3c.4x16
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;creating-an-ibm-cloud-kubernetes-cluster&#34;&gt;Creating an IBM Cloud Kubernetes cluster&lt;/h3&gt;
&lt;p&gt;Run with the following command to create a cluster:&lt;/p&gt;
&lt;p&gt;Replace the &lt;code&gt;workers&lt;/code&gt; parameter above with the desired number of worker nodes.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re starting in a fresh account with no public and private VLANs, they are created automatically for you
when creating a Kubernetes cluster with worker nodes provider &lt;code&gt;classic&lt;/code&gt; for the first time. If you already have VLANs
configured in your account, retrieve them via &lt;code&gt;ibmcloud ks vlans --zone ${CLUSTER_ZONE}&lt;/code&gt; and include the public and
private VLAN ids (set in the &lt;code&gt;PUBLIC_VLAN_ID&lt;/code&gt; and &lt;code&gt;PRIVATE_VLAN_ID&lt;/code&gt; environment variables) in the command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster create &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_PROVIDER&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --name&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_NAME&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --zone&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_ZONE&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --flavor &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_FLAVOR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --workers&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --private-vlan &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PRIVATE_VLAN_ID&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --public-vlan &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PUBLIC_VLAN_ID&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wait until the cluster is deployed and configured. It can take a while for the cluster to be ready. Run with following
command to periodically check the state of your cluster. Your cluster is ready when the state is &lt;code&gt;normal&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks clusters --provider &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_PROVIDER&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt;grep &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt;awk &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{print &amp;#34;Name:&amp;#34;$1&amp;#34;\tState:&amp;#34;$3}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;verifying-the-cluster&#34;&gt;Verifying the cluster&lt;/h3&gt;
&lt;p&gt;To use the created cluster, switch the Kubernetes context to point to the cluster with the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster config --cluster &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Make sure all worker nodes are up with the command below&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get nodes
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and make sure all the nodes are in &lt;code&gt;Ready&lt;/code&gt; state.&lt;/p&gt;
&lt;h3 id=&#34;delete-the-cluster&#34;&gt;Delete the cluster&lt;/h3&gt;
&lt;p&gt;Delete the cluster including it&amp;rsquo;s storage:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster rm --force-delete-storage -c &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Set up OAuth client</title>
      <link>/docs/distributions/gke/deploy/oauth-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/oauth-setup/</guid>
      <description>
        
        
        &lt;h2 id=&#34;set-up-oauth-consent-screen-and-client-credential&#34;&gt;Set up OAuth Consent Screen and Client Credential&lt;/h2&gt;
&lt;p&gt;If you want to use
&lt;a href=&#34;https://cloud.google.com/iap/docs/&#34;&gt;Cloud Identity-Aware Proxy (Cloud IAP)&lt;/a&gt;
when deploying OpenDataology on Google Cloud,
then you must follow these instructions to create an OAuth client for use
with OpenDataology.&lt;/p&gt;
&lt;p&gt;Cloud IAP is recommended for production deployments or deployments with access
to sensitive data.&lt;/p&gt;
&lt;p&gt;Follow the steps below to create an OAuth client ID that identifies Cloud IAP
when requesting access to a user&amp;rsquo;s email account. OpenDataology uses the email
address to verify the user&amp;rsquo;s identity.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Set up your OAuth &lt;a href=&#34;https://console.cloud.google.com/apis/credentials/consent&#34;&gt;consent screen&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;strong&gt;Application name&lt;/strong&gt; box, enter the name of your application.
The example below uses the name &amp;ldquo;OpenDataology&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Under &lt;strong&gt;Support email&lt;/strong&gt;, select the email address that you want to display
as a public contact. You must use either your email address or a Google
Group that you own.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you see &lt;strong&gt;Authorized domains&lt;/strong&gt;, enter&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;project&amp;gt;.cloud.goog
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;where &amp;lt;project&amp;gt; is your Google Cloud project ID.&lt;/li&gt;
&lt;li&gt;If you are using your own domain, such as &lt;strong&gt;acme.com&lt;/strong&gt;, you should add
that as well&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Authorized domains&lt;/strong&gt; option appears only for certain project
configurations. If you don&amp;rsquo;t see the option, then there&amp;rsquo;s nothing you
need to set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Save&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here&amp;rsquo;s an example of the completed form:&lt;br&gt;
&lt;img src=&#34;/docs/images/consent-screen.png&#34; 
alt=&#34;OAuth consent screen&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the &lt;a href=&#34;https://console.cloud.google.com/apis/credentials&#34;&gt;credentials screen&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;strong&gt;Create credentials&lt;/strong&gt;, and then click &lt;strong&gt;OAuth client ID&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Under &lt;strong&gt;Application type&lt;/strong&gt;, select &lt;strong&gt;Web application&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;In the &lt;strong&gt;Name&lt;/strong&gt; box enter any name for your OAuth client ID. This is &lt;em&gt;not&lt;/em&gt;
the name of your application nor the name of your OpenDataology deployment. It&amp;rsquo;s
just a way to help you identify the OAuth client ID.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Create&lt;/strong&gt;. A dialog box appears, like the one below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/new-oauth.png&#34; 
alt=&#34;OAuth consent screen&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy the &lt;strong&gt;client ID&lt;/strong&gt; shown in the dialog box, because you need the client
ID in the next step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the &lt;strong&gt;Create credentials&lt;/strong&gt; screen, find your newly created OAuth
credential and click the pencil icon to edit it:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/oauth-edit.png&#34; 
alt=&#34;OAuth consent screen&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;strong&gt;Authorized redirect URIs&lt;/strong&gt; box, enter the following (if it&amp;rsquo;s not
already present in the list of authorized redirect URIs):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://iap.googleapis.com/v1/oauth/clientIds/&amp;lt;CLIENT_ID&amp;gt;:handleRedirect
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;CLIENT_ID&amp;gt;&lt;/code&gt; is the OAuth client ID that you copied from the dialog box in
step four. It looks like &lt;code&gt;XXX.apps.googleusercontent.com&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Note that the URI is not dependent on the OpenDataology deployment or endpoint.
Multiple OpenDataology deployments can share the same OAuth client without the
need to modify the redirect URIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Press &lt;strong&gt;Enter/Return&lt;/strong&gt; to add the URI. Check that the URI now appears as
a confirmed item under &lt;strong&gt;Authorized redirect URIs&lt;/strong&gt;. (The URI should no longer be
editable.)&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example of the completed form:
&lt;img src=&#34;/docs/images/oauth-credential.png&#34; 
alt=&#34;OAuth credentials&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Save&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make note that you can find your OAuth client credentials in the credentials
section of the Google Cloud Console. You need to retrieve the &lt;strong&gt;client ID&lt;/strong&gt; and
&lt;strong&gt;client secret&lt;/strong&gt; later when you&amp;rsquo;re ready to enable Cloud IAP.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/management-setup/&#34;&gt;Set up your management cluster&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/iam/docs/granting-changing-revoking-access#granting-console&#34;&gt;Grant your users the IAP-secured Web App User IAM role&lt;/a&gt; so they can access the OpenDataology console through IAP.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Create or access an IBM Cloud Kubernetes cluster on a VPC</title>
      <link>/docs/distributions/ibm/create-cluster-vpc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/create-cluster-vpc/</guid>
      <description>
        
        
        &lt;h2 id=&#34;create-and-setup-a-new-cluster&#34;&gt;Create and setup a new cluster&lt;/h2&gt;
&lt;p&gt;Follow these steps to create and setup a new IBM Cloud Kubernetes Service(IKS) cluster on &lt;code&gt;vpc-gen2&lt;/code&gt; provider.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;vpc-gen2&lt;/code&gt; cluster does not expose each node to the public internet directly and thus has more secure
and more complex network setup. It is recommended setup for secured production use cases of OpenDataology.&lt;/p&gt;
&lt;h3 id=&#34;setting-environment-variables&#34;&gt;Setting environment variables&lt;/h3&gt;
&lt;p&gt;Choose the region and the worker node provider for your cluster, and set the environment variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNERTES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;1.18
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_ZONE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;us-south-3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;OpenDataology-vpc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;KUBERNETES_VERSION&lt;/code&gt;: Run &lt;code&gt;ibmcloud ks versions&lt;/code&gt; to see the supported Kubernetes versions. Refer to
&lt;a href=&#34;https://www.OpenDataology.org/docs/started/k8s/overview/#minimum-system-requirements&#34;&gt;Supported version matrix&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CLUSTER_ZONE&lt;/code&gt;: Run &lt;code&gt;ibmcloud ks locations&lt;/code&gt; to list supported zones. For example, choose &lt;code&gt;us-south-3&lt;/code&gt; to create your
cluster in the Dallas (US) data center.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CLUSTER_NAME&lt;/code&gt; must be lowercase and unique among any other Kubernetes
clusters in the specified &lt;code&gt;${CLUSTER_ZONE}&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: Refer to &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-clusters&#34;&gt;Creating clusters&lt;/a&gt; in the IBM
Cloud documentation for additional information on how to set up other providers and zones in your cluster.&lt;/p&gt;
&lt;h3 id=&#34;choosing-a-worker-node-flavor&#34;&gt;Choosing a worker node flavor&lt;/h3&gt;
&lt;p&gt;The worker nodes flavor name varies from zones and providers. Run
&lt;code&gt;ibmcloud ks flavors --zone ${CLUSTER_ZONE} --provider vpc-gen2&lt;/code&gt; to list available flavors.&lt;/p&gt;
&lt;p&gt;Below are some examples of flavors supported in the &lt;code&gt;us-south-3&lt;/code&gt; zone with &lt;code&gt;vpc-gen2&lt;/code&gt; node provider:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks flavors --zone us-south-3 --provider vpc-gen2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;For more information about these flavors, see &amp;#39;https://ibm.biz/flavors&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name         Cores   Memory   Network Speed   OS             Server Type   Storage   Secondary Storage   Provider   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bx2.16x64    16      64GB     16Gbps          UBUNTU_18_64   virtual       100GB     0B                  vpc-gen2   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bx2.2x8†     2       8GB      4Gbps           UBUNTU_18_64   virtual       100GB     0B                  vpc-gen2   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bx2.32x128   32      128GB    16Gbps          UBUNTU_18_64   virtual       100GB     0B                  vpc-gen2   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bx2.48x192   48      192GB    16Gbps          UBUNTU_18_64   virtual       100GB     0B                  vpc-gen2   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bx2.4x16     4       16GB     8Gbps           UBUNTU_18_64   virtual       100GB     0B                  vpc-gen2   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The recommended configuration for a cluster is at least 8 vCPU cores with 16GB memory. Hence, we recommend
&lt;code&gt;bx2.4x16&lt;/code&gt; flavor to create a two-worker-node cluster. Keep in mind that you can always scale the cluster
by adding more worker nodes should your application scales up.&lt;/p&gt;
&lt;p&gt;Now set the environment variable with the flavor you choose.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_FLAVOR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;bx2.4x16
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-an-ibm-cloud-kubernetes-cluster-for-vpc-gen2-infrastructure&#34;&gt;Create an IBM Cloud Kubernetes cluster for &lt;code&gt;vpc-gen2&lt;/code&gt; infrastructure&lt;/h2&gt;
&lt;p&gt;Creating a &lt;code&gt;vpc-gen2&lt;/code&gt; based cluster needs a VPC, a subnet and a public gateway attached to it. Fortunately, this is a one
time setup. Future &lt;code&gt;vpc-gen2&lt;/code&gt; clusters can reuse the same VPC/subnet(with attached public-gateway).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Begin with installing a &lt;code&gt;vpc-infrastructure&lt;/code&gt; plugin:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud plugin install vpc-infrastructure
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Refer to this &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial&#34;&gt;link&lt;/a&gt;, for more information.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Target &lt;code&gt;vpc-gen 2&lt;/code&gt; to access gen 2 VPC resources:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is target --gen &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that the target is correctly set up:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is target
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Target Generation: 2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create or use an existing VPC:&lt;/p&gt;
&lt;p&gt;a) Use an existing VPC:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is vpcs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Listing vpcs for generation 2 compute in all resource groups and region ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                                          Name                Status      Classic access   Default network ACL                                    Default security group                                 Resource group   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r006-hidden-68cc-4d40-xxxx-4319fa3gxxxx   my-vpc1              available   false            husker-sloping-bee-resize                              blimp-hasty-unaware-overflow                           OpenDataology   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the above list contains the VPC that can be used to deploy your cluster - make a note of its ID.&lt;/p&gt;
&lt;p&gt;b) To create a new VPC, proceed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is vpc-create my-vpc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Creating vpc my-vpc in resource group OpenDataology under account IBM as ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                                             r006-hidden-68cc-4d40-xxxx-4319fa3fxxxx   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name                                           my-vpc   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Save the ID in a variable &lt;code&gt;VPC_ID&lt;/code&gt; as follows, so that we can use it later.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;VPC_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;r006-hidden-68cc-4d40-xxxx-4319fa3fxxxx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create or use an existing subnet:&lt;/p&gt;
&lt;p&gt;a) To use an existing subnet:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is subnets
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Listing subnets for generation 2 compute in all resource groups and region ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                                          Name                      Status      Subnet CIDR       Addresses     ACL                                                    Public Gateway                             VPC                 Zone         Resource group   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;0737-27299d09-1d95-4a9d-a491-a6949axxxxxx   my-subnet                 available   10.240.128.0/18   16373/16384   husker-sloping-bee-resize                              my-gateway                                 my-vpc              us-south-3   OpenDataology   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the above list contains the subnet corresponding to your VPC, that can be used to deploy your cluster - make sure
you note it&amp;rsquo;s ID.&lt;/p&gt;
&lt;p&gt;b) To create a new subnet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List address prefixes and note the CIDR block corresponding to a Zone;
in the below example, for Zone: &lt;code&gt;us-south-3&lt;/code&gt; the CIDR block is : &lt;code&gt;10.240.128.0/18&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is vpc-address-prefixes &lt;span style=&#34;color:#000&#34;&gt;$VPC_ID&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Listing address prefixes of vpc r006-hidden-68cc-4d40-xxxx-4319fa3fxxxx under account IBM as user new@user-email.com...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                                          Name                                CIDR block        Zone         Has subnets   Is default   Created   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r006-xxxxxxxx-4002-46d2-8a4f-f69e7ba3xxxx   rising-rectified-much-brew          10.240.0.0/18     us-south-1   false         true         2021-03-05T14:58:39+05:30   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r006-xxxxxxxx-dca9-4321-bb6c-960c4424xxxx   retrial-reversal-pelican-cavalier   10.240.64.0/18    us-south-2   false         true         2021-03-05T14:58:39+05:30   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r006-xxxxxxxx-7352-4a46-bfb1-fcbac6cbxxxx   subfloor-certainly-herbal-ajar      10.240.128.0/18   us-south-3   false         true         2021-03-05T14:58:39+05:30  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Now create a subnet as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is subnet-create my-subnet &lt;span style=&#34;color:#000&#34;&gt;$VPC_ID&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_ZONE&lt;/span&gt; --ipv4-cidr-block &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10.240.128.0/18&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Creating subnet my-subnet in resource group OpenDataology under account IBM as user new@user-email.com...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                  0737-27299d09-1d95-4a9d-a491-a6949axxxxxx   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name                my-subnet
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Make sure you export the subnet IDs follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;SUBNET_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;0737-27299d09-1d95-4a9d-a491-a6949axxxxxx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;code&gt;vpc-gen2&lt;/code&gt; based Kubernetes cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster create vpc-gen2 &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--name &lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_NAME&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--zone &lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_ZONE&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--version &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--flavor &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKER_NODE_FLAVOR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--vpc-id &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;VPC_ID&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--subnet-id &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;SUBNET_ID&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--workers &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Attach a public gateway&lt;/p&gt;
&lt;p&gt;This step is mandatory for OpenDataology deployment to succeed, because pods need public internet access to download images.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, check if your cluster is already assigned a public gateway:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is pubgws
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Listing public gateways for generation 2 compute in all resource groups and region ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                                          Name                                       Status      Floating IP      VPC                 Zone         Resource group   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r006-xxxxxxxx-5731-4ffe-bc51-1d9e5fxxxxxx   my-gateway                                 available   xxx.xxx.xxx.xxx       my-vpc              us-south-3   default   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the above run, the gateway is already attached for the vpc: &lt;code&gt;my-vpc&lt;/code&gt;. In case no gateway is attached, proceed with
the rest of the setup.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Next, attach a public gateway by running the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is public-gateway-create my-gateway &lt;span style=&#34;color:#000&#34;&gt;$VPC_ID&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;$CLUSTER_ZONE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID: r006-xxxxxxxx-5731-4ffe-bc51-1d9e5fxxxxxx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Save the above generated gateway ID as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;GATEWAY_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;r006-xxxxxxxx-5731-4ffe-bc51-1d9e5fxxxxxx&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Finally, attach the public gateway to the subnet:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud is subnet-update &lt;span style=&#34;color:#000&#34;&gt;$SUBNET_ID&lt;/span&gt; --public-gateway-id &lt;span style=&#34;color:#000&#34;&gt;$GATEWAY_ID&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Updating subnet 0737-27299d09-1d95-4a9d-a491-a6949axxxxxx under account IBM as user new@user-email.com...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ID                  0737-27299d09-1d95-4a9d-a491-a6949axxxxxx   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name                my-subnet   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;verifying-the-cluster&#34;&gt;Verifying the cluster&lt;/h3&gt;
&lt;p&gt;To use the created cluster, switch the Kubernetes context to point to the cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster config --cluster &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Make sure all worker nodes are up with the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get nodes
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and verify that all the nodes are in &lt;code&gt;Ready&lt;/code&gt; state.&lt;/p&gt;
&lt;h3 id=&#34;delete-the-cluster&#34;&gt;Delete the cluster&lt;/h3&gt;
&lt;p&gt;Delete the cluster including it&amp;rsquo;s storage:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster rm --force-delete-storage -c &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Deploy Management cluster</title>
      <link>/docs/distributions/gke/deploy/management-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/management-setup/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to setup a management cluster which you will use to deploy one or more instances of OpenDataology.&lt;/p&gt;
&lt;p&gt;The management cluster is used to run &lt;a href=&#34;https://cloud.google.com/config-connector/docs/overview&#34;&gt;Cloud Config Connector&lt;/a&gt;. Cloud Config Connector is a Kubernetes addon that allows you to manage Google Cloud resources through Kubernetes.&lt;/p&gt;
&lt;p&gt;While the management cluster can be deployed in the same project as your OpenDataology cluster, typically you will want to deploy
it in a separate project used for administering one or more OpenDataology instances, because it will run with escalated permissions to create Google Cloud resources in the managed projects.&lt;/p&gt;
&lt;p&gt;Optionally, the cluster can be configured with &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs&#34;&gt;Anthos Config Management&lt;/a&gt;
to manage Google Cloud infrastructure using GitOps.&lt;/p&gt;
&lt;h2 id=&#34;deployment-steps&#34;&gt;Deployment steps&lt;/h2&gt;
&lt;h3 id=&#34;install-the-required-tools&#34;&gt;Install the required tools&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/sdk/docs/components&#34;&gt;gcloud components&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud components install kubectl kustomize kpt anthoscli beta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud components update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# If the output said the Cloud SDK component manager is disabled for installation, copy the command from output and run it.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can install specific version of kubectl by following instruction (Example: &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/&#34;&gt;Install kubectl on Linux&lt;/a&gt;). Latest patch version of kubectl from &lt;code&gt;v1.17&lt;/code&gt; to &lt;code&gt;v1.19&lt;/code&gt; works well too.&lt;/p&gt;
&lt;p&gt;Note: Starting from OpenDataology 1.4, it requires &lt;code&gt;kpt v1.0.0-beta.6&lt;/code&gt; or above to operate in &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; repository. gcloud hasn&amp;rsquo;t caught up with this kpt version yet, &lt;a href=&#34;https://kpt.dev/installation/&#34;&gt;install kpt&lt;/a&gt; separately from &lt;a href=&#34;https://github.com/GoogleContainerTools/kpt/tags&#34;&gt;https://github.com/GoogleContainerTools/kpt/tags&lt;/a&gt; for now. Note that kpt requires docker to be installed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fetch-opendataologygcp-blueprints-package&#34;&gt;Fetch OpenDataology/gcp-blueprints package&lt;/h3&gt;
&lt;p&gt;The management cluster manifests live in GitHub repository &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints&#34;&gt;OpenDataology/gcp-blueprints&lt;/a&gt;, use the following commands to pull OpenDataology manifests:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone the GitHub repository and check out the v1.5.1 tag:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/OpenDataology/gcp-blueprints.git 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout tags/v1.5.1 -b v1.5.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Alternatively, you can get the package by using &lt;code&gt;kpt&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Check out OpenDataology v1.5.1 blueprints&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt pkg get https://github.com/OpenDataology/gcp-blueprints.git@v1.5.1 gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;code&gt;gcp-blueprints/management&lt;/code&gt; directory for Management cluster configurations.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; management
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Tip&lt;/h4&gt;

    To continuously manage the management cluster, you are recommended to check
the management configuration directory into source control. For example, &lt;code&gt;MGMT_DIR=~/gcp-blueprints/management/&lt;/code&gt;.

&lt;/div&gt;

&lt;h3 id=&#34;configure-environment-variables&#34;&gt;Configure Environment Variables&lt;/h3&gt;
&lt;p&gt;Fill in environment variables in &lt;code&gt;gcp-blueprints/management/env.sh&lt;/code&gt; as followed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;the project where you deploy your management cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;name of your management cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;LOCATION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;location of your management cluster, use either us-central1 or us-east1&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; env.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This guide assumes the following convention:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;${MGMT_PROJECT}&lt;/code&gt; environment variable contains the Google Cloud project
ID where management cluster is deployed to.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;${MGMT_NAME}&lt;/code&gt; is the cluster name of your management cluster and the prefix for other Google Cloud resources created in the deployment process. Management cluster
should be a different cluster from your OpenDataology cluster.&lt;/p&gt;
&lt;p&gt;Note, &lt;code&gt;${MGMT_NAME}&lt;/code&gt; should&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start with a lowercase letter&lt;/li&gt;
&lt;li&gt;only contain lowercase letters, numbers and &lt;code&gt;-&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;end with a number or a letter&lt;/li&gt;
&lt;li&gt;contain no more than 18 characters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;${LOCATION}&lt;/code&gt; environment variable contains the location of your management cluster.
you can choose between regional or zonal, see &lt;a href=&#34;https://cloud.google.com/compute/docs/regions-zones#available&#34;&gt;Available regions and zones&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configure-kpt-setter-values&#34;&gt;Configure kpt setter values&lt;/h3&gt;
&lt;p&gt;Use kpt to &lt;a href=&#34;https://catalog.kpt.dev/apply-setters/v0.2/&#34;&gt;set values&lt;/a&gt; for the name, project, and location of your management cluster. Run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash kpt-set.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you can find out which setters exist in a package and what their
current values are by running the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt fn &lt;span style=&#34;color:#204a87&#34;&gt;eval&lt;/span&gt; -i list-setters:v0.1 ./manifests
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;prerequisite-for-config-controller&#34;&gt;Prerequisite for Config Controller&lt;/h3&gt;
&lt;p&gt;In order to deploy Google Cloud Services like Kubernetes resources, we need to create a management cluster with Config Controller installed. Follow &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/how-to/config-controller-setup#before_you_begin&#34;&gt;Before you begin&lt;/a&gt; to create default network if not existed. Make sure to use &lt;code&gt;${MGMT_PROJECT}&lt;/code&gt; for PROJECT_ID.&lt;/p&gt;
&lt;h3 id=&#34;deploy-management-cluster&#34;&gt;Deploy Management Cluster&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Deploy the management cluster by applying cluster resources:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make create-cluster
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a kubectl &lt;strong&gt;context&lt;/strong&gt; for the management cluster, it will be named &lt;code&gt;${MGMT_NAME}&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make create-context
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Grant permission to Config Controller service account:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make grant-owner-permission
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Config Controller has created a default service account, this step grants owner permission to this service account in order to
allow Config Controller to manage Google Cloud resources. Refer to &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/how-to/config-controller-setup#set_up&#34;&gt;Config Controller setup&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;understanding-the-deployment-process&#34;&gt;Understanding the deployment process&lt;/h2&gt;
&lt;p&gt;This section gives you more details about the configuration and
deployment process, so that you can customize your management cluster if necessary.&lt;/p&gt;
&lt;h3 id=&#34;config-controller&#34;&gt;Config Controller&lt;/h3&gt;
&lt;p&gt;Management cluster is a tool for managing Google Cloud services like KRM, for example: GKE container cluster, MySQL database, etc.
And you can use one Managment cluster for multiple OpenDataology clusters, across multiple Google Cloud projects.
This capability is offered by &lt;a href=&#34;https://cloud.google.com/config-connector/docs/how-to/getting-started&#34;&gt;Config Connector&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Starting with OpenDataology 1.5, we leveraged the managed version of Config Connector, which is called &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview&#34;&gt;Config Controller&lt;/a&gt;.
Therefore, The Management cluster is the Config Controller cluster deployed using &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/how-to/config-controller-setup&#34;&gt;Config Controller setup&lt;/a&gt; process.
Note that you can create only one Management cluster within a Google Cloud project, and you usually need just one Management cluster.&lt;/p&gt;
&lt;h3 id=&#34;management-cluster-layout&#34;&gt;Management cluster layout&lt;/h3&gt;
&lt;p&gt;Inside the Config Controller, we manange Google Cloud resources in namespace mode. That means one namespace is responsible to manage Google Cloud resources deployed to the Google Cloud project with the same name. Your management cluster contains following namespaces:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;config-control&lt;/li&gt;
&lt;li&gt;namespace with the same name as your OpenDataology clusters&amp;rsquo; Google Cloud project name&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;config-control&lt;/code&gt; is the default namespace which is installed while creating Management cluster, you have granted the default service account (like &lt;code&gt;service-&amp;lt;management-project-id&amp;gt;@gcp-sa-yakima.iam.gserviceaccount.com&lt;/code&gt;)
within this project to manage Config Connector. It is the prerequisite for managing resources in other Google Cloud projects.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;namespace with the same name as your OpenDataology clusters&#39; Google Cloud project name&lt;/code&gt; is the resource pool for OpenDataology cluster&amp;rsquo;s Google Cloud project.
For each OpenDataology Google Cloud project, you will have service account with pattern &lt;code&gt;kcc-&amp;lt;kf-project-name&amp;gt;@&amp;lt;management-project-name&amp;gt;.iam.gserviceaccount.com&lt;/code&gt; in &lt;code&gt;config-control&lt;/code&gt; namespace, and it needs to have owner permission to &lt;code&gt;${KF_PROJECT}&lt;/code&gt;, you will perform this step during &lt;a href=&#34;/docs/gke/deploy/deploy-cli/&#34;&gt;Deploy OpenDataology cluster&lt;/a&gt;. After setup, your Google Cloud resources in OpenDataology cluster project will be deployed to the namespace with name &lt;code&gt;${KF_PROJECT}&lt;/code&gt; in the management cluster.&lt;/p&gt;
&lt;p&gt;Your management cluster directory contains the following file:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Makefile&lt;/strong&gt; is a file that defines rules to automate deployment process. You can refer to &lt;a href=&#34;https://www.gnu.org/software/make/manual/make.html#Introduction&#34;&gt;GNU make documentation&lt;/a&gt; for more introduction. The Makefile we provide is designed to be user maintainable. You are encouraged to read, edit and maintain it to suit your own deployment customization needs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;debug&#34;&gt;Debug&lt;/h3&gt;
&lt;p&gt;If you encounter issue creating Google Cloud resources using Config Controller. You can list resources in the &lt;code&gt;${KF_PROJECT}&lt;/code&gt; namespace of management cluster to learn about the detail.
Learn more with &lt;a href=&#34;https://cloud.google.com/config-connector/docs/how-to/monitoring-your-resources&#34;&gt;Monitoring your resources&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl --context&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; get all -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# If you want to check the service account creation status&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl --context&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; get IAMServiceAccount -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl --context&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; get IAMServiceAccount &amp;lt;service-account-name&amp;gt; -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -oyaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;faqs&#34;&gt;FAQs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Where is &lt;code&gt;kfctl&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kfctl&lt;/code&gt; is no longer being used to apply resources for Google Cloud, because required functionalities are now supported by generic tools including &lt;a href=&#34;https://www.gnu.org/software/make/&#34;&gt;Make&lt;/a&gt;, &lt;a href=&#34;https://kustomize.io&#34;&gt;Kustomize&lt;/a&gt;, &lt;a href=&#34;https://googlecontainertools.github.io/kpt/&#34;&gt;kpt&lt;/a&gt;, and &lt;a href=&#34;https://cloud.google.com/config-connector/docs/overview&#34;&gt;Cloud Config Connector&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why do we use an extra management cluster to manage Google Cloud resources?&lt;/p&gt;
&lt;p&gt;The management cluster is very lightweight cluster that runs &lt;a href=&#34;https://cloud.google.com/config-connector/docs/overview&#34;&gt;Cloud Config Connector&lt;/a&gt;. Cloud Config Connector makes it easier to configure Google Cloud resources using YAML and Kustomize.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a more detailed explanation of the drastic changes happened in OpenDataology v1.1 on Google Cloud, read &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/issues/123&#34;&gt;OpenDataology/gcp-blueprints #123&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli&#34;&gt;Deploy OpenDataology&lt;/a&gt; using kubectl, kustomize and kpt.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology</title>
      <link>/docs/distributions/azure/deploy/install-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/azure/deploy/install-kubeflow/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to use the kfctl binary to
deploy OpenDataology on Azure.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install and configure the &lt;a href=&#34;https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest&#34;&gt;Azure Command Line Interface (Az)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Log in with &lt;code&gt;az login&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Install Docker
&lt;ul&gt;
&lt;li&gt;For Windows and WSL: &lt;a href=&#34;https://docs.docker.com/docker-for-windows/wsl/&#34;&gt;Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For other OS: &lt;a href=&#34;https://docs.docker.com/docker-hub/&#34;&gt;Docker Desktop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You do not need to have an existing Azure Resource Group or Cluster for AKS (Azure Kubernetes Service). You can create a cluster in the deployment process.&lt;/p&gt;
&lt;h2 id=&#34;understanding-the-deployment-process&#34;&gt;Understanding the deployment process&lt;/h2&gt;
&lt;p&gt;The deployment process is controlled by the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - (Optional) Creates configuration files defining the various
resources in your deployment. You only need to run &lt;code&gt;kfctl build&lt;/code&gt; if you want
to edit the resources before running &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;apply&lt;/strong&gt; - Creates or updates the resources.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;delete&lt;/strong&gt; - Deletes the resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;app-layout&#34;&gt;App layout&lt;/h3&gt;
&lt;p&gt;Your OpenDataology application directory &lt;strong&gt;${KF_DIR}&lt;/strong&gt; contains the following files and
directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${CONFIG_FILE}&lt;/strong&gt; is a YAML file that defines configurations related to your
OpenDataology deployment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This file is a copy of the GitHub-based configuration YAML file that
you used when deploying OpenDataology. For example, &lt;a href=&#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_azure.v1.2.0.yaml&#34;&gt;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_azure.v1.2.0.yaml&lt;/a&gt;
.&lt;/li&gt;
&lt;li&gt;When you run &lt;code&gt;kfctl apply&lt;/code&gt; or &lt;code&gt;kfctl build&lt;/code&gt;, kfctl creates
a local version of the configuration file, &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;,
which you can further customize if necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;kustomize&lt;/strong&gt; is a directory that contains the kustomize packages for OpenDataology applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The directory is created when you run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;You can customize the Kubernetes resources (modify the manifests and run &lt;code&gt;kfctl apply&lt;/code&gt; again).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you experience any issues running these scripts, see the &lt;a href=&#34;/docs/azure/troubleshooting-azure&#34;&gt;troubleshooting guidance&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2 id=&#34;azure-setup&#34;&gt;Azure setup&lt;/h2&gt;
&lt;h3 id=&#34;to-log-into-azure-from-the-command-line-interface-run-the-following-commands&#34;&gt;To log into Azure from the command line interface, run the following commands&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;az login
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;az account set --subscription &amp;lt;NAME OR ID OF SUBSCRIPTION&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;initial-cluster-setup-for-new-cluster&#34;&gt;Initial cluster setup for new cluster&lt;/h3&gt;
&lt;p&gt;Create a resource group:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;az group create -n &amp;lt;RESOURCE_GROUP_NAME&amp;gt; -l &amp;lt;LOCATION&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;RESOURCE_GROUP_NAME=KubeTest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOCATION=westus&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Create a specifically defined cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;az aks create -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt; -n &amp;lt;NAME&amp;gt; -s &amp;lt;AGENT_SIZE&amp;gt; -c &amp;lt;AGENT_COUNT&amp;gt; -l &amp;lt;LOCATION&amp;gt; --generate-ssh-keys
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NAME=KubeTestCluster&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AGENT_SIZE=Standard_D4s_v3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AGENT_COUNT=2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RESOURCE_GROUP_NAME=KubeTest&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:  If you are using a GPU based AKS cluster (For example: AGENT_SIZE=Standard_NC6), you also need to &lt;a href=&#34;https://docs.microsoft.com/azure/aks/gpu-cluster#install-nvidia-drivers&#34;&gt;install the NVidia drivers&lt;/a&gt; on the cluster nodes before you can use GPUs with OpenDataology.&lt;/p&gt;
&lt;h2 id=&#34;opendataology-installation&#34;&gt;OpenDataology installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: To deploy OpenDataology on Azure with multi-user authentication and namespace separation, use the instructions for &lt;a href=&#34;/docs/azure/authentication-oidc&#34;&gt;Authentication using OICD in Azure&lt;/a&gt;. The instructions in this guide apply only to a single-user OpenDataology deployment. Such a deployment cannot be upgraded to a multi-user deployment at this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: kfctl is currently available for Linux and macOS users only. If you use Windows, you can install kfctl on Windows Subsystem for Linux (WSL). Refer to the official &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-win10&#34;&gt;instructions&lt;/a&gt; for setting up WSL.&lt;/p&gt;
&lt;p&gt;Run the following commands to set up and deploy OpenDataology.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create user credentials. You only need to run this command once.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;az aks get-credentials -n &amp;lt;NAME&amp;gt; -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the kfctl v1.2.0 release from the
&lt;a href=&#34;https://github.com/OpenDataology/kfctl/releases/tag/v1.2.0&#34;&gt;OpenDataology releases
page&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unpack the tar ball:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tar -xvf kfctl_v1.2.0_&amp;lt;platform&amp;gt;.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following commands to set up and deploy OpenDataology. The code below includes an optional command to add the
binary kfctl to your path. If you don’t add the binary to your path, you must use the full path to the kfctl binary each time you run it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# The following command is optional. It adds the kfctl binary to your path.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# If you don&amp;#39;t add kfctl to your path, you must use the full path
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# each time you run kfctl.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Use only alphanumeric characters or - in the directory name.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PATH=$PATH:&amp;#34;&amp;lt;path-to-kfctl&amp;gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set KF_NAME to the name of your OpenDataology deployment. You also use this
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# value as directory name when creating your configuration directory.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# For example, your deployment name can be &amp;#39;my-OpenDataology&amp;#39; or &amp;#39;kf-test&amp;#39;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export KF_NAME=&amp;lt;your choice of name for the OpenDataology deployment&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set the path to the base directory where you want to store one or more 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# OpenDataology deployments. For example, /opt/.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Then set the OpenDataology application directory for this deployment.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export BASE_DIR=&amp;lt;path to a base directory&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export KF_DIR=${BASE_DIR}/${KF_NAME}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set the configuration file to use when deploying OpenDataology.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# The following configuration installs Istio by default. Comment out 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# the Istio components in the config file to skip Istio installation. 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# See https://github.com/OpenDataology/OpenDataology/pull/3663
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export CONFIG_URI=&amp;#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_k8s_istio.v1.2.0.yaml&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p ${KF_DIR}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ${KF_DIR}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfctl apply -V -f ${CONFIG_URI}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${KF_NAME}&lt;/strong&gt; - The name of your OpenDataology deployment.
If you want a custom deployment name, specify that name here.
For example,  &lt;code&gt;my-OpenDataology&lt;/code&gt; or &lt;code&gt;kf-test&lt;/code&gt;.
The value of KF_NAME must consist of lower case alphanumeric characters or
&amp;lsquo;-&amp;rsquo;, and must start and end with an alphanumeric character.
The value of this variable cannot be greater than 25 characters. It must
contain just a name, not a directory path.
You also use this value as directory name when creating the directory where
your OpenDataology  configurations are stored, that is, the OpenDataology application
directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${KF_DIR}&lt;/strong&gt; - The full path to your OpenDataology application directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${CONFIG_URI}&lt;/strong&gt; - The GitHub address of the configuration YAML file that
you want to use to deploy OpenDataology. The URI used in this guide is
&lt;a href=&#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_k8s_istio.v1.2.0.yaml&#34;&gt;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_k8s_istio.v1.2.0.yaml&lt;/a&gt;.
When you run &lt;code&gt;kfctl apply&lt;/code&gt; or &lt;code&gt;kfctl build&lt;/code&gt; (see the next step), kfctl creates
a local version of the configuration YAML file which you can further
customize if necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run this command to check that the resources have been deployed correctly in namespace &lt;code&gt;OpenDataology&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get all -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open the OpenDataology Dashboard&lt;/p&gt;
&lt;p&gt;The default installation does not create an external endpoint but you can use port-forwarding to visit your cluster.
Run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, open &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser.&lt;/p&gt;
&lt;p&gt;To open the dashboard to a public IP address, you should first implement a solution to prevent unauthorized access.
You can read more about Azure authentication options from &lt;a href=&#34;/docs/azure/authentication&#34;&gt;Access Control for Azure Deployment&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;additional-information&#34;&gt;Additional information&lt;/h2&gt;
&lt;p&gt;You can find general information about OpenDataology configuration in the guide to &lt;a href=&#34;/docs/methods/kfctl/kustomize/&#34;&gt;configuring OpenDataology with kfctl and kustomize&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology on Nutanix Karbon</title>
      <link>/docs/distributions/nutanix/install-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/nutanix/install-kubeflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make sure you first create a Kubernetes cluster using Nutanix Karbon. See &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Karbon-v2_2:kar-karbon-deploy-karbon-t.html&#34;&gt;Nutanix Karbon documentation&lt;/a&gt; at the Nutanix Support Portal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;a href=&#34;https://www.terraform.io/downloads.html&#34;&gt;Terraform&lt;/a&gt; based on your platform&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install kubectl from &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;Install Tools&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Karbon-v2_2:kar-karbon-download-kubeconfig-t.html&#34;&gt;Kubeconfig&lt;/a&gt; of your deployed Karbon cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installing-opendataology&#34;&gt;Installing OpenDataology&lt;/h2&gt;
&lt;p&gt;Do these steps to deploy OpenDataology 1.5.0 on your Karbon cluster.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the terraform script to deploy OpenDataology on Nutanix Karbon by cloning the Github repository shown.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/nutanix/karbon-platform-services.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd automation/infrastructure/terraform/kcs/install_OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create &lt;code&gt;env.tfvars&lt;/code&gt; file in the same folder with the following cluster variables. Override other variables from variables.tf file if required.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prism_central_username = &amp;#34;enter username&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prism_central_password = &amp;#34;enter password&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prism_central_endpoint = &amp;#34;enter endpoint_ip_or_host_fqdn&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;karbon_cluster_name    = &amp;#34;enter karbon_cluster_name&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeconfig_filename    = &amp;#34;enter karbon_cluster_name-kubectl.cfg&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenDataology_version       = &amp;#34;1.5.0&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply terraform commands to deploy OpenDataology in the cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;terraform init
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;terraform plan --var-file=env.tfvars
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;terraform apply --var-file=env.tfvars
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure all the pods are running before continuing to the next step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl -n OpenDataology get pods
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                                                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;admission-webhook-deployment-65dcd649d8-468g9                1/1     Running   0          3m39s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-deployer-deployment-6b78494889-6lfg9                   2/2     Running   1          3m1s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-server-bff956474-lm952                                 2/2     Running   0          3m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;centraldashboard-6b5fb79878-h9dqn                            1/1     Running   0          3m40s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jupyter-web-app-deployment-75559c6c87-mt4q2                  1/1     Running   0          3m1s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;katib-controller-79f44b76bb-t7rzl                            1/1     Running   0          3m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;katib-db-manager-6d9857f658-p4786                            1/1     Running   0          2m59s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;katib-mysql-586f79b694-2qcl5                                 1/1     Running   0          2m59s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;katib-ui-5fdb7869cf-jmssr                                    1/1     Running   0          3m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfserving-controller-manager-0                               2/2     Running   0          3m15s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenDataology-pipelines-profile-controller-6cfd6bf9bd-cptgg       1/1     Running   0          2m59s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metacontroller-0                                             1/1     Running   0          3m15s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-envoy-deployment-6756c995c9-gqkbd                   1/1     Running   0          3m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-grpc-deployment-7cb87744c7-4crm9                    2/2     Running   3          3m40s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-writer-6bf5cfd7d8-fgq9f                             2/2     Running   0          3m40s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minio-5b65df66c9-9z7mg                                       2/2     Running   0          2m59s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;....
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;add-a-new-opendataology-user&#34;&gt;Add a new OpenDataology user&lt;/h2&gt;
&lt;p&gt;New users are created using the Profile resource. A new namespace is created with the same Profile name. For creating a new user with email &lt;code&gt;user@example.com&lt;/code&gt; in a namespace &lt;code&gt;project1&lt;/code&gt;, apply the following profile&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: OpenDataology.org/v1beta1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Profile
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name: project1   # replace with the name of profile you want, this will be the user&amp;#39;s namespace name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    owner:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        kind: User
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        name: user2@example.com   # replace with the user email
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;EOF
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you are using basic authentication, add the user credentials in dex which is the default OpenId Connect provider in OpenDataology. Generate the hash by using bcrypt (available at &lt;a href=&#34;https://bcrypt-generator.com&#34;&gt;https://bcrypt-generator.com&lt;/a&gt;) in the following configmap&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit cm dex -o yaml -n auth
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the following  under staticPasswords section&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- email: user2@example.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  hash: &amp;lt;hash&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  username: user2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;setup-a-loadbalancer-optional&#34;&gt;Setup a LoadBalancer (Optional)&lt;/h2&gt;
&lt;p&gt;If you already have a load balancer set up for your Karbon cluster, you can skip this step. If you do not wish to
expose the OpenDataology dashboard to an external load balancer IP, you can also skip this step.
If not, you can install the &lt;a href=&#34;https://metallb.universe.tf/&#34;&gt;MetalLB&lt;/a&gt; load balancer manifests on your Karbon cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.10.2/manifests/namespace.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.10.2/manifests/metallb.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the manifests have been applied, we need to configure MetalLB with the IP range that it can use to assign external IPs to services of type LoadBalancer. You can find the range from the subnet in Prism Central’s &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Nutanix-Flow-Networking-Guide:ear-flow-nw-view-subnet-list-pc-r.html&#34;&gt;networking and security&lt;/a&gt; settings.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: ConfigMap
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  namespace: metallb-system
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  config: |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    address-pools:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - name: default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        protocol: layer2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        addresses:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        - &amp;lt;IP_ADDRESS_RANGE: x.x.x.x-x.x.x.x&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Create a ConfigMap with the following information, substitute the addresses field with your IP address range, and apply it to the cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl apply -f metallb-configmap.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;access-opendataology-central-dashboard&#34;&gt;Access OpenDataology Central Dashboard&lt;/h2&gt;
&lt;p&gt;There are multiple ways to acces your OpenDataology Central Dashboard:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Port Forward: The default way to access OpenDataology Central Dashboard is by using Port-Forward. You can port forward the istio ingress gateway to local port 8080.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl --kubeconfig=&amp;lt;karbon_k8s_cluster_kubeconfig_path&amp;gt; port-forward svc/istio-ingressgateway -n istio-system 8080:80
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can now access the OpenDataology Central Dashboard at http://localhost:8080. At the Dex login page, enter user credentials that you previously created.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NodePort: For accessing through NodePort, you need to configure HTTPS. Create a certificate using cert-manager for your Worker node IP in your cluster. Add HTTPS to OpenDataology gateway as given in &lt;a href=&#34;https://istio.io/latest/docs/tasks/traffic-management/ingress/secure-ingress/&#34;&gt;Istio Secure Gateways&lt;/a&gt;. Then access your cluster at&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://&amp;lt;worknernode-ip&amp;gt;:&amp;lt;https-nodeport&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LoadBalancer: If you have a LoadBalancer set up (See optional &amp;ldquo;Setup a LoadBalancer&amp;rdquo; section above), you can access the dashboard using the external IP by making the following changes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update Istio Gateway to expose port 443 with HTTPS and make port 80 redirect to 443:
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n OpenDataology edit gateways.networking.istio.io OpenDataology-gateway
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;The updated gateway spec should look like:
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Gateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology-gateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;selector&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;istio&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ingressgateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;servers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hosts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;port&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;http&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;number&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;80&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;protocol&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;HTTP&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Upgrade HTTP to HTTPS&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tls&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;httpsRedirect&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hosts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;port&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;https&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;number&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;443&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;protocol&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;HTTPS&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tls&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;mode&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;SIMPLE&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;privateKey&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/etc/istio/ingressgateway-certs/tls.key&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;serverCertificate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/etc/istio/ingressgateway-certs/tls.crt&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Change the type of the istio-ingressgateway service to LoadBalancer
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system  patch service istio-ingressgateway -p &amp;#39;{&amp;#34;spec&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;LoadBalancer&amp;#34;}}&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Get the IP address for the &lt;code&gt;LoadBalancer&lt;/code&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system get svc istio-ingressgateway -o jsonpath=&amp;#39;{.status.loadBalancer.ingress[0]}&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Set the &lt;code&gt;REDIRECT_URL&lt;/code&gt; in &lt;code&gt;oidc-authservice-parameters&lt;/code&gt; configmap to something like &lt;code&gt;https://x.x.x.x/login/oidc&lt;/code&gt; where the &lt;code&gt;x.x.x.x&lt;/code&gt; is the IP address of your istio-ingressgateway.
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system edit configmap oidc-authservice-parameters
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Append the same to the &lt;code&gt;redirectURIs&lt;/code&gt; list in &lt;code&gt;dex&lt;/code&gt; configmap
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n auth edit configmap dex
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Rollout restart authservice and dex
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system rollout restart statefulset authservice
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n auth rollout restart deployment dex
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Create a &lt;code&gt;certificate.yaml&lt;/code&gt; with the YAML below to create a self-signed certificate
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: cert-manager.io/v1alpha2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Certificate
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: istio-ingressgateway-certs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  namespace: istio-system
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  commonName: istio-ingressgateway.istio-system.svc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ipAddresses:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - &amp;lt;ISTIO_INGRESSGATEWAY_IP_ADDRESS: x.x.x.x&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  isCA: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  issuerRef:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    kind: ClusterIssuer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name: OpenDataology-self-signing-issuer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  secretName: istio-ingressgateway-certs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;Apply &lt;code&gt;certificate.yaml&lt;/code&gt; to the &lt;code&gt;istio-system&lt;/code&gt; namespace
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system apply -f certificate.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;You can now access the OpenDataology dashboard by navigating to the istio-ingressgateway external IP e.g. &lt;code&gt;x.x.x.x&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology on OpenShift</title>
      <link>/docs/distributions/openshift/install-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/openshift/install-kubeflow/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to use the &lt;code&gt;kfctl&lt;/code&gt; CLI to deploy OpenDataology 1.3 on an existing OpenShift 4.x cluster.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;openshift-4-cluster&#34;&gt;OpenShift 4 cluster&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You need to have access to an OpenShift 4 cluster as &lt;code&gt;cluster-admin&lt;/code&gt; to be able to deploy OpenDataology.&lt;/li&gt;
&lt;li&gt;You can use &lt;a href=&#34;https://code-ready.github.io/crc/&#34;&gt;Code Ready Containers&lt;/a&gt; (CRC) to run a local cluster, use &lt;a href=&#34;https://try.openshift.com&#34;&gt;try.openshift.com&lt;/a&gt; to create a new cluster or use an existing cluster.&lt;/li&gt;
&lt;li&gt;Install &lt;a href=&#34;https://docs.openshift.com/container-platform/4.2/cli_reference/openshift_cli/getting-started-cli.html&#34;&gt;&lt;code&gt;oc&lt;/code&gt; command-line tool&lt;/a&gt; to communicate with the cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;code-ready-containers&#34;&gt;Code Ready Containers&lt;/h4&gt;
&lt;p&gt;If you are using Code Ready Containers, you need to make sure you have enough resources configured for the VM:&lt;/p&gt;
&lt;p&gt;Recommended:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;16 GB memory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;6 CPU
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;45 GB disk space
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Minimal:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;10 GB memory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;6 CPU
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;30 GB disk space (default for CRC)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installing-opendataology&#34;&gt;Installing OpenDataology&lt;/h2&gt;
&lt;p&gt;Use the following steps to install OpenDataology 1.3 on OpenShift 4.x.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the example &amp;ldquo;kfdef&amp;rdquo; for OpenDataology 1.3 on Openshift from [OpenDataology/manifests/distributions/kfdef]
(&lt;a href=&#34;https://raw.githubusercontent.com/opendatahub-io/manifests/v1.3-branch/distributions/kfdef/kfctl_openshift_v1.3.0.yaml)&#34;&gt;https://raw.githubusercontent.com/opendatahub-io/manifests/v1.3-branch/distributions/kfdef/kfctl_openshift_v1.3.0.yaml)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build the deployment configuration using the example OpenShift KFDef file.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Create a directory and copy the KFDef file to it. And finally build the configuration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# set the OpenDataology application directory for this deployment, for example /opt/openshift-kfdef
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export KF_DIR=&amp;lt;path-to-kfdef&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p ${KF_DIR}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp kfctl_openshift_v1.3.0.yaml ${KF_DIR}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# build deployment configuration
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ${KF_DIR}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfctl build --file=kfctl_openshift_v1.3.0.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the generated deployment configuration.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfctl apply --file=kfctl_openshift_v1.3.0.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait until all the pods are running.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ oc get pods -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                                               READY   STATUS              RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;admission-webhook-deployment-6748884cff-wb7kp      1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-deployer-deployment-799f449d59-5zl2l         1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-server-67849767c5-7w44j                      1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;centraldashboard-78f95899fc-8rt8k                  1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-envoy-deployment-67fd74f564-tsrxm         1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-grpc-deployment-9d547547d-g9cq7           1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-writer-7776fc6f6f-4f4hp                   1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minio-5cb67d5f6d-l9665                             1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-6d4fbc667b-hhqsw                       1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-persistenceagent-667c448c65-r9sn5      1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-scheduledworkflow-5b9769fc8b-s9nt8     1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-ui-6f9f496b7-9rr4s                     1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-viewer-crd-77ccffd6d4-n4x55            1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-visualizationserver-6c7b448b99-5ttn4   1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mysql-7659b8f58c-npr57                             1/1     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;profiles-deployment-7c8446984b-nvvh7               2/2     Running             0          42h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;workflow-controller-7899f6947-gz7km                1/1     Running             0          42h    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The command below looks up the URL of the OpenDataology user interface assigned by the OpenShift cluster. You can open the printed URL in your browser to access the OpenDataology user interface.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;oc get routes -n istio-system istio-ingressgateway -o jsonpath=&amp;#39;http://{.spec.host}/&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;See how to &lt;a href=&#34;/docs/openshift/uninstall-OpenDataology&#34;&gt;uninstall&lt;/a&gt; your OpenDataology deployment
using the CLI.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction</title>
      <link>/docs/distributions/operator/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/operator/introduction/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes the OpenDataology Operator and the current supported releases of OpenDataology Operator.&lt;/p&gt;
&lt;h2 id=&#34;opendataology-operator&#34;&gt;OpenDataology Operator&lt;/h2&gt;
&lt;p&gt;OpenDataology Operator helps deploy, monitor and manage the lifecycle of OpenDataology. Built using the &lt;a href=&#34;https://coreos.com/blog/introducing-operator-framework&#34;&gt;Operator Framework&lt;/a&gt; which offers an open source toolkit to build, test, package operators and manage the lifecycle of operators.&lt;/p&gt;
&lt;p&gt;The operator is currently in incubation phase and is based on this &lt;a href=&#34;https://docs.google.com/document/d/1vNBZOM-gDMpwTbhx0EDU6lDpyUjc7vhT3bdOWWCRjdk/edit#&#34;&gt;design doc&lt;/a&gt;. It is built on top of &lt;em&gt;KfDef&lt;/em&gt; CR, and uses &lt;em&gt;kfctl&lt;/em&gt; as the nucleus for Controller. Current roadmap for this Operator is listed &lt;a href=&#34;https://github.com/OpenDataology/kfctl/issues/193&#34;&gt;here&lt;/a&gt;. The Operator is also &lt;a href=&#34;https://operatorhub.io/operator/OpenDataology&#34;&gt;published on OperatorHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Applications and components to be deployed as part of OpenDataology platform are defined in the KfDef configuration manifest. Each application has a &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize&#34;&gt;kustomize&lt;/a&gt; configuration with all its resource manifests. KfDef &lt;code&gt;spec&lt;/code&gt; includes the &lt;code&gt;applications&lt;/code&gt; field.  Application are specified in the &lt;code&gt;kustomizeConfig&lt;/code&gt; field. &lt;code&gt;parameters&lt;/code&gt; and &lt;code&gt;overlays&lt;/code&gt; may be used to provide custom setting for the application. &lt;code&gt;repoRef&lt;/code&gt; field specifies the path to retrieve the application&amp;rsquo;s kustomize configuration.&lt;/p&gt;
&lt;p&gt;KfDef &lt;code&gt;spec&lt;/code&gt; may also include a &lt;code&gt;plugins&lt;/code&gt; field for certain cloud platforms, including AWS and GCP. It is used by the platforms to preprocess certain tasks before OpenDataology deployment.&lt;/p&gt;
&lt;p&gt;An example of KfDef is as follow:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kfdef.apps.OpenDataology.org/v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KfDef&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;applications&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Install Istio&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomizeConfig&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repoRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;stacks/ibm/application/istio-stack&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;istio-stack&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Install OpenDataology applications.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomizeConfig&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repoRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;stacks/ibm&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology-apps&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Other applications&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomizeConfig&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repoRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;stacks/ibm/application/spark-operator&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;spark-operator&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Model Serving applications&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomizeConfig&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repoRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;knative/installs/generic&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;knative&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kustomizeConfig&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repoRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kfserving/installs/generic&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kfserving&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;repos&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manifests&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;uri&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;https://github.com/OpenDataology/manifests/archive/master.tar.gz&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;master&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;More KfDef examples may be found in OpenDataology &lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/master/kfdef&#34;&gt;manifests&lt;/a&gt; repo. Users can pick one there and make some modification to fit their requirements. &lt;a href=&#34;https://github.com/opendatahub-io&#34;&gt;OpenDataHub&lt;/a&gt; project also maintains a KfDef &lt;a href=&#34;https://github.com/opendatahub-io/manifests/blob/v1.0-branch-openshift/kfdef/kfctl_openshift.yaml&#34;&gt;manifest&lt;/a&gt; for OpenDataology deployment on OpenShift Container Platforms.&lt;/p&gt;
&lt;p&gt;The operator watches on all KfDef configuration instances in the cluster as custom resources (CR) and manage them. It handles reconcile requests to all the &lt;em&gt;KfDef&lt;/em&gt; instances. To understand more on the operator controller behavior, refer to this &lt;a href=&#34;https://github.com/kubernetes-sigs/controller-runtime/blob/master/pkg/doc.go&#34;&gt;controller-runtime link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OpenDataology Operator shares the same packages and functions as the &lt;code&gt;kfctl&lt;/code&gt; CLI, which is the command line approach to deploy OpenDataology. Therefore, the deployment flow is similar except that the &lt;code&gt;ownerReferences&lt;/code&gt; metadata is added for each application&amp;rsquo;s Kubernetes object. The KfDef CR is the parent of all these objects. OpenDataology Operator does better in tearing down the OpenDataology deployment than the CLI approach. When the KfDef CR is deleted, Kubernetes garbage collection mechanism then takes over the responsibility to remove all and only the resources deployed through this KfDef configuration.&lt;/p&gt;
&lt;p&gt;One of the many good reasons to use an operator is to monitor the resources. The OpenDataology Operator also watches all child resources of the KfDef CR. Should any of these resources be deleted, the operator would try to apply the resource manifest and bring the object up again.&lt;/p&gt;
&lt;p&gt;The operator responds to following events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When a &lt;em&gt;KfDef&lt;/em&gt; instance is created or updated, the operator&amp;rsquo;s &lt;em&gt;reconciler&lt;/em&gt; will be notified of the event and invoke the &lt;code&gt;Apply&lt;/code&gt; functions provided by the &lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/master/pkg&#34;&gt;&lt;code&gt;kfctl&lt;/code&gt; package&lt;/a&gt; to deploy OpenDataology. The OpenDataology resources specified with the manifests will be owned by the &lt;em&gt;KfDef&lt;/em&gt; instance with their &lt;code&gt;ownerReferences&lt;/code&gt; set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When a &lt;em&gt;KfDef&lt;/em&gt; instance is deleted, since the owner is deleted, all the secondary resources owned by it will be deleted through the &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/&#34;&gt;garbage collection&lt;/a&gt;. In the mean time, the &lt;em&gt;reconciler&lt;/em&gt; will be notified of the event and remove the finalizers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When any resource deployed as part of a &lt;em&gt;KfDef&lt;/em&gt; instance is deleted, the operator&amp;rsquo;s &lt;em&gt;reconciler&lt;/em&gt; will be notified of the event and invoke the &lt;code&gt;Apply&lt;/code&gt; functions provided by the &lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/master/pkg&#34;&gt;&lt;code&gt;kfctl&lt;/code&gt; package&lt;/a&gt; to re-deploy the OpenDataology. The deleted resource will be recreated with the same manifest as specified when the &lt;em&gt;KfDef&lt;/em&gt; instance is created.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Deploying OpenDataology with the OpenDataology Operator includes two steps: &lt;a href=&#34;/docs/methods/operator/install-operator&#34;&gt;installing the OpenDataology Operator&lt;/a&gt; followed by &lt;a href=&#34;/docs/methods/operator/deploy/operator&#34;&gt;deploying&lt;/a&gt; the KfDef custom resource.&lt;/p&gt;
&lt;h2 id=&#34;current-tested-operators-and-pre-built-images&#34;&gt;Current Tested Operators and Pre-built Images&lt;/h2&gt;
&lt;p&gt;OpenDataology Operator controller logic is based on the &lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/master/pkg&#34;&gt;&lt;code&gt;kfctl&lt;/code&gt; package&lt;/a&gt;, so for each major release of &lt;code&gt;kfctl&lt;/code&gt;, an operator image is built and tested with that version of &lt;a href=&#34;github.com/OpenDataology/manifests&#34;&gt;&lt;code&gt;manifests&lt;/code&gt;&lt;/a&gt; to deploy a &lt;em&gt;KfDef&lt;/em&gt; instance. Following table shows what releases have been tested.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;branch tag&lt;/th&gt;
&lt;th&gt;operator image&lt;/th&gt;
&lt;th&gt;manifests version&lt;/th&gt;
&lt;th&gt;kfdef example&lt;/th&gt;
&lt;th&gt;note&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/v1.0&#34;&gt;v1.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hub.docker.com/layers/aipipeline/OpenDataology-operator/v1.0.0/images/sha256-63d00b29a61ff5bc9b0527c8a515cd4cb55de474c45d8e0f65742908ede4d88f?context=repo&#34;&gt;aipipeline/OpenDataology-operator:v1.0.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/f56bb47d7dc5378497ad1e38ea99f7b5ebe7a950&#34;&gt;1.0.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/f56bb47d7dc5378497ad1e38ea99f7b5ebe7a950/kfdef/kfctl_k8s_istio.v1.0.0.yaml&#34;&gt;kfctl_k8s_istio.v1.0.0.yaml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/v1.0.1&#34;&gt;v1.0.1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hub.docker.com/layers/aipipeline/OpenDataology-operator/v1.0.1/images/sha256-828024b773040271e4b547ce9219046f705fb7123e05503d5a2d1428dfbcfb6e?context=repo&#34;&gt;aipipeline/OpenDataology-operator:v1.0.1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/v1.0.1&#34;&gt;1.0.1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/v1.0.1/kfdef/kfctl_k8s_istio.v1.0.1.yaml&#34;&gt;kfctl_k8s_istio.v1.0.1.yaml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/v1.0.2&#34;&gt;v1.0.2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hub.docker.com/layers/aipipeline/OpenDataology-operator/v1.0.2/images/sha256-18d2ca6f19c1204d5654dfc4cc08032c168e89a95dee68572b9e2aaedada4bda?context=repo&#34;&gt;aipipeline/OpenDataology-operator:v1.0.2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/v1.0.2&#34;&gt;1.0.2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/v1.0.2/kfdef/kfctl_k8s_istio.v1.0.2.yaml&#34;&gt;kfctl_k8s_istio.v1.0.2.yaml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfctl/tree/v1.1.0&#34;&gt;v1.1.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hub.docker.com/layers/aipipeline/OpenDataology-operator/v1.0.0/images/sha256-63d00b29a61ff5bc9b0527c8a515cd4cb55de474c45d8e0f65742908ede4d88f?context=explore&#34;&gt;aipipeline/OpenDataology-operator:v1.1.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/v1.1.0&#34;&gt;1.1.0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/v1.1-branch/kfdef/kfctl_ibm.v1.1.0.yaml&#34;&gt;kfctl_ibm.v1.1.0.yaml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/kfctl&#34;&gt;master&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hub.docker.com/layers/aipipeline/OpenDataology-operator/master/images/sha256-e81020c426a12237c7cf84316dbbd0efda76e732233ddd57ef33543381dfb8a1?context=repo&#34;&gt;aipipeline/OpenDataology-operator:master&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests&#34;&gt;master&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/manifests/blob/master/kfdef/kfctl_ibm.yaml&#34;&gt;kfctl_ibm.yaml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;as of 07/29/2020&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: if building a customized operator for a specific version of OpenDataology is desired, you can run &lt;code&gt;git checkout&lt;/code&gt; to that specific branch tag. Keep in mind to use the matching version of manifests.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Deploy OpenDataology cluster</title>
      <link>/docs/distributions/gke/deploy/deploy-cli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/deploy-cli/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to use &lt;code&gt;kubectl&lt;/code&gt; and &lt;a href=&#34;https://googlecontainertools.github.io/kpt/&#34;&gt;kpt&lt;/a&gt; to
deploy OpenDataology on Google Cloud.&lt;/p&gt;
&lt;h2 id=&#34;deployment-steps&#34;&gt;Deployment steps&lt;/h2&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;Before installing OpenDataology on the command line:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You must have created a management cluster and installed Config Connector.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you don&amp;rsquo;t have a management cluster follow the &lt;a href=&#34;/docs/distributions/gke/deploy/management-setup/&#34;&gt;instructions&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your management cluster will need a namespace setup to administer the Google Cloud project where OpenDataology will be deployed. This step will be included in later step of current page.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You need to use Linux or &lt;a href=&#34;https://cloud.google.com/shell/&#34;&gt;Cloud Shell&lt;/a&gt; for ASM installation. Currently ASM installation doesn&amp;rsquo;t work on macOS because it &lt;a href=&#34;https://cloud.google.com/service-mesh/docs/scripted-install/asm-onboarding#installing_required_tools&#34;&gt;comes with an old version of bash&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure that your Google Cloud project meets the minimum requirements
described in the &lt;a href=&#34;/docs/distributions/gke/deploy/project-setup/&#34;&gt;project setup guide&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the guide
&lt;a href=&#34;/docs/distributions/gke/deploy/oauth-setup/&#34;&gt;setting up OAuth credentials&lt;/a&gt;
to create OAuth credentials for &lt;a href=&#34;https://cloud.google.com/iap/docs/&#34;&gt;Cloud Identity-Aware Proxy (Cloud
IAP)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unfortunately &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/backendconfig&#34;&gt;GKE&amp;rsquo;s BackendConfig&lt;/a&gt;
currently doesn&amp;rsquo;t support creating &lt;a href=&#34;https://cloud.google.com/iap/docs/programmatic-oauth-clients&#34;&gt;IAP OAuth clients programmatically&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-the-required-tools&#34;&gt;Install the required tools&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;a href=&#34;https://cloud.google.com/sdk/&#34;&gt;gcloud&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install gcloud components&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud components install kubectl kustomize kpt anthoscli beta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud components update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can install specific version of kubectl by following instruction (Example: &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/&#34;&gt;Install kubectl on Linux&lt;/a&gt;). Latest patch version of kubectl from &lt;code&gt;v1.17&lt;/code&gt; to &lt;code&gt;v1.19&lt;/code&gt; works well too.&lt;/p&gt;
&lt;p&gt;Note: Starting from OpenDataology 1.4, it requires &lt;code&gt;kpt v1.0.0-beta.6&lt;/code&gt; or above to operate in &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; repository. gcloud hasn&amp;rsquo;t caught up with this kpt version yet, &lt;a href=&#34;https://kpt.dev/installation/&#34;&gt;install kpt&lt;/a&gt; separately from &lt;a href=&#34;https://github.com/GoogleContainerTools/kpt/tags&#34;&gt;https://github.com/GoogleContainerTools/kpt/tags&lt;/a&gt; for now. Note that kpt requires docker to be installed.&lt;/p&gt;
&lt;p&gt;Note: You also need to &lt;a href=&#34;https://cloud.google.com/service-mesh/v1.10/docs/scripted-install/asm-onboarding#installing_required_tools&#34;&gt;install required tools&lt;/a&gt; for ASM installation tool &lt;code&gt;install_asm&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fetch-opendataologygcp-blueprints-and-upstream-packages&#34;&gt;Fetch OpenDataology/gcp-blueprints and upstream packages&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;If you have already installed Management cluster, you have &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; locally. You just need to run &lt;code&gt;cd OpenDataology&lt;/code&gt; to access OpenDataology cluster manifests. Otherwise, you can run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Check out OpenDataology v1.5.1 blueprints&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/OpenDataology/gcp-blueprints.git 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout tags/v1.5.1 -b v1.5.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Alternatively, you can get the package by using &lt;code&gt;kpt&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Check out OpenDataology v1.5.1 blueprints&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt pkg get https://github.com/OpenDataology/gcp-blueprints.git@v1.5.1 gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; gcp-blueprints
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to pull upstream manifests from &lt;code&gt;OpenDataology/manifests&lt;/code&gt; repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Visit OpenDataology cluster related manifests&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash ./pull-upstream.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;environment-variables&#34;&gt;Environment Variables&lt;/h3&gt;
&lt;p&gt;Log in to gcloud. You only need to run this command once:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud auth login
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Review and fill all the environment variables in &lt;code&gt;gcp-blueprints/OpenDataology/env.sh&lt;/code&gt;, they will be used by &lt;code&gt;kpt&lt;/code&gt; later on, and some of them will be used in this deployment guide. Review the comment in &lt;code&gt;env.sh&lt;/code&gt; for the explanation for each environment variable. After defining these environment variables, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; env.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set environment variables with OAuth Client ID and Secret for IAP:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLIENT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;Your CLIENT_ID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLIENT_SECRET&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;Your CLIENT_SECRET&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    Do not omit the &lt;b&gt;export&lt;/b&gt; because scripts triggered by &lt;b&gt;make&lt;/b&gt; need these environment variables. Do not check in these two environment variables configuration to source control, they are secrets.

&lt;/div&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;kpt-setter-config&#34;&gt;kpt setter config&lt;/h4&gt;
&lt;p&gt;Run the following commands to configure kpt setter for your OpenDataology cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash ./kpt-set.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Everytime you change environment variables, make sure you run the command above to apply
kpt setter change to all packages. Otherwise, kustomize build will not be able to pick up
new changes.&lt;/p&gt;
&lt;p&gt;Note, you can find out which setters exist in a package and their
current values by running the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt fn &lt;span style=&#34;color:#204a87&#34;&gt;eval&lt;/span&gt; -i list-setters:v0.1 ./apps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt fn &lt;span style=&#34;color:#204a87&#34;&gt;eval&lt;/span&gt; -i list-setters:v0.1 ./common
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can learn more about &lt;code&gt;list-setters&lt;/code&gt; in &lt;a href=&#34;https://catalog.kpt.dev/list-setters/v0.1/&#34;&gt;kpt documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;authorize-cloud-config-connector-for-each-opendataology-project&#34;&gt;Authorize Cloud Config Connector for each OpenDataology project&lt;/h4&gt;
&lt;p&gt;In the &lt;a href=&#34;/docs/distributions/gke/deploy/management-setup/&#34;&gt;Management cluster deployment&lt;/a&gt; we created the Google Cloud service account &lt;strong&gt;serviceAccount:kcc-${KF_PROJECT}@${MGMT_PROJECT}.iam.gserviceaccount.com&lt;/strong&gt;
this is the service account that Config Connector will use to create any Google Cloud resources in &lt;code&gt;${KF_PROJECT}&lt;/code&gt;. You need to grant this Google Cloud service account sufficient privileges to create the desired resources in OpenDataology project.
You only need to perform steps below once for each OpenDataology project, but make sure to do it even when KF_PROJECT and MGMT_PROJECT are the same project.&lt;/p&gt;
&lt;p&gt;The easiest way to do this is to grant the Google Cloud service account owner permissions on one or more projects.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Set the Management environment variable if you haven&amp;rsquo;t:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;the project where you deploy your management cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;the kubectl context name &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; management cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply ConfigConnectorContext for &lt;code&gt;${KF_PROJECT}&lt;/code&gt; in management cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply-kcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;configure-opendataology&#34;&gt;Configure OpenDataology&lt;/h3&gt;
&lt;p&gt;Make sure you are using KF_PROJECT in the gcloud CLI tool:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud config &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; project &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deploy-opendataology&#34;&gt;Deploy OpenDataology&lt;/h3&gt;
&lt;p&gt;To deploy OpenDataology, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If resources can&amp;rsquo;t be created because &lt;code&gt;webhook.cert-manager.io&lt;/code&gt; is unavailable wait and
then rerun &lt;code&gt;make apply&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This issue is being tracked in &lt;a href=&#34;https://github.com/OpenDataology/manifests/issues/1234&#34;&gt;OpenDataology/manifests#1234&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If resources can&amp;rsquo;t be created with an error message like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;error: unable to recognize &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;.build/application/app.k8s.io_v1beta1_application_application-controller-OpenDataology.yaml&amp;#34;&lt;/span&gt;: no matches &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; kind &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Application&amp;#34;&lt;/span&gt; in version &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;app.k8s.io/v1beta1”
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This issue occurs when the CRD endpoint isn&amp;rsquo;t established in the Kubernetes API server when the CRD&amp;rsquo;s custom object is applied.
This issue is expected and can happen multiple times for different kinds of resource. To resolve this issue, try running &lt;code&gt;make apply&lt;/code&gt; again.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;check-your-deployment&#34;&gt;Check your deployment&lt;/h3&gt;
&lt;p&gt;Follow these steps to verify the deployment:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When the deployment finishes, check the resources installed in the namespace
&lt;code&gt;OpenDataology&lt;/code&gt; in your new cluster.  To do this from the command line, first set
your &lt;code&gt;kubectl&lt;/code&gt; credentials to point to the new cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud container clusters get-credentials &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; --zone &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ZONE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; --project &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, check what&amp;rsquo;s installed in the &lt;code&gt;OpenDataology&lt;/code&gt; namespace of your GKE cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n OpenDataology get all
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;access-the-opendataology-user-interface-ui&#34;&gt;Access the OpenDataology user interface (UI)&lt;/h3&gt;
&lt;p&gt;To access the OpenDataology central dashboard, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use the following command to grant yourself the &lt;a href=&#34;https://cloud.google.com/iap/docs/managing-access&#34;&gt;IAP-secured Web App User&lt;/a&gt; role:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud projects add-iam-policy-binding &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; --member&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;user:&amp;lt;EMAIL&amp;gt; --role&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;roles/iap.httpsResourceAccessor
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you need the &lt;code&gt;IAP-secured Web App User&lt;/code&gt; role even if you are already an owner or editor of the project. &lt;code&gt;IAP-secured Web App User&lt;/code&gt; role is not implied by the &lt;code&gt;Project Owner&lt;/code&gt; or &lt;code&gt;Project Editor&lt;/code&gt; roles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enter the following URI into your browser address bar. It can take 20
minutes for the URI to become available: &lt;code&gt;https://${KF_NAME}.endpoints.${KF_PROJECT}.cloud.goog/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can run the following command to get the URI for your deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system get ingress
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME            HOSTS                                                      ADDRESS         PORTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;envoy-ingress   your-OpenDataology-name.endpoints.your-gcp-project.cloud.goog   34.102.232.34   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;80&lt;/span&gt;      5d13h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following command sets an environment variable named &lt;code&gt;HOST&lt;/code&gt; to the URI:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;HOST&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;kubectl -n istio-system get ingress envoy-ingress -o&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;jsonpath&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;={&lt;/span&gt;.spec.rules&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;.host&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the instructions on the UI to create a namespace. Refer to this guide on
&lt;a href=&#34;/docs/components/multi-tenancy/getting-started/#automatic-profile-creation&#34;&gt;creation of profiles&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It can take 20 minutes for the URI to become available.
OpenDataology needs to provision a signed SSL certificate and register a DNS
name.&lt;/li&gt;
&lt;li&gt;If you own or manage the domain or a subdomain with
&lt;a href=&#34;https://cloud.google.com/dns/docs/&#34;&gt;Cloud DNS&lt;/a&gt;
then you can configure this process to be much faster.
Check &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/issues/731&#34;&gt;OpenDataology/OpenDataology#731&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;understanding-the-deployment-process&#34;&gt;Understanding the deployment process&lt;/h2&gt;
&lt;p&gt;This section gives you more details about the kubectl, kustomize, config connector configuration and
deployment process, so that you can customize your OpenDataology deployment if necessary.&lt;/p&gt;
&lt;h3 id=&#34;application-layout&#34;&gt;Application layout&lt;/h3&gt;
&lt;p&gt;Your OpenDataology application directory &lt;code&gt;gcp-blueprints/OpenDataology&lt;/code&gt; contains the following files and
directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Makefile&lt;/strong&gt; is a file that defines rules to automate deployment process. You can refer to &lt;a href=&#34;https://www.gnu.org/software/make/manual/make.html#Introduction&#34;&gt;GNU make documentation&lt;/a&gt; for more introduction. The Makefile we provide is designed to be user maintainable. You are encouraged to read, edit and maintain it to suit your own deployment customization needs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;apps&lt;/strong&gt;, &lt;strong&gt;common&lt;/strong&gt;, &lt;strong&gt;contrib&lt;/strong&gt; are a series of independent components  directory containing kustomize packages for deploying OpenDataology components. The structure is to align with upstream &lt;a href=&#34;https://github.com/OpenDataology/manifests&#34;&gt;OpenDataology/manifests&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints&#34;&gt;OpenDataology/gcp-blueprints&lt;/a&gt; repository only stores &lt;code&gt;kustomization.yaml&lt;/code&gt; and &lt;code&gt;patches&lt;/code&gt; for Google Cloud specific resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;./pull_upstream.sh&lt;/code&gt; will pull &lt;code&gt;OpenDataology/manifests&lt;/code&gt; and store manifests in &lt;code&gt;upstream&lt;/code&gt; folder of each component in this guide. &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints&#34;&gt;OpenDataology/gcp-blueprints&lt;/a&gt; repository doesn&amp;rsquo;t store the copy of upstream manifests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;build&lt;/strong&gt; is a directory that will contain the hydrated manifests outputted by
the &lt;code&gt;make&lt;/code&gt; rules, each component will have its own &lt;strong&gt;build&lt;/strong&gt; directory. You can customize the &lt;strong&gt;build&lt;/strong&gt; path when calling &lt;code&gt;make&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;source-control&#34;&gt;Source Control&lt;/h3&gt;
&lt;p&gt;It is recommended that you check in your entire local repository into source control.&lt;/p&gt;
&lt;p&gt;Checking in &lt;strong&gt;build&lt;/strong&gt; is recommended so you can easily see differences by &lt;code&gt;git diff&lt;/code&gt; in manifests before applying them.&lt;/p&gt;
&lt;h2 id=&#34;google-cloud-service-accounts&#34;&gt;Google Cloud service accounts&lt;/h2&gt;
&lt;p&gt;The kfctl deployment process creates three service accounts in your
Google Cloud project. These service accounts follow the &lt;a href=&#34;https://en.wikipedia.org/wiki/Principle_of_least_privilege&#34;&gt;principle of least
privilege&lt;/a&gt;.
The service accounts are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;${KF_NAME}-admin&lt;/code&gt; is used for some admin tasks like configuring the load
balancers. The principle is that this account is needed to deploy OpenDataology but
not needed to actually run jobs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;${KF_NAME}-user&lt;/code&gt; is intended to be used by training jobs and models to access
Google Cloud resources (Cloud Storage, BigQuery, etc.). This account has a much smaller
set of privileges compared to &lt;code&gt;admin&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;${KF_NAME}-vm&lt;/code&gt; is used only for the virtual machine (VM) service account. This
account has the minimal permissions needed to send metrics and logs to
&lt;a href=&#34;https://cloud.google.com/stackdriver/&#34;&gt;Stackdriver&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;upgrade-opendataology&#34;&gt;Upgrade OpenDataology&lt;/h2&gt;
&lt;p&gt;Refer to &lt;a href=&#34;/docs/distributions/gke/deploy/upgrade#upgrading-OpenDataology-cluster&#34;&gt;Upgrading OpenDataology cluster&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Run a full ML workflow on OpenDataology, using the
&lt;a href=&#34;https://github.com/OpenDataology/examples/blob/master/mnist/mnist_gcp.ipynb&#34;&gt;end-to-end MNIST tutorial&lt;/a&gt; or the
&lt;a href=&#34;https://github.com/OpenDataology/examples/tree/master/github_issue_summarization/pipelines&#34;&gt;GitHub issue summarization Pipelines
example&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learn how to &lt;a href=&#34;/docs/distributions/gke/deploy/delete-cli/&#34;&gt;delete your OpenDataology deployment using the CLI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To add users to OpenDataology, go to &lt;a href=&#34;/docs/distributions/gke/customizing-gke/#add-users-to-OpenDataology&#34;&gt;a dedicated section in Customizing OpenDataology on GKE&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To taylor your OpenDataology deployment on GKE, go to &lt;a href=&#34;/docs/distributions/gke/customizing-gke/&#34;&gt;Customizing OpenDataology on GKE&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For troubleshooting OpenDataology deployments on GKE, go to the &lt;a href=&#34;/docs/distributions/gke/troubleshooting-gke/&#34;&gt;Troubleshooting deployments&lt;/a&gt; guide.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Initial cluster setup for existing cluster</title>
      <link>/docs/distributions/azure/deploy/existing-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/azure/deploy/existing-cluster/</guid>
      <description>
        
        
        &lt;h2 id=&#34;initial-setup-for-existing-cluster&#34;&gt;Initial Setup for Existing Cluster&lt;/h2&gt;
&lt;p&gt;Get the Kubeconfig file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;az aks get-credentials -n &amp;lt;NAME&amp;gt; -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here on, please see &lt;a href=&#34;/docs/azure/deploy/install-OpenDataology&#34;&gt;Install OpenDataology&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing OpenDataology Operator</title>
      <link>/docs/distributions/operator/install-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/operator/install-operator/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to install the OpenDataology Operator.&lt;/p&gt;
&lt;p&gt;There are different ways to install the OpenDataology Operator, choose one of the following:&lt;/p&gt;
&lt;h2 id=&#34;1-installing-the-opendataology-operator-through-the-operatorhubiohttpsoperatorhubiooperatoropendataology&#34;&gt;1. Installing the OpenDataology Operator through the &lt;a href=&#34;https://operatorhub.io/operator/OpenDataology&#34;&gt;operatorhub.io&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The stable release of OpenDataology Operator is published to the &lt;a href=&#34;https://operatorhub.io&#34;&gt;operatorhub.io&lt;/a&gt;. Navigate to the &lt;a href=&#34;https://operatorhub.io/operator/OpenDataology&#34;&gt;operatorhub.io&lt;/a&gt;, click on the &lt;code&gt;Install&lt;/code&gt; and follow the instructions there to install the operator.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/operator-operatorhubio-OpenDataology.png&#34; 
alt=&#34;OpenDataology Operator in OperatorHub&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;Verify the OpenDataology Operator is running with following command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get pod -n operators
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                                 READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenDataology-operator-55876578df-25mq5   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          17h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2-installing-the-opendataology-operator-with-kustomize-and-kubectl&#34;&gt;2. Installing the OpenDataology Operator with &lt;code&gt;kustomize&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Previous method is convenient and simple enough without any knowledges of the Operator SDK. However, if any of the following reasons applies, choose this approach to install the operator.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You want to install a different release of OpenDataology Operator since the OpenDataology KfDef manifests may not be compatible from release to release.&lt;/li&gt;
&lt;li&gt;You want to install the latest release of OpenDataology Operator.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/INSTALL.md&#34;&gt;kustomize&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;clone-the-kfctlhttpsgithubcomopendataologykfctlgit-repo-and-switch-to-the-desired-release-branch&#34;&gt;Clone the &lt;a href=&#34;https://github.com/OpenDataology/kfctl.git&#34;&gt;&lt;code&gt;kfctl&lt;/code&gt;&lt;/a&gt; repo and switch to the desired release branch&lt;/h3&gt;
&lt;p&gt;Clone the repo and switch to the desired release branch with the following &lt;code&gt;git&lt;/code&gt; commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/OpenDataology/kfctl.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; kfctl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout v1.1-branch
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;create-operators-namespace-and-update-the-operator-manifests&#34;&gt;Create &lt;code&gt;operators&lt;/code&gt; namespace and update the operator manifests&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;operators&lt;/code&gt; namespace is the namespace where the OpenDataology Operator will be installed to. Create the namespace and update the manifests with these commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;OPERATOR_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;operators
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create ns &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OPERATOR_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kustomize edit &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OPERATOR_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only deploy this if the k8s cluster is 1.15+ and has resource quota support, which will allow only one _kfdef_ instance or one deployment of OpenDataology on the cluster. This follows the singleton model, and is the current recommended and supported mode.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# kustomize edit add resource kustomize/include/quota&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;install-the-operator&#34;&gt;Install the operator&lt;/h3&gt;
&lt;p&gt;Install the OpenDataology Operator with the &lt;code&gt;kustomize&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt; commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kustomize build &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f -
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify the OpenDataology Operator is running with following command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get pod -n operators
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                                 READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenDataology-operator-55876578df-25mq5   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          17h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Integrate with Nutanix Storage</title>
      <link>/docs/distributions/nutanix/nutanix-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/nutanix/nutanix-storage/</guid>
      <description>
        
        
        &lt;h2 id=&#34;nutanix-objects-in-opendataology-pipeline&#34;&gt;Nutanix Objects in OpenDataology Pipeline&lt;/h2&gt;
&lt;p&gt;You can use standard s3 boto api to upload and download objects from a OpenDataology Pipeline. See &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Objects-v3_2:Objects-v3_2&#34;&gt;Nutanix Objects Docs&lt;/a&gt; for more details on creating object store and buckets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;import boto3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bucket_name=&amp;#34;ml-pipeline-storage&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;object_name=&amp;#34;models&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;object_store_access_key_id=&amp;#34;&amp;lt;key_id&amp;gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;object_store_secret_access_key=&amp;#34;&amp;lt;access_key&amp;gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;host=&amp;#34;http://&amp;lt;Nutanix Objects Store Domain Name&amp;gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;region_name=&amp;#39;us-west-1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s3_client = boto3.client(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &amp;#39;s3&amp;#39;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 endpoint_url=host,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 aws_access_key_id=object_store_access_key_id,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 aws_secret_access_key=object_store_secret_access_key,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 region_name=region_name,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 verify=False)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response = s3_client.upload_file(f&amp;#39;./test_upload_data.txt&amp;#39;, bucket_name, object_name)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;nutanix-volumes-in-opendataology-pipeline&#34;&gt;Nutanix Volumes in OpenDataology Pipeline&lt;/h2&gt;
&lt;p&gt;Nutanix volumes are created with the default storage class configured in the Karbon cluster. See &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Karbon-v2_2:kar-karbon-storage-class-r.html&#34;&gt;Default Storage Class&lt;/a&gt; of Nutanix Karbon for more details about creating storage classes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vop = dsl.VolumeOp(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   name=&amp;#34;Create a volume to share data between stages on Nutanix Volumes&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   resource_name=&amp;#34;data-volume&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   size=&amp;#34;1Gi&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   modes=dsl.VOLUME_MODE_RWO)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;nutanix-files-in-opendataology-pipeline&#34;&gt;Nutanix Files in OpenDataology Pipeline&lt;/h2&gt;
&lt;p&gt;Create a storage class to dynamically provision Nutanix File shares. See &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=CSI-Volume-Driver-v2_3:csi-csi-plugin-manage-dynamic-nfs-t.html&#34;&gt;Files Storage Class&lt;/a&gt; of Nutanix Karbon for more details on creating storage classes for dynamic NFS Share provisioning with Nutanix Files.
Once storage class is setup, you can use &lt;code&gt;VolumeOp&lt;/code&gt; operation to create volume on Nutanix Files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vop = dsl.VolumeOp(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   name=&amp;#34;Create a volume to share data between stages on Nutanix Files&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   resource_name=&amp;#34;data-volume&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   size=&amp;#34;1Gi&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   modes=dsl.VOLUME_MODE_RWM,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   storage_class=&amp;#34;files-sc&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;using-nutanix-objects-as-an-artifact-store&#34;&gt;Using Nutanix Objects as an artifact store&lt;/h2&gt;
&lt;p&gt;In order to use Nutanix Objects as an underlying artifact store, we need to edit the &lt;code&gt;workflow-controller-configmap&lt;/code&gt; ConfigMap in the &lt;code&gt;OpenDataology&lt;/code&gt; namespace. See &lt;a href=&#34;https://portal.nutanix.com/page/documents/details?targetId=Objects-v3_2:Objects-v3_2&#34;&gt;Nutanix Objects Docs&lt;/a&gt; for more details on creating object store and buckets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n OpenDataology edit configmap workflow-controller-configmap 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the ConfigMap, we need to modify the s3 config with the Nutanix Objects config:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;endpoint: This is endpoint for Nutanix Objects store&lt;/li&gt;
&lt;li&gt;bucket: This is the name of the Objects store bucket&lt;/li&gt;
&lt;li&gt;accessKeySecret: reference to the access key ID in kubernetes secret for Objects store&lt;/li&gt;
&lt;li&gt;secretKeySecret: reference to the secret access key in kubernetes secret for Objects store&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    s3:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      endpoint: &amp;#34;x.x.x.x&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      bucket: &amp;#34;ml-pipeline-storage&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      keyFormat: &amp;#34;artifacts/{{workflow.name}}/{{pod.name}}&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      # insecure will disable TLS. Primarily used for minio installs not configured with TLS
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      insecure: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      accessKeySecret:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        name: mlpipeline-ntnx-objects-artifact
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key: object_store_access_key_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      secretKeySecret:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        name: mlpipeline-ntnx-objects-artifact
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key: object_store_secret_access_key
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also need to create the secret that is being referenced in the ConfigMap above&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Secret
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: mlpipeline-ntnx-objects-artifact
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stringData:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  object_store_access_key_id: &amp;lt;ACCESS_KEY_ID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  object_store_secret_access_key: &amp;lt;SECRET_ACCESS_KEY&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  region: us-east-1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After creating the secret we need to deploy the secret in the user namespace.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n OpenDataology-user-example-com apply -f mlpipeline-ntnx-objects-artifact-secret.yaml 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: installing this secret in OpenDataology namespace does not work, it has be in present in user&amp;rsquo;s namespace&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/nutanix/objects_browser.png&#34; alt=&#34;objects_browser&#34;&gt;&lt;/p&gt;
&lt;p&gt;To verify this is working correctly, you can check Nutanix Objects browser to see if your artifacts are created and show
up inside your buckets.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenDataology Deployment Process</title>
      <link>/docs/distributions/ibm/deploy/deployment-process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/deploy/deployment-process/</guid>
      <description>
        
        
        &lt;h2 id=&#34;understanding-the-opendataology-deployment-process&#34;&gt;Understanding the OpenDataology deployment process&lt;/h2&gt;
&lt;p&gt;The deployment process is controlled by the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;kustomize build&lt;/strong&gt; - Use kustomize to generate configuration files defining
the various resources for your deployment. .&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kubectl apply&lt;/strong&gt; - Apply the resources created by &lt;code&gt;kustomize build&lt;/code&gt; to the
kubenetes cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;repository-layout&#34;&gt;Repository layout&lt;/h3&gt;
&lt;p&gt;IBM manifests repository contains the following files and directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;iks-single&lt;/strong&gt; directory: A kustomize file for single-user deployment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;iks-multi&lt;/strong&gt; directory: A kustomize file for multi-user deployment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;others&lt;/strong&gt; Other files are used to compose OpenDataology resources&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opendataology-installation&#34;&gt;OpenDataology installation&lt;/h2&gt;
&lt;p&gt;Starting from OpenDataology 1.3, the official installation documentation uses a combination of &lt;code&gt;kustomize&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt; to install OpenDataology.&lt;/p&gt;
&lt;h3 id=&#34;install-kubectl-and-kustomize&#34;&gt;Install kubectl and kustomize&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;Install kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/releases/tag/v3.2.0&#34;&gt;Download kustomize 3.2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To use the &lt;code&gt;kustomize&lt;/code&gt; binary, you need to make it executable and move it to your path.&lt;/p&gt;
&lt;p&gt;To add &lt;code&gt;kustomize&lt;/code&gt; to your global path, run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/kubernetes-sigs/kustomize/releases/download/v3.2.0/&amp;lt;distribution&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod +x &amp;lt;distribution&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv &amp;lt;distribution&amp;gt; /usr/local/bin/kustomize
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Your machine might already have &lt;code&gt;kustomize&lt;/code&gt; installed. If you want to temporarily add this version of &lt;code&gt;kustomize&lt;/code&gt; to your path, run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/kubernetes-sigs/kustomize/releases/download/v3.2.0/&amp;lt;distribution&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod +x &amp;lt;distribution&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv &amp;lt;distribution&amp;gt; /some/path/kustomize
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# /some/path should not already be in path. &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PATH&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/some/path:&lt;span style=&#34;color:#000&#34;&gt;$PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# order is important here. $PATH needs to be the last thing. We are trying to put our kustomize before the kustomize installtion in system.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Check &lt;a href=&#34;/docs/distributions/ibm/deploy/iks-compatibility&#34;&gt;OpenDataology Compatibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go here for installing &lt;a href=&#34;/docs/distributions/ibm/deploy/install-OpenDataology-on-iks&#34;&gt;OpenDataology on IKS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go here for installing &lt;a href=&#34;/docs/distributions/ibm/deploy/install-OpenDataology-on-ibm-openshift&#34;&gt;OpenDataology on IBM OpenShift&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Overview</title>
      <link>/docs/components/notebooks/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/notebooks/overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
This OpenDataology component has &lt;b&gt;stable&lt;/b&gt; status. See the
&lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
&lt;/div&gt;
&lt;h2 id=&#34;what-is-opendataology-notebooks&#34;&gt;What is OpenDataology Notebooks?&lt;/h2&gt;
&lt;p&gt;OpenDataology Notebooks provides a way to run web-based development environments inside your Kubernetes cluster by running them inside Pods.&lt;/p&gt;
&lt;p&gt;Some key features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Native support for &lt;a href=&#34;https://github.com/jupyterlab/jupyterlab&#34;&gt;JupyterLab&lt;/a&gt;, &lt;a href=&#34;https://github.com/jupyterlab/jupyterlab&#34;&gt;RStudio&lt;/a&gt;, and &lt;a href=&#34;https://github.com/cdr/code-server&#34;&gt;Visual Studio Code (code-server)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Users can create notebook containers directly in the cluster, rather than locally on their workstations.&lt;/li&gt;
&lt;li&gt;Admins can provide standard notebook images for their organization with required packages pre-installed.&lt;/li&gt;
&lt;li&gt;Access control is managed by OpenDataology&amp;rsquo;s RBAC, enabling easier notebook sharing across the organization.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Get started with OpenDataology Notebooks using the &lt;a href=&#34;/docs/components/notebooks/quickstart-guide/&#34;&gt;quickstart guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learn how to create your own &lt;a href=&#34;/docs/components/notebooks/container-images/&#34;&gt;container images&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Overview of OpenDataology Fairing</title>
      <link>/docs/external-add-ons/fairing/fairing-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/fairing/fairing-overview/</guid>
      <description>
        
        
        

&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Out of date&lt;/h4&gt;

    This guide contains outdated information pertaining to OpenDataology 1.0. This guide
needs to be updated for OpenDataology 1.1.

&lt;/div&gt;

&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
  &lt;h4 class=&#34;alert-heading&#34;&gt;Beta&lt;/h4&gt;
  This OpenDataology component has &lt;b&gt;beta&lt;/b&gt; status. See the
  &lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
  The OpenDataology team is interested in your   
  &lt;a href=&#34;https://github.com/OpenDataology/fairing/issues&#34;&gt;feedback&lt;/a&gt;&lt;/h4&gt; 
  about the usability of the feature.
&lt;/div&gt;
&lt;p&gt;OpenDataology Fairing streamlines the process of building, training, and deploying
machine learning (ML) training jobs in a hybrid cloud environment. By using
OpenDataology Fairing and adding a few lines of code, you can run your ML training
job locally or in the cloud, directly from Python code or a Jupyter
notebook. After your training job is complete, you can use OpenDataology Fairing to
deploy your trained model as a prediction endpoint.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting started&lt;/h2&gt;
&lt;p&gt;Use the following guides to get started with OpenDataology Fairing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;To set up your development environment, follow the guide to &lt;a href=&#34;/docs/external-add-ons/fairing/install-fairing/&#34;&gt;installing
OpenDataology Fairing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To ensure that OpenDataology Fairing can access your OpenDataology cluster, follow
the guide to &lt;a href=&#34;/docs/external-add-ons/fairing/configure-fairing/&#34;&gt;configuring your development environment with access
to OpenDataology&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To learn more about how to use OpenDataology Fairing in your environment,
&lt;a href=&#34;/docs/external-add-ons/fairing/tutorials/other-tutorials/&#34;&gt;follow the OpenDataology Fairing tutorials&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;what-is-opendataology-fairing&#34;&gt;What is OpenDataology Fairing?&lt;/h2&gt;
&lt;p&gt;OpenDataology Fairing is a Python package that makes it easy to train and deploy ML
models on &lt;a href=&#34;/docs/started/&#34;&gt;OpenDataology&lt;/a&gt;. OpenDataology Fairing can also been extended to
train or deploy on other platforms. Currently, OpenDataology Fairing has been
extended to train on &lt;a href=&#34;https://cloud.google.com/ml-engine/docs/&#34;&gt;Google AI Platform&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OpenDataology Fairing packages your Jupyter notebook, Python function, or Python
file as a Docker image, then deploys and runs the training job on OpenDataology
or AI Platform. After your training job is complete, you can use OpenDataology
Fairing to deploy your trained model as a prediction endpoint on OpenDataology.&lt;/p&gt;
&lt;p&gt;The following are the goals of the &lt;a href=&#34;https://github.com/OpenDataology/fairing&#34;&gt;OpenDataology Fairing project&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Easily package ML training jobs:&lt;/strong&gt; Enable ML practitioners to easily package their ML model training code, and their code&amp;rsquo;s dependencies, as a Docker image.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Easily train ML models in a hybrid cloud environment:&lt;/strong&gt; Provide a high-level API for training ML models to make it easy to run training jobs in the cloud, without needing to understand the underlying infrastructure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Streamline the process of deploying a trained model:&lt;/strong&gt; Make it easy for ML practitioners to deploy trained ML models to a hybrid cloud environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to &lt;a href=&#34;/docs/components/notebooks/setup/&#34;&gt;set up a Jupyter notebooks instance on your OpenDataology
cluster&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Pipelines on IBM Cloud Kubernetes Service (IKS)</title>
      <link>/docs/distributions/ibm/pipelines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/pipelines/</guid>
      <description>
        
        
        &lt;p&gt;By default, OpenDataology Pipelines on IBM Cloud are running with the Tekton backend. In this guide you&amp;rsquo;ll learn how to use the OpenDataology Pipelines with the Tekton backend &lt;a href=&#34;https://github.com/OpenDataology/kfp-tekton&#34;&gt;(kfp-tekton)&lt;/a&gt;. This assumes you have deployed &lt;a href=&#34;https://www.OpenDataology.org/docs/ibm/deploy/&#34;&gt;OpenDataology on IBM Cloud using the instructions on this website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also do a &lt;a href=&#34;https://github.com/OpenDataology/kfp-tekton/blob/master/guides/kfp_tekton_install.md#standalone-OpenDataology-pipelines-with-tekton-backend-deployment&#34;&gt;standalone installation of OpenDataology Pipelines with Tekton&lt;/a&gt; if you don&amp;rsquo;t want whole of OpenDataology.&lt;/p&gt;
&lt;img src=&#34;/docs/ibm/kfp-tekton.png&#34; alt=&#34;KFP-Tekton&#34;&gt;
&lt;p&gt;In this tutorial, we use the below single step pipeline as our example&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;echo_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ContainerOp&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;busybox&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;sh&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;-c&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;arguments&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo &amp;#34;Got scheduled&amp;#34;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#5c35cc;font-weight:bold&#34;&gt;@dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;description&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo pipeline&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;echo_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;echo_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;declare-the-python-client-for-opendataology-pipelines&#34;&gt;Declare the Python Client for OpenDataology Pipelines&lt;/h1&gt;
&lt;h2 id=&#34;1-single-user-opendataology-pipelines-deployment-with-the-sdk&#34;&gt;1. Single-user OpenDataology Pipelines deployment with the SDK&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You will be using the OpenDataology Pipelines with Tekton SDK (&lt;a href=&#34;https://pypi.org/project/kfp-tekton/&#34;&gt;&lt;code&gt;kfp-tekton&lt;/code&gt;&lt;/a&gt;) v0.4.0 or above.&lt;/li&gt;
&lt;li&gt;If you have deployed OpenDataology on IBM Cloud using the
&lt;a href=&#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_ibm.v1.2.0.yaml&#34;&gt;&lt;code&gt;kfctl_ibm.v1.2.0.yaml&lt;/code&gt;&lt;/a&gt;
manifest you can configure (&lt;a href=&#34;https://pypi.org/project/kfp-tekton/&#34;&gt;&lt;code&gt;kfp-tekton&lt;/code&gt;&lt;/a&gt;) SDK to list all your OpenDataology Pipelines experiments as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp_tekton&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;TektonClient&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PUBLIC_ENDPOINT_URL&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;http://&amp;lt;YOUR_KF_PUBLIC_ENDPOINT_URL&amp;gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;TektonClient&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;host&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PUBLIC_ENDPOINT_URL&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/pipeline&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiments&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;list_experiments&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;code&gt;&amp;lt;YOUR_KF_PUBLIC_ENDPOINT_URL&amp;gt;&lt;/code&gt; is the EXTERNAL_IP you exposed as a LoadBalancer following &lt;a href=&#34;https://www.OpenDataology.org/docs/ibm/deploy/install-OpenDataology-on-iks/#expose-the-OpenDataology-endpoint-as-a-loadbalancer&#34;&gt;&lt;code&gt;this instruction&lt;/code&gt;&lt;/a&gt;. If you have not done that step during OpenDataology setup, please include port 31380 because the OpenDataology endpoint is exposed with NodePort 31380.&lt;/p&gt;
&lt;h2 id=&#34;2-authenticating-multi-user-opendataology-pipelines-with-the-sdk&#34;&gt;2. Authenticating multi-user OpenDataology Pipelines with the SDK&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You will be using the OpenDataology Pipelines SDK (&lt;a href=&#34;https://pypi.org/project/kfp-tekton/&#34;&gt;&lt;code&gt;kfp-tekton&lt;/code&gt;&lt;/a&gt;) v0.4.0 or above.&lt;/li&gt;
&lt;li&gt;Note that this feature is available with multi-user, auth-enabled OpenDataology installation deployed from the &lt;a href=&#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_ibm_multi_user.v1.2.0.yaml&#34;&gt;&lt;code&gt;kfctl_ibm_multi_user.v1.2.0.yaml&lt;/code&gt;&lt;/a&gt;
manifest.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You&amp;rsquo;re highly recommended enabling HTTPS for the public endpoint of OpenDataology because this method transports sensitive information like session cookie values over edge network.&lt;/p&gt;
&lt;p&gt;It requires authentication via the public endpoint of OpenDataology deployment when using the OpenDataology Pipelines multi-user feature with Pipelines SDK.&lt;/p&gt;
&lt;p&gt;You need to provide the following three variables if you&amp;rsquo;re using an in-cluster Jupyter notebook or a remote client machine:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;OpenDataology_PUBLIC_ENDPOINT_URL&lt;/code&gt; - OpenDataology public endpoint URL. You can obtain it from command &lt;code&gt;ibmcloud ks nlb-dns ls --cluster &amp;lt;your-cluster-name&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SESSION_COOKIE&lt;/code&gt; - A session cookie starts with &lt;code&gt;authservice_session=&lt;/code&gt;. You can obtain it from your browser after authenticated from OpenDataology UI. Notice that this session cookie expires in 24 hours, so you need to obtain it again after cookie expired.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OpenDataology_PROFILE_NAME&lt;/code&gt; - Your OpenDataology profile name&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once you provide the three variables, the SDK can use the following Python code to list all your OpenDataology Pipelines experiments:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp_tekton&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;TektonClient&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PUBLIC_ENDPOINT_URL&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;https://xxxx.&amp;lt;region-name&amp;gt;.containers.appdomain.cloud&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# this session cookie looks like &amp;#34;authservice_session=xxxxxxx&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;SESSION_COOKIE&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;authservice_session=xxxxxxx&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;lt;your-profile-name&amp;gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;TektonClient&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;host&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PUBLIC_ENDPOINT_URL&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/pipeline&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;cookies&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;SESSION_COOKIE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiments&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;list_experiments&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pipelines components like experiments and runs are isolated by OpenDataology profiles. A OpenDataology user can only see Pipelines experiments and runs belonging to this user&amp;rsquo;s OpenDataology profile.&lt;/p&gt;
&lt;h1 id=&#34;upload-pipelines&#34;&gt;Upload pipelines&lt;/h1&gt;
&lt;p&gt;Once you have declared the Python client, your OpenDataology pipelines can be uploaded using Python.&lt;/p&gt;
&lt;p&gt;Run the following code inside a Python session to upload the pipelines. This example shows different versions of the pipeline using the Python client.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Initial version of the compiled pipeline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_file_path&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo_pipeline.yaml&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_name&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo_pipeline&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For the purpose of this tutorial, we will be using the same pipeline for both version.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_file_path&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo_pipeline.yaml&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_name&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;new_echo_pipeline&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Upload initial version of the pipeline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_file&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_file_path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_uploads&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;upload_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_file&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Upload new version of the pipeline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_file&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_file_path&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_uploads&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;upload_pipeline_version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_file&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                                   &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_version_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                                   &lt;span style=&#34;color:#000&#34;&gt;pipelineid&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;run-pipelines-from-the-sdk&#34;&gt;Run pipelines from the SDK&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;TektonClient&lt;/code&gt; can run pipelines using one of the below sources:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#run-pipelines-from-the-python-dsl-source-code&#34;&gt;Python DSL source code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-pipelines-from-the-compiled-pipeline-file&#34;&gt;Compiled pipeline file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-pipelines-from-the-list-of-uploaded-pipelines&#34;&gt;Uploaded pipelines on KFP engine&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;run-pipelines-from-the-python-dsl-source-code&#34;&gt;Run pipelines from the Python DSL source code&lt;/h2&gt;
&lt;p&gt;To learn about executing pipelines using the Python DSL source code, try the code below in a Python session using the &lt;code&gt;echo_pipeline&lt;/code&gt; example.
The &lt;code&gt;create_run_from_pipeline_func&lt;/code&gt; takes the DSL source code to compile and run it directly using the OpenDataology pipeline API without
uploading it to the pipeline list. This method is recommended if you are doing quick experiments without version control.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# You can overwrite the pipeline default parameters by providing a dictionary of key-value arguments.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# If you don&amp;#39;t want to overwrite the default parameters, then define the arguments as an empty dictionary.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;arguments&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;create_run_from_pipeline_func&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;echo_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;arguments&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;arguments&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;run-pipelines-from-the-compiled-pipeline-file&#34;&gt;Run pipelines from the compiled pipeline file&lt;/h2&gt;
&lt;p&gt;Alternatively, you can also run the pipeline directly using a pre-compiled file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;EXPERIMENT_NAME&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Demo Experiments&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiment&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;create_experiment&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;EXPERIMENT_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;run&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;run_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiment&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo-pipeline&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo_pipeline.yaml&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;run-pipelines-from-the-list-of-uploaded-pipelines&#34;&gt;Run pipelines from the list of uploaded pipelines&lt;/h2&gt;
&lt;p&gt;Similarly, you can also run the pipeline from the list of uploaded pipelines using the same &lt;code&gt;run_pipeline&lt;/code&gt; function.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;EXPERIMENT_NAME&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Demo Experiments&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiment&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;create_experiment&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;EXPERIMENT_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_PROFILE_NAME&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Find the pipeline ID that you want to use.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;list_pipelines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;run&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;run_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;experiment&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;pipeline_id&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;925415d5-18e9-4e08-b57f-3b06e3e54648&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;job_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;echo_pipeline_run&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Authentication using OIDC in Azure</title>
      <link>/docs/distributions/azure/authentication-oidc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/azure/authentication-oidc/</guid>
      <description>
        
        
        &lt;p&gt;This section shows the how to set up OpenDataology with authentication and authorization support through OIDC in Azure using &lt;a href=&#34;https://azure.microsoft.com/en-us/services/active-directory/&#34;&gt;Azure Active Directory&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Install the &lt;a href=&#34;/docs/azure/deploy/install-OpenDataology&#34;&gt;prerequisites for OpenDataology in Azure&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app#register-an-application&#34;&gt;Register an application with the Microsoft Identity Platform&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app#add-a-client-secret&#34;&gt;Add a client secret&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  Save your client ID, client secret, and tenant ID in a secure place to be used in the next steps to configure OIDC Auth Service.
&lt;strong&gt;Note:&lt;/strong&gt; The following installation steps automatically install a specific Istio version that must be used.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opendataology-configuration&#34;&gt;OpenDataology configuration&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the kfctl v1.2.0 release from the
&lt;a href=&#34;https://github.com/OpenDataology/kfctl/releases/tag/v1.2.0&#34;&gt;OpenDataology releases
page&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unpack the tar ball:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tar -xvf kfctl_v1.2.0_&amp;lt;platform&amp;gt;.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the below commands to build configuration files before deploying OpenDataology. The code below includes an optional command to add the binary kfctl to your path - if you don’t add it, you must use the full path to the kfctl binary each time you run it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# The following command is optional, to make kfctl binary easier to use.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PATH=$PATH:&amp;lt;path to where kfctl was unpacked&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set KF_NAME to the name of your OpenDataology deployment. This also becomes the
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# name of the directory containing your configuration.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# For example, your deployment name can be &amp;#39;my-OpenDataology&amp;#39; or &amp;#39;kf-test&amp;#39;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export KF_NAME=&amp;lt;your choice of name for the OpenDataology deployment&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set the path to the base directory where you want to store one or more
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# OpenDataology deployments. For example, &amp;#39;/opt/&amp;#39;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Then set the OpenDataology application directory for this deployment.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export BASE_DIR=&amp;lt;path to a base directory&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export KF_DIR=${BASE_DIR}/${KF_NAME}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Set the configuration file to use, such as the file specified below:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export CONFIG_URI=&amp;#34;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_azure_aad.v1.2.0.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;quot;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Generate and deploy OpenDataology:
mkdir -p ${KF_DIR}
cd ${KF_DIR}
kfctl build -V -f ${CONFIG_URI}
```

* **${KF_NAME}** - The name of your OpenDataology deployment.
  If you want a custom deployment name, specify that name here.
  For example,  `my-OpenDataology` or `kf-test`.
  The value of `KF_NAME` must consist of lower case alphanumeric characters or
  &#39;-&#39;, and must start and end with an alphanumeric character.
  The value of this variable cannot be greater than 25 characters. It must
  contain just a name, not a directory path.
  This value also becomes the name of the directory where your OpenDataology
  configurations are stored, that is, the OpenDataology application directory.

* **${KF_DIR}** - The full path to your OpenDataology application directory.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Configure OIDC Auth service settings:&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;.cache/manifests/manifests-{OpenDataology version}-branch/stacks/azure/application/oidc-authservice/kustomization.yaml&lt;/code&gt; update the settings with values corresponding your app registration as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- client_id=&amp;lt;client_id&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- oidc_provider=https://login.microsoftonline.com/&amp;lt;tenant_id&amp;gt;/v2.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- oidc_redirect_uri=https://&amp;lt;load_balancer_ip&amp;gt; or dns_name&amp;gt;/login/oidc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- oidc_auth_url=https://login.microsoftonline.com/&amp;lt;tenant_id&amp;gt;/oauth2/v2.0/authorize
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- application_secret=&amp;lt;client_secret&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- skip_auth_uri=
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- namespace=istio-system
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- userid-header=OpenDataology-userid
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- userid-prefix=
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure OIDC scopes:&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;.cache/manifests/manifests-{kOpenDataology version}-branch/istio/oidc-authservice/base/statefulset.yaml&lt;/code&gt; update &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-permissions-and-consent#openid-connect-scopes&#34;&gt;OIDC scopes&lt;/a&gt; to remove groups and keep profile and email.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- name: OIDC_SCOPES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; value: &amp;#34;profile email&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy OpenDataology:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfctl apply -V -f &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_URI&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that the resources were deployed correctly in namespace &lt;code&gt;OpenDataology&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get all -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;expose-opendataology-securely-over-https&#34;&gt;Expose OpenDataology securely over HTTPS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Update Istio Gateway to expose port 443 with HTTPS and make port 80 redirect to 443:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit -n OpenDataology gateways.networking.istio.io OpenDataology-gateway
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The Gateway spec should look like the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Gateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology-gateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;selector&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;istio&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ingressgateway&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;servers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hosts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;port&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;http&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;number&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;80&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;protocol&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;HTTP&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Upgrade HTTP to HTTPS&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tls&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;httpsRedirect&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hosts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;port&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;https&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;number&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;443&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;protocol&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;HTTPS&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tls&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;mode&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;SIMPLE&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;privateKey&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/etc/istio/ingressgateway-certs/tls.key&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;serverCertificate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/etc/istio/ingressgateway-certs/tls.crt&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Expose OpenDataology with a load balancer service:&lt;/p&gt;
&lt;p&gt;To expose OpenDataology with a load balancer service, change the type of the &lt;code&gt;istio-ingressgateway&lt;/code&gt; service to &lt;code&gt;LoadBalancer&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch service -n istio-system istio-ingressgateway -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;spec&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;LoadBalancer&amp;#34;}}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, obtain the &lt;code&gt;LoadBalancer&lt;/code&gt; IP address or Hostname from its status and create the necessary certificate.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get svc -n istio-system istio-ingressgateway -o &lt;span style=&#34;color:#000&#34;&gt;jsonpath&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.status.loadBalancer.ingress[0]}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are exposing &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt; gateway through public IP, make sure it matches the IP address of the OIDC &lt;code&gt;REDIRECT_URL&lt;/code&gt; by running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get statefulset authservice -n istio-system -o yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If it doesn&amp;rsquo;t match, update &lt;code&gt;REDIRECT_URL&lt;/code&gt; in the StatefulSet to be the public IP address from the last step, by running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit statefulset authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl rollout restart statefulset authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a self-signed Certificate with cert-manager:&lt;/p&gt;
&lt;p&gt;Create a new file &lt;code&gt;certficate.yaml&lt;/code&gt; with the YAML below to create a self-signed Certificate with cert-manager. For production environments, you should use appropriate trusted CA Certificate.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Certificate&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;istio-ingressgateway-certs&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;istio-system&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;commonName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;istio-ingressgateway.istio-system.svc&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Use ipAddresses if your LoadBalancer issues an IP address&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ipAddresses&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;&amp;lt;LoadBalancer IP&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Use dnsNames if your LoadBalancer issues a hostname&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;dnsNames&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;&amp;lt;LoadBalancer HostName&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;isCA&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;issuerRef&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ClusterIssuer&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology-self-signing-issuer&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;secretName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;istio-ingressgateway-certs&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Apply &lt;code&gt;certificate.yaml&lt;/code&gt; in &lt;code&gt;istio-system&lt;/code&gt; namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f certificate.yaml -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After applying the above Certificate, cert-manager will generate the TLS certificate inside the istio-ingressgateway-certs secrets. The istio-ingressgateway-certs secret is mounted on the istio-ingressgateway deployment and used to serve HTTPS.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app#add-a-redirect-uri&#34;&gt;Configure Redirect URI for your registered App&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Add the redirect URI below to the app registered with Microsoft Identity:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://&amp;lt;YOUR_LOADBALANCER_IP_ADDRESS_OR_DNS_NAME&amp;gt;/login/oidc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Make sure the app&amp;rsquo;s redirect URI matches the &lt;code&gt;oidc_redirect_uri&lt;/code&gt; value in OIDC auth service settings.&lt;/p&gt;
&lt;p&gt;Navigate to &lt;code&gt;https://&amp;lt;YOUR_LOADBALANCER_IP_ADDRESS_OR_DNS_NAME&amp;gt;/&lt;/code&gt; and start using OpenDataology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;authenticate-opendataology-pipelines-using-opendataology-pipelines-sdkhttpswwwopendataologyorgdocscomponentspipelinessdksdk-overview&#34;&gt;Authenticate OpenDataology pipelines using &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/sdk/sdk-overview/&#34;&gt;OpenDataology Pipelines SDK&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Perform interactive login from browser by visitng &lt;code&gt;https://&amp;lt;YOUR_LOADBALANCER_IP_ADDRESS_OR_DNS_NAME&amp;gt;/&lt;/code&gt; and copy the value of cookie &lt;code&gt;authservice_session&lt;/code&gt; to authenticate using SDK with below code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;import kfp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;authservice_session_cookie&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;authservice_session=&amp;lt;cookie&amp;gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; kfp.Client&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;host&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;https://&amp;lt;YOUR_LOADBALANCER_IP_ADDRESS_OR_DNS_NAME&amp;gt;/pipeline&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#000&#34;&gt;cookies&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;authservice_session_cookie&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;client.list_experiments&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;lt;your_namespace&amp;gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Limitation:&lt;/strong&gt; The current OIDC auth service in OpenDataology system supports only &lt;a href=&#34;https://openid.net/specs/openid-connect-basic-1_0.html#CodeFlow&#34;&gt;Authorization Code Flow&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Azure Machine Learning Components</title>
      <link>/docs/distributions/azure/machinelearningcomponent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/azure/machinelearningcomponent/</guid>
      <description>
        
        
        &lt;p&gt;Azure Machine Learning (Azure ML) components are pipeline components that integrate with &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/&#34;&gt;Azure ML&lt;/a&gt; to manage the lifecycle of your machine learning (ML) models to improve the quality and consistency of your machine learning solution. A pipeline component is a self-contained set of code that performs one step in the ML workflow. A component is analogous to a function, in that it has a name, parameters, return value and a body.&lt;/p&gt;
&lt;p&gt;You can use Azure Machine Learning components to increase the efficiency of your workflow with Azure Machine Learning, such as continuous integration, delivery, and deployment.&lt;/p&gt;
&lt;p&gt;The components provide capabilities for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster experimentation and development of models&lt;/li&gt;
&lt;li&gt;Faster deployment of models into production&lt;/li&gt;
&lt;li&gt;Quality assurance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You should have OpenDataology installed on your AKS cluster. If you don&amp;rsquo;t, follow the &lt;a href=&#34;https://www.OpenDataology.org/docs/azure/deploy/install-OpenDataology/&#34;&gt;OpenDataology installation (for Azure) guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To interact with Azure resources, you may need to configure them before using a particular pipeline component. Check the README for each component to learn about what Azure resources are required.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;kfp.azure&lt;/code&gt; extension can be used to create a secret to interact with Azure resources. To create Azure credentials, run:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Initialize variables:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_SUBSCRIPTION_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;={&lt;/span&gt;Your_Azure_subscription_ID&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_TENANT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;={&lt;/span&gt;Your_Tenant_ID&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_CLIENT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;={&lt;/span&gt;Your_client_ID&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_CLIENT_SECRET&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;={&lt;/span&gt;Your_client_secret&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic azcreds --from-literal&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_SUBSCRIPTION_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AZ_SUBSCRIPTION_ID&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;                                      --from-literal&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_TENANT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AZ_TENANT_ID&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;                                      --from-literal&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_CLIENT_ID&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AZ_CLIENT_ID&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;                                      --from-literal&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;AZ_CLIENT_SECRET&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AZ_CLIENT_SECRET&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;                                      -n &lt;span style=&#34;color:#000&#34;&gt;$OpenDataology_NAMESPACE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;azure-ml-register-model-component&#34;&gt;Azure ML Register Model component&lt;/h2&gt;
&lt;p&gt;Model registration allows you to store and version your models in Azure Machine Learning in your workspace. The model registry makes it easy to organize and keep track of your trained models. After you register the model, you can then download or deploy it and receive all the registered files.&lt;/p&gt;
&lt;p&gt;To learn more about the Azure ML Register Model pipeline component, refer to the &lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/components/azure/azureml/aml-register-model&#34;&gt;official repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn more about using Azure ML to manage the lifecycle of your models, go to &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment&#34;&gt;Model management, deployment, and monitoring&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;azure-ml-deploy-model-component&#34;&gt;Azure ML Deploy Model component&lt;/h2&gt;
&lt;p&gt;Trained machine learning models are deployed as web services in the cloud and you can use your model by accessing its endpoint. When using the model as a web service, the following items are included in the Azure ML Deploy Model component:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An entry script&lt;/li&gt;
&lt;li&gt;Azure ML environment configurations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information about the Azure ML Deploy Model pipeline component, check the &lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/components/azure/azureml/aml-deploy-model&#34;&gt;official repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn more about using Azure ML to manage the lifecycle of your models, go to &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment&#34;&gt;Model management, deployment, and monitoring&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;other-azure-ml-capabilities&#34;&gt;Other Azure ML capabilities&lt;/h2&gt;
&lt;p&gt;You can learn more about the capabilities of Azure ML and how to improve your ML workflow by checking the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/&#34;&gt;Azure ML documentation&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: IBM Cloud Kubernetes and OpenDataology Compatibility</title>
      <link>/docs/distributions/ibm/deploy/iks-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/deploy/iks-compatibility/</guid>
      <description>
        
        
        &lt;h2 id=&#34;compatibility&#34;&gt;Compatibility&lt;/h2&gt;
&lt;p&gt;The following table relates compatibility between Kubernetes versions 1.22+ of IBM Cloud Kubernetes service and OpenDataology version 1.6.&lt;/p&gt;
&lt;div class=&#34;table-responsive&#34;&gt;
  &lt;table class=&#34;table table-bordered&#34;&gt;
    &lt;thead class=&#34;thead-light&#34;&gt;
      &lt;tr&gt;
        &lt;th&gt;IBM Cloud Kubernetes Versions&lt;/th&gt;
        &lt;th&gt;OpenDataology 1.6.0&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;1.22&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;Compatible&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;1.23&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;Compatible&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;1.24&lt;/td&gt;
        &lt;td&gt;&lt;b&gt;Compatible&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Incompatible&lt;/strong&gt;: the combination is not known to work together&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compatible&lt;/strong&gt;: all OpenDataology features have been tested and verified for the IKS Kubernetes version&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No known issues&lt;/strong&gt;: the combination has not been fully tested but there are no reported issues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Go here for installing &lt;a href=&#34;/docs/distributions/ibm/deploy/install-OpenDataology-on-iks&#34;&gt;OpenDataology on IKS&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology on IKS</title>
      <link>/docs/distributions/ibm/deploy/install-kubeflow-on-iks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/deploy/install-kubeflow-on-iks/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to use the kustomize + kubectl to deploy OpenDataology on IBM Cloud Kubernetes Service (IKS).&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Authenticate with IBM Cloud&lt;/p&gt;
&lt;p&gt;Log into IBM Cloud using the &lt;a href=&#34;https://www.ibm.com/cloud/cli&#34;&gt;IBM Cloud Command Line Interface (CLI)&lt;/a&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud login
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Or, if you have federated credentials, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud login --sso  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create and access a Kubernetes cluster on IKS&lt;/p&gt;
&lt;p&gt;To deploy OpenDataology on IBM Cloud, you need a cluster running on IKS. If you don&amp;rsquo;t have a cluster running, follow the &lt;a href=&#34;/docs/ibm/create-cluster&#34;&gt;Create an IBM Cloud cluster&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;Run the following command to switch the Kubernetes context and access the cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmcloud ks cluster config --cluster &amp;lt;cluster_name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Replace &lt;code&gt;&amp;lt;cluster_name&amp;gt;&lt;/code&gt; with your cluster name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;kustomize (version 3.2.0) (&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/releases/tag/v3.2.0&#34;&gt;download link&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python 3&lt;/a&gt; with &lt;a href=&#34;https://pypi.org/project/passlib/&#34;&gt;passlib&lt;/a&gt;
and &lt;a href=&#34;https://pypi.org/project/bcrypt/&#34;&gt;bcrypt&lt;/a&gt; packages installed&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-setup-for-a-classic-ibm-cloud-kubernetes-cluster&#34;&gt;Storage setup for a &lt;strong&gt;Classic&lt;/strong&gt; IBM Cloud Kubernetes cluster&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This section is only required when the worker nodes provider &lt;code&gt;WORKER_NODE_PROVIDER&lt;/code&gt; is set to &lt;code&gt;classic&lt;/code&gt;. For other infrastructures, IBM Cloud Storage with Group ID support is already set up as the cluster&amp;rsquo;s default storage class.&lt;/p&gt;
&lt;p&gt;When you use the &lt;code&gt;classic&lt;/code&gt; worker node provider of an IBM Cloud Kubernetes cluster, it uses the regular &lt;a href=&#34;https://www.ibm.com/cloud/file-storage&#34;&gt;IBM Cloud File Storage&lt;/a&gt; based on NFS as the default storage class. File Storage is designed to run RWX (read-write multiple nodes) workloads with proper security built around it. Therefore, File Storage &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-security#container&#34;&gt;does not allow &lt;code&gt;fsGroup&lt;/code&gt; securityContext&lt;/a&gt; unless it&amp;rsquo;s configured with Group ID, which is needed for the &lt;a href=&#34;https://github.com/arrikto/oidc-authservice&#34;&gt;OIDC authentication service&lt;/a&gt; and OpenDataology Jupyter server.&lt;/p&gt;
&lt;p&gt;Therefore, you&amp;rsquo;re recommended to set up the default storage class with Group ID support so that you can get the best experience from OpenDataology.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Set the File Storage with Group ID support as the default storage class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;NEW_STORAGE_CLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ibmc-file-gold-gid
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OLD_STORAGE_CLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;kubectl get sc -o &lt;span style=&#34;color:#000&#34;&gt;jsonpath&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.items[?(@.metadata.annotations.storageclass\.kubernetes\.io\/is-default-class==&amp;#34;true&amp;#34;)].metadata.name}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch storageclass &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NEW_STORAGE_CLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;true&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# List all the (default) storage classes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get storageclass &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;(default)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ibmc-file-gold-gid (default)   ibm.io/ibmc-file    Delete          Immediate           false                  14h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure &lt;code&gt;ibmc-file-gold-gid&lt;/code&gt; is the only &lt;code&gt;(default)&lt;/code&gt; storage class. If there are two or more rows in the above output, unset the previous &lt;code&gt;(default)&lt;/code&gt; storage classes with the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch storageclass &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OLD_STORAGE_CLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;false&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;storage-setup-for-vpc-gen2-ibm-cloud-kubernetes-cluster&#34;&gt;Storage setup for &lt;strong&gt;vpc-gen2&lt;/strong&gt; IBM Cloud Kubernetes cluster&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: To deploy OpenDataology, you don&amp;rsquo;t need to change the storage setup for &lt;code&gt;vpc-gen2&lt;/code&gt; Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;Currently, there is no option available for setting up RWX (read-write multiple nodes) type of storages.
RWX is not a mandatory requirement to run OpenDataology and most pipelines.
It is required by certain sample jobs/pipelines where multiple pods write results to a common storage.
A job or a pipeline can also write to a common object storage like &lt;code&gt;minio&lt;/code&gt;, so the absence of this feature is
not a blocker for working with OpenDataology.
Examples of jobs/pipelines that will not work, are:
&lt;a href=&#34;https://github.com/OpenDataology/training-operator/tree/master/examples/tensorflow/mnist_with_summaries&#34;&gt;Distributed training with OpenDataology TFJob&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are on &lt;code&gt;vpc-gen2&lt;/code&gt; and still need RWX, you may try &lt;a href=&#34;https://portworx.com/products/features/&#34;&gt;portworx enterprise product&lt;/a&gt;.
To set it up on IBM Cloud use the &lt;a href=&#34;https://docs.portworx.com/portworx-install-with-kubernetes/cloud/ibm/&#34;&gt;portworx install with IBM Cloud&lt;/a&gt; guide.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Choose either &lt;strong&gt;single user&lt;/strong&gt; or &lt;strong&gt;multi-tenant&lt;/strong&gt; section based on your usage.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re experiencing issues during the installation because of conflicts on your OpenDataology deployment, you can &lt;a href=&#34;/docs/ibm/deploy/uninstall-OpenDataology&#34;&gt;uninstall OpenDataology&lt;/a&gt; and install it again.&lt;/p&gt;
&lt;h2 id=&#34;single-user&#34;&gt;Single user&lt;/h2&gt;
&lt;p&gt;Using kustomize together with kubectl to deploy OpenDataology:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone the manifest repo as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/IBM/manifests.git -b v1.6-branch ibm-manifests-160
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change directory to &lt;code&gt;ibm-manifests-160&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; ibm-manifests-160
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate password for default user: &lt;code&gt;user@example.com&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 -c &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=&amp;#34;2y&amp;#34;).hash(getpass.getpass()))&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Type your password and press &lt;code&gt;&amp;lt;Enter&amp;gt;&lt;/code&gt; after you see &lt;code&gt;Password:&lt;/code&gt; prompt. Copy the hash code for next step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit &lt;code&gt;dist/stacks/ibm/application/dex-auth/custom-env.yaml&lt;/code&gt; and fill the relevant field
with the hash code from previous step:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;staticPasswords:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- email: user@example.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  hash: &amp;lt;enter the generated hash here&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also change the email value if needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the &lt;code&gt;kustomize&lt;/code&gt; file under &lt;code&gt;iks-single&lt;/code&gt; folder for single user deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;while&lt;/span&gt; ! kustomize build iks-single &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f -&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Retrying to apply resources&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; sleep 10&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;accessing-your-cluster&#34;&gt;Accessing your cluster&lt;/h3&gt;
&lt;p&gt;The OpenDataology endpoint is exposed with &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#nodeport&#34;&gt;NodePort&lt;/a&gt; &lt;code&gt;30380&lt;/code&gt;. To get a static ip, you can &lt;a href=&#34;#expose-the-OpenDataology-endpoint-as-a-loadbalancer&#34;&gt;expose the OpenDataology endpoint as a LoadBalancer&lt;/a&gt; and access the &lt;strong&gt;EXTERNAL_IP&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For single-user OpenDataology, IBM Cloud uses Dex authentication by default. You can access the cluster using
the email and password you specified in step 3 and 4 of &lt;a href=&#34;#single-user&#34;&gt;Single User&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;multi-user-auth-enabled&#34;&gt;Multi-user, auth-enabled&lt;/h2&gt;
&lt;p&gt;Run the following steps to deploy OpenDataology with &lt;a href=&#34;https://cloud.ibm.com/catalog/services/app-id&#34;&gt;IBM Cloud AppID&lt;/a&gt;
as an authentication provider.&lt;/p&gt;
&lt;p&gt;The scenario is a OpenDataology cluster admin configures OpenDataology as a web
application in AppID and manages user authentication with builtin identity
providers (Cloud Directory, SAML, social log-in with Google or Facebook etc.) or
custom providers.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites-1&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;For authentication,  IBM Cloud uses &lt;a href=&#34;https://cloud.ibm.com/catalog/services/app-id&#34;&gt;AppID&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://cloud.ibm.com/catalog/services/app-id&#34;&gt;Creating an App ID service instance on IBM Cloud&lt;/a&gt; guide to learn about OpenDataology authentication.
You can also learn &lt;a href=&#34;https://cloud.ibm.com/docs/appid?topic=appid-getting-started&#34;&gt;how to use App ID&lt;/a&gt; with different authentication methods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://cloud.ibm.com/docs/appid?topic=appid-app#app-register&#34;&gt;Registering your app&lt;/a&gt;
section of the App ID guide to create an application with type
&lt;em&gt;regularwebapp&lt;/em&gt; under the provisioned AppID instance. Make sure the &lt;em&gt;scope&lt;/em&gt;
contains &lt;em&gt;email&lt;/em&gt;. Then retrieve the following configuration parameters from your AppID:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;clientId&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;secret&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;oAuthServerUrl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will be using these information in the subsequent sections.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Register the OpenDataology OIDC redirect page. The OpenDataology &lt;code&gt;REDIRECT_URL&lt;/code&gt; URL is
&lt;code&gt;[http|https]://&amp;lt;OpenDataology-FQDN&amp;gt;/login/oidc&lt;/code&gt;, depends on if you enable the HTTPS or not.
&lt;code&gt;&amp;lt;OpenDataology-FQDN&amp;gt;&lt;/code&gt; is the endpoint for accessing OpenDataology. By default, the &lt;code&gt;&amp;lt;OpenDataology-FQDN&amp;gt;&lt;/code&gt;
on IBM Cloud is &lt;code&gt;&amp;lt;worker_node_external_ip&amp;gt;:30380&lt;/code&gt;. To get a static ip, you can
&lt;a href=&#34;#expose-the-OpenDataology-endpoint-as-a-loadbalancer&#34;&gt;expose the OpenDataology endpoint as a LoadBalancer&lt;/a&gt;
and use the &lt;strong&gt;EXTERNAL_IP&lt;/strong&gt; for your &lt;code&gt;&amp;lt;OpenDataology-FQDN&amp;gt;&lt;/code&gt;. Or use &lt;code&gt;ibmcloud ks nlb-dns&lt;/code&gt; command
to map the &lt;strong&gt;EXTERNAL_IP&lt;/strong&gt; to the generated FQDN for your cluster. In this case, you use the
generated FQDN as &lt;code&gt;OpenDataology-FQDN&lt;/code&gt;. If you enable HTTPS, you shall use generated FQDN.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, you need to place the OpenDataology OIDC &lt;code&gt;REDIRECT_URL&lt;/code&gt; under &lt;strong&gt;Manage Authentication&lt;/strong&gt; &amp;gt; &lt;strong&gt;Authentication settings&lt;/strong&gt; &amp;gt; &lt;strong&gt;Add web redirect URLs&lt;/strong&gt;.&lt;/p&gt;
&lt;img src=&#34;/docs/images/ibm/appid-redirect-settings.png&#34; alt=&#34;APP ID Redirect Settings&#34; class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;
&lt;p&gt;Example:
&lt;code&gt;https://my-OpenDataology-442dbba0442be6c8c50f31ed96b00601-0000.sjc04.containers.appdomain.cloud/login/oidc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;deploy-using-kustomize-together-with-kubectl&#34;&gt;Deploy: Using kustomize together with kubectl&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone the manifest repo as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/IBM/manifests.git -b v1.6-branch ibm-manifests-160
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change directory to &lt;code&gt;ibm-manifests-160&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; ibm-manifests-160
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the &lt;code&gt;dist/stacks/ibm/application/oidc-authservice-appid/params.env&lt;/code&gt;
with values collected in &lt;a href=&#34;#prerequisites-1&#34;&gt;Prereq&lt;/a&gt; section.
You will need the following values:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;oAuthServerUrl&amp;gt;&lt;/code&gt; - replace &lt;code&gt;&amp;lt;APP_ID_oauthServerUrl&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;OpenDataology-FQDN&amp;gt;&lt;/code&gt; - fill in the FQDN of OpenDataology, if you don&amp;rsquo;t know yet, just give a dummy one like
&lt;code&gt;localhost&lt;/code&gt;. Then change it after you got one. Or get default FQDN of your cluster by this command:
&lt;code&gt;ibmcloud ks nlb-dns ls -c &amp;lt;cluster name&amp;gt;&lt;/code&gt; (replace &lt;code&gt;&amp;lt;cluter name&amp;gt;&lt;/code&gt; with your cluster name)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OIDC_PROVIDER=https://us-south.appid.cloud.ibm.com/oauth/v4/f341ff8b-a088-497a-same-5da4628df7fd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;REDIRECT_URL=https://my-OpenDataology-442dbba0442be6c8c50f31ed96b00601-0000.sjc04.containers.appdomain.cloud/login/oidc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OIDC_AUTH_URL=https://us-south.appid.cloud.ibm.com/oauth/v4/f341ff8b-a088-497a-same-5da4628df7fd/authorization
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the &lt;code&gt;dist/stacks/ibm/application/oidc-authservice-appid/secret_params.env&lt;/code&gt;
with values collected in &lt;a href=&#34;#prerequisites-1&#34;&gt;Prereq&lt;/a&gt; section.
You will need the following values:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;clientId&amp;gt;&lt;/code&gt; - replace the &lt;code&gt;&amp;lt;APP_ID_clientId&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;secret&amp;gt;&lt;/code&gt; - replace the &lt;code&gt;&amp;lt;APP_ID_secret&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CLIENT_SECRET=NjNhZDA3ODAtM2I3MCSECRETLTkwN2QtNDdhYmU5ZGIyMTBl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CLIENT_ID=52b3e496-8888-8888-ABC9-c0da309cdf52
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can apply the &lt;code&gt;kustomize&lt;/code&gt; file in &lt;code&gt;iks-multi&lt;/code&gt; folder:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;while&lt;/span&gt; ! kustomize build iks-multi &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f -&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Retrying to apply resources&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; sleep 10&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If at any point the values change and you have to change them, you can either patch the
&lt;a href=&#34;#patch-configmap&#34;&gt;configmap&lt;/a&gt; and &lt;a href=&#34;#patch-secret&#34;&gt;secret&lt;/a&gt; or change the content in the
files and apply the kustomize again. You will need to restart authservice with
&lt;code&gt;kubectl delete pod -l app=authservice -n istio-system&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;To apply just the &lt;code&gt;oidc-authservice-appid&lt;/code&gt; you can use this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kustomize build dist/stacks/ibm/application/oidc-authservice-appid &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f -
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete pod -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;verify-mutli-user-installation&#34;&gt;Verify mutli-user installation&lt;/h3&gt;
&lt;p&gt;Check the pod &lt;code&gt;authservice-0&lt;/code&gt; is in running state in namespace &lt;code&gt;istio-system&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get pod -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;extra-network-setup-requirement-for-vpc-gen2-clusters-only&#34;&gt;Extra network setup requirement for &lt;strong&gt;vpc-gen2&lt;/strong&gt; clusters only&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These steps are not required for &lt;code&gt;classic&lt;/code&gt; clusters, i.e. where &lt;code&gt;WORKER_NODE_PROVIDER&lt;/code&gt; is set to &lt;code&gt;classic&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;vpc-gen2&lt;/code&gt; cluster does not assign a public IP address to the Kubernetes master node by default.
It provides access via a Load Balancer, which is configured to allow only a set of ports over public internet.
Access the cluster&amp;rsquo;s resources in a &lt;code&gt;vpc-gen2&lt;/code&gt; cluster, using one of the following options,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load Balancer method: To configure via a Load Balancer, go to &lt;a href=&#34;#expose-the-OpenDataology-endpoint-as-a-loadbalancer&#34;&gt;Expose the OpenDataology endpoint as a LoadBalancer&lt;/a&gt;.
This method is recommended when you have OpenDataology deployed with &lt;a href=&#34;#multi-user-auth-enabled&#34;&gt;Multi-user, auth-enabled&lt;/a&gt; support — otherwise it will expose
cluster resources to the public.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Socks proxy method: If you need access to nodes or NodePort in the &lt;code&gt;vpc-gen2&lt;/code&gt; cluster, this can be achieved by starting another instance in the
same &lt;code&gt;vpc-gen2&lt;/code&gt; cluster and assigning it a public IP (i.e. the floating IP). Next, use SSH to log into the instance or create an SSH socks proxy,
such as &lt;code&gt;ssh -D9999 root@new-instance-public-ip&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, configure the socks proxy at &lt;code&gt;localhost:9999&lt;/code&gt; and access cluster services.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl port-forward&lt;/code&gt; method: To access OpenDataology dashboard, run &lt;code&gt;kubectl -n istio-system port-forward service/istio-ingressgateway 7080:http2&lt;/code&gt;.
Then in a browser, go to&lt;a href=&#34;http://127.0.0.1:7080/&#34;&gt;http://127.0.0.1:7080/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Important notice&lt;/strong&gt;: Exposing cluster/compute resources publicly without setting up a proper user authentication mechanism
is very insecure and can have very serious consequences(even legal). If there is no need to expose cluster services publicly,
Socks proxy method or &lt;code&gt;kubectl port-forward&lt;/code&gt; method are recommended.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;next-steps-secure-the-opendataology-dashboard-with-https&#34;&gt;Next steps: secure the OpenDataology dashboard with HTTPS&lt;/h2&gt;
&lt;h3 id=&#34;prerequisites-2&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;For both &lt;code&gt;classic&lt;/code&gt; and &lt;code&gt;vpc-gen2&lt;/code&gt; cluster providers, make sure you have &lt;a href=&#34;#multi-user-auth-enabled&#34;&gt;Multi-user, auth-enabled&lt;/a&gt; OpenDataology set up.&lt;/p&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;p&gt;Follow the steps in &lt;a href=&#34;../authentication/#exposing-the-OpenDataology-dashboard-with-dns-and-tls-termination&#34;&gt;Exposing the OpenDataology dashboard with DNS and TLS termination&lt;/a&gt;.
Then, you will have the required DNS name as OpenDataology FQDN to enable the OIDC flow for AppID:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Follow the step &lt;a href=&#34;https://cloud.ibm.com/docs/appid?topic=appid-managing-idp#add-redirect-uri&#34;&gt;Adding redirect URIs&lt;/a&gt;
to fill a URL for AppID to redirect to OpenDataology. The URL should look like &lt;code&gt;https://&amp;lt;OpenDataology-FQDN&amp;gt;/login/oidc&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the secret &lt;code&gt;appid-application-configuration&lt;/code&gt; with the updated OpenDataology FQDN to replace &lt;code&gt;&amp;lt;OpenDataology-FQDN&amp;gt;&lt;/code&gt; in below command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;REDIRECT_URL&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://&amp;lt;OpenDataology-FQDN&amp;gt;/login/oidc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PATCH&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;data&amp;#34;: {&amp;#34;REDIRECT_URL&amp;#34;: &amp;#34;%s&amp;#34;}}&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$REDIRECT_URL&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch configmap/oidc-authservice-parameters -n istio-system -p&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PATCH&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restart the pod &lt;code&gt;authservice-0&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete pod -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then, visit &lt;code&gt;https://&amp;lt;OpenDataology-FQDN&amp;gt;/&lt;/code&gt;. The page should redirect you to AppID for authentication.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;h3 id=&#34;expose-the-opendataology-endpoint-as-a-loadbalancer&#34;&gt;Expose the OpenDataology endpoint as a LoadBalancer&lt;/h3&gt;
&lt;p&gt;By default, the OpenDataology deployment on IBM Cloud only exposes the endpoint as &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#nodeport&#34;&gt;NodePort&lt;/a&gt; 30380. If you want to expose the endpoint as a &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer&#34;&gt;LoadBalancer&lt;/a&gt;, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch svc istio-ingressgateway -n istio-system -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;spec&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;LoadBalancer&amp;#34;}}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, you can locate the LoadBalancer in the &lt;strong&gt;EXTERNAL_IP&lt;/strong&gt; column when you run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get svc istio-ingressgateway -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There is a small delay, usually ~5 mins, for above commands to take effect.&lt;/p&gt;
&lt;h3 id=&#34;authservice-pod-taking-too-long-to-restart&#34;&gt;Authservice pod taking too long to restart&lt;/h3&gt;
&lt;p&gt;You might see the &lt;code&gt;authservice-0&lt;/code&gt; pod taking some time to restart. If that happens you can delete to pod which will kick off restart from kubernetes reconciler.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete pod -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;authservice -n istio-system
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Uninstall OpenDataology</title>
      <link>/docs/distributions/nutanix/uninstall-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/nutanix/uninstall-kubeflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;uninstall-opendataology&#34;&gt;Uninstall OpenDataology&lt;/h2&gt;
&lt;p&gt;To delete a OpenDataology installation, apply the following command from your terraform script folder&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;terraform destroy -var-file=env.tfvars
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Upgrade OpenDataology</title>
      <link>/docs/distributions/gke/deploy/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/upgrade/</guid>
      <description>
        
        
        &lt;h2 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h2&gt;
&lt;p&gt;To better understand upgrade process, you should read the following sections first:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/management-setup#understanding-the-deployment-process&#34;&gt;Understanding the deployment process for management cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli#understanding-the-deployment-process&#34;&gt;Understanding the deployment process for OpenDataology cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This guide assumes the following settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;${MGMT_DIR}&lt;/code&gt; and &lt;code&gt;${MGMT_NAME}&lt;/code&gt; environment variables
are the same as in &lt;a href=&#34;/docs/distributions/gke/deploy/management-setup#configure-environment-variables&#34;&gt;Management cluster setup&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;${KF_NAME}&lt;/code&gt;, &lt;code&gt;${CLIENT_ID}&lt;/code&gt; and &lt;code&gt;${CLIENT_SECRET}&lt;/code&gt; environment variables
are the same as in &lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli#environment-variables&#34;&gt;Deploy using kubectl and kpt&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;${KF_DIR}&lt;/code&gt; environment variable contains the path to
your OpenDataology application directory, which holds your OpenDataology configuration
files. For example, &lt;code&gt;/opt/gcp-blueprints/OpenDataology/&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;general-upgrade-instructions&#34;&gt;General upgrade instructions&lt;/h2&gt;
&lt;p&gt;Starting from OpenDataology v1.5, we have integrated with &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview&#34;&gt;Config Controller&lt;/a&gt;. You don&amp;rsquo;t need to manually upgrade Management cluster any more, since it managed by &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/how-to/config-controller-setup#upgrade&#34;&gt;Upgrade Config Controller&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Starting from OpenDataology v1.3, we have reworked on the structure of &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; repository. All resources are located in &lt;code&gt;gcp-blueprints/management&lt;/code&gt; directory. Upgrade to Management cluster v1.3 is not supported.&lt;/p&gt;
&lt;p&gt;Before OpenDataology v1.3, both management cluster and OpenDataology cluster follow the same &lt;code&gt;instance&lt;/code&gt; and &lt;code&gt;upstream&lt;/code&gt; folder convention. To upgrade, you&amp;rsquo;ll typically need to update packages in &lt;code&gt;upstream&lt;/code&gt; to the new version and repeat the &lt;code&gt;make apply-&amp;lt;subcommand&amp;gt;&lt;/code&gt; commands in their respective deployment process.&lt;/p&gt;
&lt;p&gt;However, specific upgrades might need manual actions below.&lt;/p&gt;
&lt;h2 id=&#34;upgrading-management-cluster&#34;&gt;Upgrading management cluster&lt;/h2&gt;
&lt;h3 id=&#34;upgrading-management-cluster-before-15&#34;&gt;Upgrading management cluster before 1.5&lt;/h3&gt;
&lt;p&gt;It is strongly recommended to use source control to keep a copy of your working repository for recording changes at each step.&lt;/p&gt;
&lt;p&gt;Due to the refactoring of &lt;code&gt;OpenDataology/manifests&lt;/code&gt; repository, the way we depend on &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; has changed drastically. This section suits for upgrading from OpenDataology 1.3 to higher.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The instructions below assume that your current working directory is&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use your management cluster&amp;rsquo;s kubectl context:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Look at all your contexts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config get-contexts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Select your management cluster&amp;#39;s context&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config use-context &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Verify the context connects to the cluster properly&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get namespace
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you are using a different environment, you can always
reconfigure the context by:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make create-context
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check your existing config connector version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For OpenDataology v1.3, it should be 1.46.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl get namespace cnrm-system -ojsonpath&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.metadata.annotations.cnrm\.cloud\.google\.com\/version}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.46.0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merge the content from new OpenDataology version of &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKING_BRANCH&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;your-github-working-branch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;VERSION_TAG&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;targeted-OpenDataology-version-tag-on-github&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout -b &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKING_BRANCH&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git remote add upstream https://github.com/OpenDataology/gcp-blueprints.git &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# This is one time only.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git fetch upstream 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git merge &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;VERSION_TAG&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure your build directory (&lt;code&gt;./build&lt;/code&gt; by default) is checked in to source control (git).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to hydrate Config Connector resources:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make hydrate-kcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compare the difference on your source control tracking after making hydration change. If they are addition or modification only, proceed to next step. If it includes deletion, you need to use &lt;code&gt;kubectl delete&lt;/code&gt; to manually clean up the deleted resource for cleanup.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After confirmation, run the following command to apply new changes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply-kcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check version has been upgraded after applying new Config Connector resource:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl get namespace cnrm-system -ojsonpath&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.metadata.annotations.cnrm\.cloud\.google\.com\/version}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;upgrade-management-cluster-from-v11-to-v12&#34;&gt;Upgrade management cluster from v1.1 to v1.2&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The instructions below assume that your current working directory is&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use your management cluster&amp;rsquo;s kubectl context:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Look at all your contexts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config get-contexts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Select your management cluster&amp;#39;s context&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config use-context &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Verify the context connects to the cluster properly&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get namespace
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you are using a different environment, you can always
reconfigure the context by:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make create-context
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check your existing config connector version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For OpenDataology v1.1, it should be 1.15.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl get namespace cnrm-system -ojsonpath&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.metadata.annotations.cnrm\.cloud\.google\.com\/version}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.15.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Uninstall the old config connector in the management cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete sts,deploy,po,svc,roles,clusterroles,clusterrolebindings --all-namespaces -l cnrm.cloud.google.com/system&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt; --wait&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete validatingwebhookconfiguration abandon-on-uninstall.cnrm.cloud.google.com --ignore-not-found --wait&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete validatingwebhookconfiguration validating-webhook.cnrm.cloud.google.com --ignore-not-found --wait&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete mutatingwebhookconfiguration mutating-webhook.cnrm.cloud.google.com --ignore-not-found --wait&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These commands uninstall the config connector without removing your resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Replace your &lt;code&gt;./Makefile&lt;/code&gt; with the version in OpenDataology &lt;code&gt;v1.2.0&lt;/code&gt;: &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/v1.2.0/management/Makefile&#34;&gt;https://github.com/OpenDataology/gcp-blueprints/blob/v1.2.0/management/Makefile&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you made any customizations in &lt;code&gt;./Makefile&lt;/code&gt;, you should merge your changes with the upstream version. We&amp;rsquo;ve refactored the Makefile to move substantial commands into the upstream package, so hopefully future upgrades won&amp;rsquo;t require a manual merge of the Makefile.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update &lt;code&gt;./upstream/management&lt;/code&gt; package:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use kpt to set user values:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt cfg &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; -R . name &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt cfg &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; -R . gcloud.core.project &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt cfg &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; -R . location &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;LOCATION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you can find out which setters exist in a package and what there current values are by:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kpt cfg list-setters .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply upgraded config connector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply-kcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you can optionally also run &lt;code&gt;make apply-cluster&lt;/code&gt;, but it should be the same as your existing management cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that your config connector upgrade is successful:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For OpenDataology v1.2, it should be 1.29.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kubectl get namespace cnrm-system -ojsonpath&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{.metadata.annotations.cnrm\.cloud\.google\.com\/version}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.29.0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;upgrading-opendataology-cluster&#34;&gt;Upgrading OpenDataology cluster&lt;/h2&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;DISCLAIMERS&lt;/h4&gt;

    &lt;div&gt;The upgrade process depends on each OpenDataology application to handle the upgrade properly. There&#39;s no guarantee on data completeness unless the application provides such a guarantee.&lt;/div&gt;
&lt;div&gt;You are recommended to back up your data before an upgrade.&lt;/div&gt;
&lt;div&gt;Upgrading OpenDataology cluster can be a disruptive process, please schedule some downtime and communicate with your users.&lt;/div&gt;


&lt;/div&gt;

&lt;p&gt;To upgrade from specific versions of OpenDataology, you may need to take certain manual actions — refer to specific sections in the guidelines below.&lt;/p&gt;
&lt;h3 id=&#34;general-instructions-for-upgrading-opendataology-cluster&#34;&gt;General instructions for upgrading OpenDataology cluster&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The instructions below assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Your current working directory is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your kubectl uses a context that connects to your OpenDataology cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# List your existing contexts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config get-contexts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Use the context that connects to your OpenDataology cluster&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config use-context &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merge the new version of &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; (example: v1.3.1), you don&amp;rsquo;t need to do it again if you have already done so during management cluster upgrade.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKING_BRANCH&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;your-github-working-branch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;VERSION_TAG&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;targeted-OpenDataology-version-tag-on-github&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout -b &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;WORKING_BRANCH&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git remote add upstream https://github.com/OpenDataology/gcp-blueprints.git &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# This is one time only.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git fetch upstream 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git merge &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;VERSION_TAG&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change the &lt;code&gt;OpenDataology_MANIFESTS_VERSION&lt;/code&gt; in &lt;code&gt;./pull-upstream.sh&lt;/code&gt; with the targeted OpenDataology version same as &lt;code&gt;$VERSION_TAG&lt;/code&gt;. Run the following commands to pull new changes from upstream &lt;code&gt;OpenDataology/manifests&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash ./pull-upstream.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Optional) If you only want to upgrade some of OpenDataology components, you can comment non-upgrade components in &lt;code&gt;OpenDataology/config.yaml&lt;/code&gt; file. Commands below will only apply the remaining components.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you have checked in &lt;code&gt;build&lt;/code&gt; folders for each component. The following command will change them so you can compare for difference.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make hydrate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you confirm the changes are ready to apply, run the following command to upgrade OpenDataology cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    OpenDataology on Google Cloud doesn&amp;rsquo;t guarantee the upgrade for each OpenDataology component always works with the general upgrade guide here. Please refer to corresponding repository in &lt;a href=&#34;https://github.com/OpenDataology&#34;&gt;OpenDataology org&lt;/a&gt; for upgrade support.

&lt;/div&gt;

&lt;h3 id=&#34;upgrade-opendataology-cluster-to-v15&#34;&gt;Upgrade OpenDataology cluster to v1.5&lt;/h3&gt;
&lt;p&gt;Starting from OpenDataology v1.5.1 we upgraded ASM to v1.13. Follow the instructions on how to &lt;a href=&#34;#upgrade-asm-anthos-service-mesh&#34;&gt;upgrade ASM (Anthos Service Mesh)&lt;/a&gt;. If you want to use ASM version prior to 1.11, refer to &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/master/OpenDataology/common/asm/deprecated/README.md&#34;&gt;the legacy instructions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Starting from OpenDataology v1.5, OpenDataology manifests have included KServe as an independent component from kfserving, Google Cloud distribution has switched over from kfserving to KServe for default installed components. If you want to upgrade OpenDataology while keeping kfsering, you can comment KServe and uncomment kfserving in &lt;code&gt;gcp-blueprints/OpenDataology/config.yaml&lt;/code&gt; file. If you want to upgrade to KServe, follow the &lt;a href=&#34;https://github.com/kserve/kserve/tree/master/hack/kserve_migration&#34;&gt;KServe Migration guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;upgrade-opendataology-cluster-to-v13&#34;&gt;Upgrade OpenDataology cluster to v1.3&lt;/h3&gt;
&lt;p&gt;Due to the refactoring of &lt;code&gt;OpenDataology/manifests&lt;/code&gt; repository, the way we depend on &lt;code&gt;OpenDataology/gcp-blueprints&lt;/code&gt; has changed drastically. Upgrade to OpenDataology cluster v1.3 is not supported. And individual component upgrade has been deferred to its corresponding repository for support.&lt;/p&gt;
&lt;h3 id=&#34;upgrade-opendataology-cluster-from-v11-to-v12&#34;&gt;Upgrade OpenDataology cluster from v1.1 to v1.2&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The instructions below assume&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Your current working directory is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your kubectl uses a context that connects to your OpenDataology cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# List your existing contexts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config get-contexts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Use the context that connects to your OpenDataology cluster&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config use-context &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Recommended) Replace your &lt;code&gt;./Makefile&lt;/code&gt; with the version in OpenDataology &lt;code&gt;v1.2.0&lt;/code&gt;: &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/v1.2.0/OpenDataology/Makefile&#34;&gt;https://github.com/OpenDataology/gcp-blueprints/blob/v1.2.0/OpenDataology/Makefile&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you made any customizations in &lt;code&gt;./Makefile&lt;/code&gt;, you should merge your changes with the upstream version.&lt;/p&gt;
&lt;p&gt;This step is recommended, because we introduced usability improvements and fixed compatibility for newer Kustomize versions (while still being compatible with Kustomize v3.2.1) to the Makefile. However, the deployment process is backward-compatible, so this is recommended, but not required.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update &lt;code&gt;./upstream/manifests&lt;/code&gt; package:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Before applying new resources, you need to delete some immutable resources that were updated in this release:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete statefulset kfserving-controller-manager -n OpenDataology --wait
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete crds experiments.OpenDataology.org suggestions.OpenDataology.org trials.OpenDataology.org
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: This step &lt;strong&gt;deletes&lt;/strong&gt; all Katib running resources.&lt;/p&gt;
&lt;p&gt;Refer to &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/issues/5371#issuecomment-731359384&#34;&gt;a github comment in the v1.2 release issue&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redeploy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To evaluate the changes before deploying them you can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Run &lt;code&gt;make hydrate&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compare the contents
of &lt;code&gt;.build&lt;/code&gt; with a historic version with tools like &lt;code&gt;git diff&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;upgrade-asm-anthos-service-mesh&#34;&gt;Upgrade ASM (Anthos Service Mesh)&lt;/h2&gt;
&lt;p&gt;If you want to upgrade ASM instead of the OpenDataology components, refer to &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/master/OpenDataology/common/asm/README.md&#34;&gt;OpenDataology/common/asm/README.md&lt;/a&gt; for the latest instructions on upgrading ASM. Detailed explanation is listed below. Note: if you are going to upgrade major or minor version of ASM, it is recommended to read &lt;a href=&#34;https://cloud.google.com/service-mesh/docs/upgrade-path-old-versions-gke&#34;&gt;the official ASM upgrade documentation&lt;/a&gt; before proceeding with the steps below.&lt;/p&gt;
&lt;h3 id=&#34;install-a-new-asm-workload&#34;&gt;Install a new ASM workload&lt;/h3&gt;
&lt;p&gt;In order to use the new ASM version, we need to download the corresponding ASM configuration package and &lt;code&gt;asmcli&lt;/code&gt; script. Get a list of available ASM packages and the corresponding &lt;code&gt;asmcli&lt;/code&gt; scripts by running the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl https://storage.googleapis.com/csm-artifacts/asm/ASMCLI_VERSIONS
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It should return a list of ASM versions that can be installed with asmcli script. To install older versions, refer to &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/master/OpenDataology/common/asm/deprecated/README.md&#34;&gt;the legacy instructions&lt;/a&gt;. The returned list will have a format of &lt;code&gt;${ASM_PACKAGE_VERSION}:${ASMCLI_SCRIPT_VERSION}&lt;/code&gt;. For example, in the following output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.13.2-asm.5+config2:asmcli_1.13.2-asm.5-config2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.13.2-asm.5+config1:asmcli_1.13.2-asm.5-config1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.13.2-asm.2+config2:asmcli_1.13.2-asm.2-config2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.13.2-asm.2+config1:asmcli_1.13.2-asm.2-config1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1.13.1-asm.1+config1:asmcli_1.13.1-asm.1-config1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;record 1.13.2-asm.5+config2:asmcli_1.13.2-asm.5-config2 corresponds to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;ASM_PACKAGE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;1.13.2-asm.5+config2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;ASMCLI_SCRIPT_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;asmcli_1.13.2-asm.5-config2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You need to set these two values in &lt;a href=&#34;https://github.com/OpenDataology/gcp-blueprints/blob/master/OpenDataology/asm/Makefile&#34;&gt;OpenDataology/asm/Makefile&lt;/a&gt;. Then, run the following command in &lt;code&gt;OpenDataology/asm&lt;/code&gt; directory to install the new ASM. Note, the old ASM will not be uninstalled.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once installed successfully, you can see istiod &lt;code&gt;Deployment&lt;/code&gt; in your cluster with name in pattern &lt;code&gt;istiod-asm-VERSION-REVISION&lt;/code&gt;. For example, &lt;code&gt;istiod-asm-1132-5&lt;/code&gt; would correspond to ASM version 1.13.2-asm.5.&lt;/p&gt;
&lt;h3 id=&#34;upgrade-other-opendataology-components-to-use-new-asm&#34;&gt;Upgrade other OpenDataology components to use new ASM&lt;/h3&gt;
&lt;p&gt;There are multiple OpenDataology components with ASM namespace label, including user created namespaces. To upgrade them at once, change the following line in &lt;code&gt;OpenDataology/env.sh&lt;/code&gt; with the new ASM version &lt;code&gt;asm-VERSION-REVISION&lt;/code&gt;, like &lt;code&gt;asm-1132-5&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ASM_LABEL&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;asm-1132-5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then run the following commands in &lt;code&gt;OpenDataology/&lt;/code&gt; directory to configure the environmental variables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; env.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run the following command to configure kpt setter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash kpt-set.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Examine the change using source control after running the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make hydrate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Refer to &lt;a href=&#34;https://cloud.google.com/service-mesh/docs/unified-install/upgrade#deploying_and_redeploying_workloads&#34;&gt;Deploying and redeploying workloads&lt;/a&gt; for the complete steps to adopt the new ASM version. As part of the instructions, you can run the following command to update namespaces&amp;rsquo; labels across the cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;optional-uninstall-the-old-asm-workload&#34;&gt;(Optional) Uninstall the old ASM workload&lt;/h3&gt;
&lt;p&gt;Once you validated that new ASM installation and sidecar-injection for OpenDataology components are working as expected. You can &lt;strong&gt;Complete the transition&lt;/strong&gt; to the new ASM or &lt;strong&gt;Rollback&lt;/strong&gt; to the old ASM as instructed in &lt;a href=&#34;https://cloud.google.com/service-mesh/docs/unified-install/upgrade#deploying_and_redeploying_workloads&#34;&gt;Deploy and Redeploy workloads&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Using IBM Cloud Container Registry (ICR)</title>
      <link>/docs/distributions/ibm/using-icr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/using-icr/</guid>
      <description>
        
        
        &lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install and configure the &lt;a href=&#34;https://cloud.ibm.com/docs/cli?topic=cli-getting-started&#34;&gt;IBM Cloud CLI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Install the CLI plug-in for the IBM Cloud Container Registry by running the command &lt;code&gt;ibmcloud plugin install container-registry&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Create a namespace in ICR with the command &lt;code&gt;ibmcloud cr namespace-add &amp;lt;my_namespace&amp;gt;&lt;/code&gt;, replace &lt;code&gt;&amp;lt;my_namespace&amp;gt;&lt;/code&gt; with your preferred name.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;a href=&#34;https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started#gs_registry_namespace_add&#34;&gt;ICR namespace&lt;/a&gt; is different from the OpenDataology Profile namespace. The ICR namespace is used to group container images stored in ICR, while a &lt;a href=&#34;/docs/components/multi-tenancy/overview/&#34;&gt;OpenDataology Profile&lt;/a&gt; namespace is a group of all Kubernetes clusters owned by a user.&lt;/p&gt;
&lt;h2 id=&#34;image-pull-secret&#34;&gt;Image pull secret&lt;/h2&gt;
&lt;p&gt;As a Kubernetes cluster uses the Secret of &lt;code&gt;docker-registry&lt;/code&gt; type to authenticate with a container registry to pull a private image, it needs an image pull secret to pull container images from IBM Cloud Container Registry. You can use the default image pull secret set up by the cluster or your account&amp;rsquo;s IAM API key.&lt;/p&gt;
&lt;h3 id=&#34;using-a-default-image-pull-secret&#34;&gt;Using a default image pull secret&lt;/h3&gt;
&lt;p&gt;By default, the IBM Cloud Kubernetes cluster is set up to pull images from only your account&amp;rsquo;s namespace in IBM Cloud Container Registry by using the secret &lt;code&gt;all-icr-io&lt;/code&gt; in the &lt;code&gt;default&lt;/code&gt; namespace. A cluster admin can copy this secret to any Kubernetes namespace used as OpenDataology profile. For example, run below command to copy the secret &lt;code&gt;all-icr-io&lt;/code&gt; to the &lt;code&gt;anonymous&lt;/code&gt; namespace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get secret all-icr-io -n default -o yaml \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| sed &amp;#39;s/namespace: default/namespace: anonymous/g&amp;#39; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| kubectl -n anonymous create -f -
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once this secret is ready in your OpenDataology profile, a data scientist can use it to pull container images from ICR.&lt;/p&gt;
&lt;p&gt;See details and FAQs from the official guide &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-registry&#34;&gt;Setting up an image registry&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;getting-an-iam-api-key&#34;&gt;Getting an IAM API Key&lt;/h3&gt;
&lt;p&gt;You will need an IBM Cloud IAM API Key to work with ICR if you:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Have no access to the default image pull secret &lt;code&gt;all-icr-io&lt;/code&gt; from the &lt;code&gt;default&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;Need to access container images in other IBM Cloud accounts.&lt;/li&gt;
&lt;li&gt;Need customized IAM policy by using a separate IAM service ID.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you don&amp;rsquo;t have an IBM Cloud IAM API Key, follow the official guide &lt;a href=&#34;https://cloud.ibm.com/docs/account?topic=account-userapikey#create_user_key&#34;&gt;Create an API Key&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once you get your IBM Cloud IAM API Key, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n &amp;lt;my_namespace&amp;gt; create secret docker-registry &amp;lt;secret_name&amp;gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--docker-server=&amp;lt;registry_domain_name&amp;gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--docker-username=iamapikey \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--docker-password=&amp;lt;ibm_cloud_iam_api_key&amp;gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--docker-email=&amp;lt;docker_email&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;my_namespace&amp;gt;&lt;/code&gt;: your namespace to use with ICR to create an image pull secret.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;ibm_cloud_iam_api_key&amp;gt;&lt;/code&gt;: your IBM Cloud API Key.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;secret_name&amp;gt;&lt;/code&gt;: a unique name for the pull image secret, such as &lt;code&gt;us-icr-io&lt;/code&gt;, for example.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;registry_domain_name&amp;gt;&lt;/code&gt;: the image registry where your registry namespace is set up. Use regional domain name when storing container images in specific region, such as &lt;code&gt;us.icr.io&lt;/code&gt; when using region &lt;code&gt;en-us&lt;/code&gt; and &lt;code&gt;uk.icr.io&lt;/code&gt; when using region &lt;code&gt;eu-gb&lt;/code&gt;. See full list of regional domain names from the &lt;a href=&#34;https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview#registry_regions_local&#34;&gt;About IBM Cloud Container Registry page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;docker_email&amp;gt;&lt;/code&gt;: your docker email address or any fictional email address, such as &lt;code&gt;a@b.c&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;scenarios&#34;&gt;Scenarios&lt;/h2&gt;
&lt;h3 id=&#34;using-container-images-from-icr-in-opendataology-pipelines&#34;&gt;Using container images from ICR in OpenDataology Pipelines&lt;/h3&gt;
&lt;p&gt;The pull image secret may be set in OpenDataology Pipelines SDK&amp;rsquo;s &lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.PipelineConf&#34;&gt;&lt;code&gt;PipelineConf&lt;/code&gt;&lt;/a&gt;. Refer to this &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/ef381aafccf916482d16774cac3b8568d06dff9e/samples/core/imagepullsecrets/imagepullsecrets.py#L55&#34;&gt;&lt;code&gt;imagepullsecrets.py&lt;/code&gt;&lt;/a&gt; sample in OpenDataology Pipelines project for usage.&lt;/p&gt;
&lt;h3 id=&#34;using-notebook-images-from-icr-in-a-jupyter-notebook&#34;&gt;Using notebook images from ICR in a Jupyter Notebook&lt;/h3&gt;
&lt;p&gt;When a namespace is created for OpenDataology with its profile controller, a default service account &lt;code&gt;default-editor&lt;/code&gt; is created in that namespace. Before creating a Notebook Server, run following command to patch the service account. Replace &lt;code&gt;&amp;lt;secret_name&amp;gt;&lt;/code&gt; with the ICR pull image secret name and &lt;code&gt;&amp;lt;my_namespace&amp;gt;&lt;/code&gt; with the OpenDataology profile namespace.&lt;/p&gt;
&lt;p&gt;Replace &lt;code&gt;&amp;lt;my_namespace&amp;gt;&lt;/code&gt; with your namespace then run below command to patch the service account &lt;code&gt;default-editor&lt;/code&gt; with this image pull secret:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch serviceaccount default-editor &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;-p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;imagePullSecrets&amp;#34;: [{&amp;#34;name&amp;#34;: &amp;#34;&amp;lt;secret-name&amp;gt;&amp;#34;}]}&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;-n &amp;lt;my_namespace&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The service account should be updated. Then, when you create the Notebook Server through OpenDataology dashboard, you should be able to choose a Custom Image. Afterwards, set the notebook image path from the ICR as follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/ibm/notebook-custom-image.png&#34; 
alt=&#34;Notebook Custom Image&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: End-to-end OpenDataology on IBM Cloud</title>
      <link>/docs/distributions/ibm/iks-e2e/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/iks-e2e/</guid>
      <description>
        
        
        &lt;p&gt;This is a guide for an end-to-end example of OpenDataology on &lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-getting-started&#34;&gt;IBM Cloud Kubernetes Service (IKS)&lt;/a&gt;. The core steps will be to take a base Tensorflow model, modify it for distributed training, serve the resulting model with TFServing, and deploy a web application that uses the trained model.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;overview-of-iks&#34;&gt;Overview of IKS&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.ibm.com/docs/containers?topic=containers-getting-started&#34;&gt;IBM Cloud Kubernetes Service (IKS)&lt;/a&gt; enables the deployment of containerized applications in Kubernetes clusters with specialized tools for management of the systems.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://cloud.ibm.com/docs/cli?topic=cloud-cli-getting-started&#34;&gt;IBM Cloud CLI&lt;/a&gt; can be used for creating, developing, and deploying cloud applications.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a list of IBM Cloud services you will use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/cloud/container-service/&#34;&gt;IKS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/cloud/object-storage&#34;&gt;IBM Cloud Object Storage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-model-and-the-data&#34;&gt;The model and the data&lt;/h3&gt;
&lt;p&gt;This tutorial trains a &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt; model on the
&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/index.html&#34;&gt;MNIST dataset&lt;/a&gt;, which is the &lt;em&gt;hello world&lt;/em&gt; for machine learning.&lt;/p&gt;
&lt;p&gt;The MNIST dataset contains a large number of images of hand-written digits in
the range 0 to 9, as well as the labels identifying the digit in each image.&lt;/p&gt;
&lt;p&gt;After training, the model can classify incoming images into 10 categories
(0 to 9) based on what it&amp;rsquo;s learned about handwritten images. In other words,
you send an image to the model, and the model does its best to identify the
digit shown in the image.
&lt;img src=&#34;/docs/images/gcp-e2e-ui-prediction.png&#34;
alt=&#34;Prediction UI&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the above screenshot, the image shows a hand-written &lt;strong&gt;7&lt;/strong&gt;. This image was
the input to the model. The table below the image shows a bar graph for each
classification label from 0 to 9, as output by the model. Each bar
represents the probability that the image matches the respective label.
Judging by this screenshot, the model seems pretty confident that this image
is a 7.&lt;/p&gt;
&lt;h3 id=&#34;the-overall-workflow&#34;&gt;The overall workflow&lt;/h3&gt;
&lt;p&gt;The following diagram shows what you accomplish by following this guide:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/ibm-e2e-OpenDataology.png&#34; 
alt=&#34;ML workflow for training and serving an MNIST model&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;In summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting up &lt;a href=&#34;https://www.OpenDataology.org/&#34;&gt;OpenDataology&lt;/a&gt; on &lt;a href=&#34;https://www.ibm.com/cloud/container-service/&#34;&gt;IKS&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Training the model:
&lt;ul&gt;
&lt;li&gt;Packaging a Tensorflow program in a container.&lt;/li&gt;
&lt;li&gt;Submitting a Tensorflow training (&lt;a href=&#34;https://www.tensorflow.org/api_guides/python/train&#34;&gt;tf.train&lt;/a&gt;) job.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Using the model for prediction (inference):
&lt;ul&gt;
&lt;li&gt;Saving the trained model to &lt;a href=&#34;https://www.ibm.com/cloud/object-storage&#34;&gt;IBM Cloud Object Storage&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Using &lt;a href=&#34;https://www.tensorflow.org/tfx/guide/serving&#34;&gt;Tensorflow Serving&lt;/a&gt; to serve the model.&lt;/li&gt;
&lt;li&gt;Running the simple web app to send prediction request to the model and display the result.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s time to get started!&lt;/p&gt;
&lt;h2 id=&#34;run-the-mnist-tutorial-on-iks&#34;&gt;Run the MNIST Tutorial on IKS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Follow the &lt;a href=&#34;/docs/ibm/deploy/install-OpenDataology&#34;&gt;IKS instructions&lt;/a&gt; to deploy OpenDataology.&lt;/li&gt;
&lt;li&gt;Launch a Jupyter notebook.&lt;/li&gt;
&lt;li&gt;Launch a terminal in Jupyter and clone the OpenDataology examples repo.
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/OpenDataology/examples.git git_OpenDataology-examples
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tip&lt;/strong&gt;: When you start a terminal in Jupyter, run the command &lt;code&gt;bash&lt;/code&gt; to start
a bash terminal which is much more friendly than the default shell.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can change the URL for your notebook from &amp;lsquo;/tree&amp;rsquo; to &amp;lsquo;/lab&amp;rsquo; to switch to using Jupyterlab.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open the notebook &lt;code&gt;mnist/mnist_ibm.ipynb&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Follow the notebook to train and deploy MNIST on OpenDataology.&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology on OpenShift</title>
      <link>/docs/distributions/ibm/deploy/install-kubeflow-on-ibm-openshift/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/ibm/deploy/install-kubeflow-on-ibm-openshift/</guid>
      <description>
        
        
        &lt;p&gt;&lt;strong&gt;This guide has not yet been updated for OpenDataology 1.3&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This guide describes how to use the kfctl binary to deploy OpenDataology on IBM Cloud Kubernetes Service (IKS).&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Authenticate with IBM Cloud&lt;/p&gt;
&lt;p&gt;Log into IBM Cloud at &lt;a href=&#34;https://cloud.ibm.com&#34;&gt;IBM Cloud&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install OpenShift CLI&lt;/p&gt;
&lt;p&gt;OpenShift CLI is the way to manage and access OpenShift cluster. You can &lt;a href=&#34;https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli&#34;&gt;Install OpenShift CLI&lt;/a&gt; from this instructions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create and access a OpenShift cluster on IKS&lt;/p&gt;
&lt;p&gt;To deploy OpenDataology on IBM Cloud, you need a cluster running OpenShift on IKS. If you don&amp;rsquo;t have a cluster running, follow the &lt;a href=&#34;https://cloud.ibm.com/docs/openshift?topic=openshift-clusters&#34;&gt;Create an IBM Cloud OpenShift cluster&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;To access the cluster follow these directions &lt;a href=&#34;https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster&#34;&gt;Access OpenShift Cluster&lt;/a&gt;. We can easily get access from the openshift console on IBM Cloud&lt;a href=&#34;https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster#access_oc_console&#34;&gt;Connecting to the cluster from the console&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re experiencing issues during the installation because of conflicts on your OpenDataology deployment, you can &lt;a href=&#34;/docs/ibm/deploy/uninstall-OpenDataology&#34;&gt;uninstall OpenDataology&lt;/a&gt; and install it again.&lt;/p&gt;
&lt;h3 id=&#34;single-user&#34;&gt;Single user&lt;/h3&gt;
&lt;p&gt;Run the following commands to set up and deploy OpenDataology for a single user without any authentication.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: By default, OpenDataology deployment on IBM Cloud uses the &lt;a href=&#34;https://github.com/OpenDataology/kfp-tekton#OpenDataology-pipelines-with-tekton&#34;&gt;OpenDataology pipeline with the Tekton backend&lt;/a&gt;.
If you want to use the OpenDataology pipeline with the Argo backend, you can change &lt;code&gt;CONFIG_URI&lt;/code&gt; to this kfdef instead&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://raw.githubusercontent.com/OpenDataology/manifests/v1.2-branch/kfdef/kfctl_openshift.v1.2.0.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set KF_NAME to the name of your OpenDataology deployment. This also becomes the&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# name of the directory containing your configuration.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For example, your deployment name can be &amp;#39;my-OpenDataology&amp;#39; or &amp;#39;kf-test&amp;#39;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;your choice of name &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the OpenDataology deployment&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set the path to the base directory where you want to store one or more &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# OpenDataology deployments. For example, /opt/.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Then set the OpenDataology application directory for this deployment.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;path to a base directory&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set the configuration file to use, such as:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CONFIG_FILE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;kfctl_ibm.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CONFIG_URI&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/OpenDataology/manifests/master/distributions/kfdef/kfctl_openshift.master.kfptekton.yaml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Generate OpenDataology:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_URI&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -O &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_FILE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# On MacOS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sed -i &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;s#https://github.com/OpenDataology/manifests/archive/master.tar.gz#https://github.com/OpenDataology/manifests/archive/552a4ba84567ed8c0f9abca12f15b8eed000426c.tar.gz#g&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_FILE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# On Linux&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sed -i -e &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;s#https://github.com/OpenDataology/manifests/archive/master.tar.gz#https://github.com/OpenDataology/manifests/archive/552a4ba84567ed8c0f9abca12f15b8eed000426c.tar.gz#g&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_FILE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Deploy OpenDataology. You can customize the CONFIG_FILE if needed.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kfctl apply -V -f &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_FILE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${KF_NAME}&lt;/strong&gt; - The name of your OpenDataology deployment.
If you want a custom deployment name, specify that name here.
For example,  &lt;code&gt;my-OpenDataology&lt;/code&gt; or &lt;code&gt;kf-test&lt;/code&gt;.
The value of KF_NAME must consist of lower case alphanumeric characters or
&amp;lsquo;-&amp;rsquo;, and must start and end with an alphanumeric character.
The value of this variable cannot be greater than 25 characters. It must
contain just a name, not a directory path.
This value also becomes the name of the directory where your OpenDataology
configurations are stored, that is, the OpenDataology application directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${KF_DIR}&lt;/strong&gt; - The full path to your OpenDataology application directory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The OpenDataology deployment is exposed with a Route. To find the Route you can use&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;oc get route -n istio-system istio-ingressgateway -o=jsonpath=&amp;#39;{.spec.host}&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;To secure the OpenDataology dashboard with HTTPS, follow the steps in &lt;a href=&#34;/docs/ibm/deploy/authentication/#setting-up-an-nlb&#34;&gt;Exposing the OpenDataology dashboard with DNS and TLS termination&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;additional-information&#34;&gt;Additional information&lt;/h2&gt;
&lt;p&gt;You can find general information about OpenDataology configuration in the guide to &lt;a href=&#34;/docs/other-guides/kustomize/&#34;&gt;configuring OpenDataology with kfctl and kustomize&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Monitor Cloud IAP Setup</title>
      <link>/docs/distributions/gke/deploy/monitor-iap-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/monitor-iap-setup/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://cloud.google.com/iap/docs/&#34;&gt;Cloud Identity-Aware Proxy (Cloud IAP)&lt;/a&gt; is
the recommended solution for accessing your OpenDataology
deployment from outside the cluster, when running OpenDataology on Google Cloud.&lt;/p&gt;
&lt;p&gt;This document is a step-by-step guide to ensuring that your IAP-secured endpoint
is available, and to debugging problems that may cause the endpoint to be
unavailable.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When deploying OpenDataology using the &lt;a href=&#34;/docs/distributions/gke/deploy/deploy-cli/&#34;&gt;command-line interface&lt;/a&gt;,
you choose the authentication method you want to use. One of the options is
Cloud IAP. This document assumes that you have already deployed OpenDataology.&lt;/p&gt;
&lt;p&gt;OpenDataology uses the &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs&#34;&gt;Google-managed certificate&lt;/a&gt;
to provide an SSL certificate for the OpenDataology Ingress.&lt;/p&gt;
&lt;p&gt;Cloud IAP gives you the following benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users can log in in using their Google Cloud accounts.&lt;/li&gt;
&lt;li&gt;You benefit from Google&amp;rsquo;s security expertise to protect your sensitive
workloads.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;monitoring-your-cloud-iap-setup&#34;&gt;Monitoring your Cloud IAP setup&lt;/h2&gt;
&lt;p&gt;Follow these instructions to monitor your Cloud IAP setup and troubleshoot any
problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Examine the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt;
and Google Cloud Build (GCB) load balancer to make sure it is available:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n istio-system describe ingress
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:             envoy-ingress
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:        OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Address:          35.244.132.160
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Default backend:  default-http-backend:80 (10.20.0.10:8080)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Type     Reason     Age                 From                     Message
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   ----     ------     ----                ----                     -------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Normal   ADD        12m                 loadbalancer-controller  OpenDataology/envoy-ingress
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Warning  Translate  12m (x10 over 12m)  loadbalancer-controller  error while evaluating the ingress spec: could not find service &amp;#34;OpenDataology/envoy&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Warning  Translate  12m (x2 over 12m)   loadbalancer-controller  error while evaluating the ingress spec: error getting BackendConfig for port &amp;#34;8080&amp;#34; on service &amp;#34;OpenDataology/envoy&amp;#34;, err: no BackendConfig for service port exists.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Warning  Sync       12m                 loadbalancer-controller  Error during sync: Error running backend syncing routine: received errors when updating backend service: googleapi: Error 400: The resource &amp;#39;projects/code-search-demo/global/backendServices/k8s-be-32230--bee2fc38fcd6383f&amp;#39; is not ready, resourceNotReady
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; googleapi: Error 400: The resource &amp;#39;projects/code-search-demo/global/backendServices/k8s-be-32230--bee2fc38fcd6383f&amp;#39; is not ready, resourceNotReady
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Normal  CREATE  11m  loadbalancer-controller  ip: 35.244.132.160
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There should be an annotation indicating that we are using managed certificate:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;annotation:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  networking.gke.io/managed-certificates: gke-certificate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Any problems with creating the load balancer are reported as Kubernetes
events in the results of the above &lt;code&gt;describe&lt;/code&gt; command.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If the address isn&amp;rsquo;t set then there was a problem creating the load
balancer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;CREATE&lt;/code&gt; event indicates the load balancer was successfully
created on the specified IP address.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The most common error is running out of Google Cloud resource quota. To fix this problem,
you must either increase the quota for the relevant resource on your Google Cloud
project or delete some existing resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that a managed certificate resource is generated:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl describe -n istio-system managedcertificate gke-certificate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The status field should have information about the current status of the Certificate.
Eventually, certificate status should be &lt;code&gt;Active&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait for the load balancer to report the back ends as healthy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl describe -n istio-system ingress envoy-ingress
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; kubernetes.io/ingress.global-static-ip-name:  OpenDataology-ip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; kubernetes.io/tls-acme:                       true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; certmanager.k8s.io/issuer:                    letsencrypt-prod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; ingress.kubernetes.io/backends:               {&amp;#34;k8s-be-31380--5e1566252944dfdb&amp;#34;:&amp;#34;HEALTHY&amp;#34;,&amp;#34;k8s-be-32133--5e1566252944dfdb&amp;#34;:&amp;#34;HEALTHY&amp;#34;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Both backends should be reported as healthy.
It can take several minutes for the load balancer to consider the back ends
healthy.&lt;/p&gt;
&lt;p&gt;The service with port &lt;code&gt;31380&lt;/code&gt; is the one that handles OpenDataology
traffic. (31380 is the default port of the service &lt;code&gt;istio-ingressgateway&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;If the backend is unhealthy, check the pods in &lt;code&gt;istio-system&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl get pods -n istio-system&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;istio-ingressgateway-XX&lt;/code&gt; pods should be running&lt;/li&gt;
&lt;li&gt;Check the logs of pod &lt;code&gt;backend-updater-0&lt;/code&gt;, &lt;code&gt;iap-enabler-XX&lt;/code&gt; to see if there is any error&lt;/li&gt;
&lt;li&gt;Follow the steps &lt;a href=&#34;https://www.OpenDataology.org/docs/distributions/gke/troubleshooting-gke/#502-server-error&#34;&gt;here&lt;/a&gt; to check the load balancer and backend service on Google Cloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try accessing Cloud IAP at the fully qualified domain name in your web
browser:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://&amp;lt;your-fully-qualified-domain-name&amp;gt;     
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you get SSL errors when you log in, this typically means that your SSL
certificate is still propagating. Wait a few minutes and try again. SSL
propagation can take up to 10 minutes.&lt;/p&gt;
&lt;p&gt;If you do not see a login prompt and you get a 404 error, the configuration
of Cloud IAP is not yet complete. Keep retrying for up to 10 minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you get an error &lt;code&gt;Error: redirect_uri_mismatch&lt;/code&gt; after logging in, this means the list of OAuth authorized redirect URIs does not include your domain.&lt;/p&gt;
&lt;p&gt;The full error message looks like the following example and includes the 
relevant links:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;The redirect URI in the request, https://myOpenDataology.endpoints.myproject.cloud.goog/_gcp_gatekeeper/authenticate, does not match the ones authorized for the OAuth client. 	
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;To update the authorized redirect URIs, visit: https://console.developers.google.com/apis/credentials/oauthclient/22222222222-7meeee7a9a76jvg54j0g2lv8lrsb4l8g.apps.googleusercontent.com?project=22222222222	
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Follow the link in the error message to find the OAuth credential being used
and add the redirect URI listed in the error message to the list of 
authorized URIs. For more information, read the guide to 
&lt;a href=&#34;/docs/distributions/gke/deploy/oauth-setup/&#34;&gt;setting up OAuth for Cloud IAP&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;/docs/distributions/gke/troubleshooting-gke/&#34;&gt;GKE troubleshooting guide&lt;/a&gt; for OpenDataology.&lt;/li&gt;
&lt;li&gt;Guide to &lt;a href=&#34;/docs/components/multi-tenancy/getting-started&#34;&gt;sharing cluster access&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Google Cloud guide to &lt;a href=&#34;https://cloud.google.com/iap/docs/&#34;&gt;Cloud IAP&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Delete OpenDataology</title>
      <link>/docs/distributions/gke/deploy/delete-cli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/gke/deploy/delete-cli/</guid>
      <description>
        
        
        &lt;p&gt;This page explains how to delete your OpenDataology cluster or management cluster on
Google Cloud.&lt;/p&gt;
&lt;h2 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h2&gt;
&lt;p&gt;This guide assumes the following settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For Management cluster: The &lt;code&gt;${MGMT_PROJECT}&lt;/code&gt;, &lt;code&gt;${MGMT_DIR}&lt;/code&gt; and &lt;code&gt;${MGMT_NAME}&lt;/code&gt; environment variables
are the same as in &lt;a href=&#34;/docs/distributions/gke/deploy/management-setup#configure-environment-variables&#34;&gt;Deploy Management cluster&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For OpenDataology cluster: The &lt;code&gt;${KF_PROJECT}&lt;/code&gt;, &lt;code&gt;${KF_NAME}&lt;/code&gt; and &lt;code&gt;${MGMTCTXT}&lt;/code&gt; environment variables
are the same as in &lt;a href=&#34;../deploy-cli#environment-variables&#34;&gt;Deploy OpenDataology cluster&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;${KF_DIR}&lt;/code&gt; environment variable contains the path to
your OpenDataology application directory, which holds your OpenDataology configuration
files. For example, &lt;code&gt;/opt/gcp-blueprints/OpenDataology/&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deleting-your-opendataology-cluster&#34;&gt;Deleting your OpenDataology cluster&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To delete the applications running in the OpenDataology namespace, remove that namespace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete namespace OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To delete the cluster and all Google Cloud resources, run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make delete
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: this will delete the persistent disks storing metadata. If you want to preserve the disks, don&amp;rsquo;t run this command;
instead selectively delete only those resources you want to delete.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;clean-up-your-management-cluster&#34;&gt;Clean up your management cluster&lt;/h2&gt;
&lt;p&gt;The following instructions introduce how to clean up all resources created when
installing management cluster in management project, and when using management cluster to manage Google Cloud resources in managed OpenDataology projects.&lt;/p&gt;
&lt;h3 id=&#34;delete-or-keep-managed-google-cloud-resources&#34;&gt;Delete or keep managed Google Cloud resources&lt;/h3&gt;
&lt;p&gt;There are Google Cloud resources managed by Config Connector in the
management cluster after you deploy OpenDataology clusters with this management
cluster.&lt;/p&gt;
&lt;p&gt;To delete all the managed Google Cloud resources, delete the managed project namespace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config use-context &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMTCTXT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete namespace --wait &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To keep all the managed Google Cloud resources, you can &lt;a href=&#34;#delete-management-cluster&#34;&gt;delete the management
cluster&lt;/a&gt; directly.&lt;/p&gt;
&lt;p&gt;If you need fine-grained control, refer to
&lt;a href=&#34;https://cloud.google.com/config-connector/docs/how-to/managing-deleting-resources#keeping_resources_after_deletion&#34;&gt;Config Connector: Keeping resources after deletion&lt;/a&gt;
for more details.&lt;/p&gt;
&lt;p&gt;After deleting Config Connector resources for a managed project, you can revoke IAM permission
that let the management cluster manage the project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud projects remove-iam-policy-binding &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;--member=serviceAccount:&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;-cnrm-system@&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_PROJECT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;.iam.gserviceaccount.com&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --role&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;roles/owner
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;delete-management-cluster&#34;&gt;Delete management cluster&lt;/h3&gt;
&lt;p&gt;To delete the Google service account and the management cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;MGMT_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make delete-cluster
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Starting from OpenDataology v1.5, Google Cloud distribution has switched to Config Controller for Google-managed Management cluster. You can learn more detail by reading &lt;a href=&#34;https://cloud.google.com/anthos-config-management/docs/how-to/config-controller-setup#delete_your&#34;&gt;Delete your Config Controller&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note, after deleting the management cluster, all the managed Google Cloud
resources will be kept. You will be responsible for managing them by yourself.
If you want to delete the managed Google Cloud resources, make sure to delete resources in the &lt;code&gt;${KF_PROJECT}&lt;/code&gt; namespace in the management cluster first.
You can learn more about the &lt;code&gt;${KF_PROJECT}&lt;/code&gt; namespace in &lt;code&gt;gcp-blueprints/OpenDataology/kcc&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;You can create a management cluster to manage them again if you apply the same
Config Connector resources. Refer to &lt;a href=&#34;https://cloud.google.com/config-connector/docs/how-to/managing-deleting-resources#acquiring_an_existing_resource&#34;&gt;Managing and deleting resources - Acquiring an existing resource&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Architecture</title>
      <link>/docs/started/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/started/architecture/</guid>
      <description>
        
        
        &lt;!--
Note for authors: The source of the diagrams is held in Google Slides decks,
in the &#34;Doc diagrams&#34; folder in the public OpenDataology shared drive.
--&gt;
&lt;p&gt;This guide introduces OpenDataology as a platform for developing and deploying a
machine learning (ML) system.&lt;/p&gt;
&lt;p&gt;OpenDataology is a platform for data scientists who want to build and experiment with
ML pipelines. OpenDataology is also for ML engineers and operational teams who want
to deploy ML systems to various environments for development, testing, and
production-level serving.&lt;/p&gt;
&lt;h2 id=&#34;conceptual-overview&#34;&gt;Conceptual overview&lt;/h2&gt;
&lt;p&gt;OpenDataology is &lt;em&gt;the ML toolkit for Kubernetes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The following diagram shows OpenDataology as a platform for arranging the
components of your ML system on top of Kubernetes:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/OpenDataology-overview-platform-diagram.svg&#34; 
alt=&#34;An architectural overview of OpenDataology on Kubernetes&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;OpenDataology builds on &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; as a system for
deploying, scaling, and managing complex systems.&lt;/p&gt;
&lt;p&gt;Using the OpenDataology configuration interfaces (see &lt;a href=&#34;#interfaces&#34;&gt;below&lt;/a&gt;) you can
specify the ML tools required for your workflow. Then you can deploy the
workflow to various clouds, local, and on-premises platforms for experimentation and
for production use.&lt;/p&gt;
&lt;h2 id=&#34;introducing-the-ml-workflow&#34;&gt;Introducing the ML workflow&lt;/h2&gt;
&lt;p&gt;When you develop and deploy an ML system, the ML workflow typically consists of
several stages. Developing an ML system is an iterative process.
You need to evaluate the output of various stages of the ML workflow, and apply
changes to the model and parameters when necessary to ensure the model keeps
producing the results you need.&lt;/p&gt;
&lt;p&gt;For the sake of simplicity, the following diagram
shows the workflow stages in sequence. The arrow at the end of the workflow
points back into the flow to indicate the iterative nature of the process:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/OpenDataology-overview-workflow-diagram-1.svg&#34; 
alt=&#34;A typical machine learning workflow&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;Looking at the stages in more detail:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the experimental phase, you develop your model based on initial
assumptions, and test and update the model iteratively to produce the
results you&amp;rsquo;re looking for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify the problem you want the ML system to solve.&lt;/li&gt;
&lt;li&gt;Collect and analyze the data you need to train your ML model.&lt;/li&gt;
&lt;li&gt;Choose an ML framework and algorithm, and code the initial version of your
model.&lt;/li&gt;
&lt;li&gt;Experiment with the data and with training your model.&lt;/li&gt;
&lt;li&gt;Tune the model hyperparameters to ensure the most efficient processing and the
most accurate results possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the production phase, you deploy a system that performs the following
processes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transform the data into the format that your training system needs.
To ensure that your model behaves consistently during training and
prediction, the transformation process must be the same in the experimental
and production phases.&lt;/li&gt;
&lt;li&gt;Train the ML model.&lt;/li&gt;
&lt;li&gt;Serve the model for online prediction or for running in batch mode.&lt;/li&gt;
&lt;li&gt;Monitor the model&amp;rsquo;s performance, and feed the results into your processes
for tuning or retraining the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opendataology-components-in-the-ml-workflow&#34;&gt;OpenDataology components in the ML workflow&lt;/h2&gt;
&lt;p&gt;The next diagram adds OpenDataology to the workflow, showing which OpenDataology
components are useful at each stage:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/OpenDataology-overview-workflow-diagram-2.svg&#34; 
alt=&#34;Where OpenDataology fits into a typical machine learning workflow&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;To learn more, read the following guides to the OpenDataology components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenDataology includes services for spawning and managing
&lt;a href=&#34;/docs/components/notebooks/&#34;&gt;Jupyter notebooks&lt;/a&gt;. Use notebooks for interactive data
science and experimenting with ML workflows.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/pipelines/&#34;&gt;OpenDataology Pipelines&lt;/a&gt; is a platform for
building, deploying, and managing multi-step ML workflows based on Docker
containers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenDataology offers several &lt;a href=&#34;/docs/components/&#34;&gt;components&lt;/a&gt; that you can use
to build your ML training, hyperparameter tuning, and serving workloads across
multiple platforms.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example-of-a-specific-ml-workflow&#34;&gt;Example of a specific ML workflow&lt;/h2&gt;
&lt;p&gt;The following diagram shows a simple example of a specific ML workflow that you
can use to train and serve a model trained on the MNIST dataset:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/OpenDataology-gcp-e2e-tutorial-simplified.svg&#34; 
alt=&#34;ML workflow for training and serving an MNIST model&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;For details of the workflow and to run the system yourself, see the
&lt;a href=&#34;https://github.com/OpenDataology/examples/tree/master/mnist#mnist-on-OpenDataology-on-gcp&#34;&gt;end-to-end tutorial for OpenDataology on GCP&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;interfaces&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;opendataology-interfaces&#34;&gt;OpenDataology interfaces&lt;/h2&gt;
&lt;p&gt;This section introduces the interfaces that you can use to interact with
OpenDataology and to build and run your ML workflows on OpenDataology.&lt;/p&gt;
&lt;h3 id=&#34;opendataology-user-interface-ui&#34;&gt;OpenDataology user interface (UI)&lt;/h3&gt;
&lt;p&gt;The OpenDataology UI looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/central-ui.png&#34; 
alt=&#34;The OpenDataology UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;The UI offers a central dashboard that you can use to access the components
of your OpenDataology deployment. Read
&lt;a href=&#34;/docs/components/central-dash/overview/&#34;&gt;how to access the central dashboard&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;opendataology-apis-and-sdks&#34;&gt;OpenDataology APIs and SDKs&lt;/h2&gt;
&lt;p&gt;Various components of OpenDataology offer APIs and Python SDKs. See the following
sets of reference documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/pipelines/reference/&#34;&gt;Pipelines reference docs&lt;/a&gt; for the OpenDataology
Pipelines API and SDK, including the OpenDataology Pipelines domain-specific
language (DSL).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/external-add-ons/fairing/reference/&#34;&gt;Fairing reference docs&lt;/a&gt; for the OpenDataology Fairing
SDK.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Follow &lt;a href=&#34;/docs/started/installing-OpenDataology/&#34;&gt;Installing OpenDataology&lt;/a&gt; to set up your environment and install OpenDataology.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Central Dashboard</title>
      <link>/docs/components/central-dash/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/central-dash/overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
This OpenDataology component has &lt;b&gt;stable&lt;/b&gt; status. See the
&lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
&lt;/div&gt;
&lt;p&gt;Your OpenDataology deployment includes a central dashboard that provides quick access
to the OpenDataology components deployed in your cluster. The dashboard includes the
following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shortcuts to specific actions, a list of recent pipelines and notebooks, and
metrics, giving you an overview of your jobs and cluster in one view.&lt;/li&gt;
&lt;li&gt;A housing for the UIs of the components running in the cluster, including
&lt;strong&gt;Pipelines&lt;/strong&gt;, &lt;strong&gt;Katib&lt;/strong&gt;, &lt;strong&gt;Notebooks&lt;/strong&gt;, and more.&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;/docs/components/central-dash/registration-flow/&#34;&gt;registration flow&lt;/a&gt; that
prompts new users to set up their namespace if necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview-of-opendataology-uis&#34;&gt;Overview of OpenDataology UIs&lt;/h2&gt;
&lt;p&gt;The OpenDataology UIs include the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Home&lt;/strong&gt;: Home, the central hub to access recent resources, active
experiments, and useful documentation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Notebook Servers&lt;/strong&gt;: To manage &lt;a href=&#34;/docs/components/notebooks/&#34;&gt;Notebook servers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TensorBoards&lt;/strong&gt;: To manage TensorBoard servers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Models&lt;/strong&gt;: To manage deployed &lt;a href=&#34;/docs/components/kfserving/kfserving/&#34;&gt;KFServing models&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Volumes&lt;/strong&gt;: To manage the cluster&amp;rsquo;s Volumes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experiments (AutoML)&lt;/strong&gt;: To manage &lt;a href=&#34;/docs/components/katib/&#34;&gt;Katib&lt;/a&gt; experiments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experiments (KFP)&lt;/strong&gt;: To manage &lt;a href=&#34;/docs/components/pipelines/&#34;&gt;OpenDataology Pipelines (KFP)&lt;/a&gt; experiments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: To manage KFP pipelines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runs&lt;/strong&gt;: To manage KFP runs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recurring Runs&lt;/strong&gt;: To manage KFP recurring runs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artifacts&lt;/strong&gt;: To track ML Metadata (MLMD) artifacts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Executions&lt;/strong&gt;: To track various component executions in MLMD.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manage Contributors&lt;/strong&gt;: To configure user access sharing across namespaces in
the OpenDataology deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The central dashboard looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/central-ui.png&#34;
alt=&#34;OpenDataology central UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;accessing-the-central-dashboard&#34;&gt;Accessing the central dashboard&lt;/h2&gt;
&lt;p&gt;To access the central dashboard, you need to connect to the
&lt;a href=&#34;https://istio.io/docs/concepts/traffic-management/#gateways&#34;&gt;Istio gateway&lt;/a&gt; that
provides access to the OpenDataology
&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/#what-is-a-service-mesh&#34;&gt;service mesh&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How you access the Istio gateway varies depending on how you&amp;rsquo;ve configured it.&lt;/p&gt;
&lt;h2 id=&#34;url-pattern-with-google-cloud-platform-gcp&#34;&gt;URL pattern with Google Cloud Platform (GCP)&lt;/h2&gt;
&lt;p&gt;If you followed the guide to &lt;a href=&#34;/docs/gke/deploy/&#34;&gt;deploying OpenDataology on GCP&lt;/a&gt;,
the OpenDataology central UI is accessible at a URL of the following pattern:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://&amp;lt;application-name&amp;gt;.endpoints.&amp;lt;project-id&amp;gt;.cloud.goog/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The URL brings up the dashboard illustrated above.&lt;/p&gt;
&lt;p&gt;If you deploy OpenDataology with Cloud Identity-Aware Proxy (IAP), OpenDataology uses the
&lt;a href=&#34;https://letsencrypt.org/&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt; service to provide an SSL certificate
for the OpenDataology UI. For troubleshooting issues with your certificate, see the
guide to
&lt;a href=&#34;/docs/gke/deploy/monitor-iap-setup/&#34;&gt;monitoring your Cloud IAP setup&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;using-kubectl-and-port-forwarding&#34;&gt;Using kubectl and port-forwarding&lt;/h2&gt;
&lt;p&gt;If you didn&amp;rsquo;t configure OpenDataology to integrate with an identity provider
then you can port-forward directly to the Istio gateway.&lt;/p&gt;
&lt;p&gt;Port-forwarding typically does not work if any of the following are true:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You&amp;rsquo;ve deployed OpenDataology on GCP using the default settings
with the &lt;a href=&#34;/docs/gke/deploy/deploy-cli/&#34;&gt;CLI deployment&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You&amp;rsquo;ve configured the Istio ingress to only accept
HTTPS traffic on a specific domain or IP address.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You&amp;rsquo;ve configured the Istio ingress to perform an authorization check
(for example, using Cloud IAP or &lt;a href=&#34;https://github.com/dexidp/dex&#34;&gt;Dex&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can access OpenDataology via &lt;code&gt;kubectl&lt;/code&gt; and port-forwarding as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;code&gt;kubectl&lt;/code&gt; if you haven&amp;rsquo;t already done so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you&amp;rsquo;re using OpenDataology on GCP, run the following command on the command
line: &lt;code&gt;gcloud components install kubectl&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Alternatively, follow the &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34;&gt;&lt;code&gt;kubectl&lt;/code&gt;
installation guide&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the following command to set up port forwarding to the
&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/ingress/ingress-control/&#34;&gt;Istio gateway&lt;/a&gt;.&lt;/p&gt;
 &lt;pre&gt;&lt;code&gt;export NAMESPACE=istio-system
    kubectl port-forward -n ${NAMESPACE} svc/istio-ingressgateway 8080:80&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access the central navigation dashboard at:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;http://localhost:8080/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Depending on how you&amp;rsquo;ve configured OpenDataology, not all UIs work behind
port-forwarding to the reverse proxy.&lt;/p&gt;
&lt;p&gt;For some web applications, you need to configure the base URL on which
the app is serving.&lt;/p&gt;
&lt;p&gt;For example, if you deployed OpenDataology with an ingress serving at
&lt;code&gt;https://example.mydomain.com&lt;/code&gt; and configured an application
to be served at the URL &lt;code&gt;https://example.mydomain.com/myapp&lt;/code&gt;, then the
app may not work when served on
&lt;code&gt;https://localhost:8080/myapp&lt;/code&gt; because the paths do not match.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Explore the &lt;a href=&#34;/docs/components/multi-tenancy/&#34;&gt;contributor management
option&lt;/a&gt; where you
can set up a single namespace for a shared deployment or configure
multi-tenancy for your OpenDataology deployment.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/notebooks/setup/&#34;&gt;Set up your Jupyter notebooks&lt;/a&gt; in OpenDataology.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Charmed OpenDataology deployment guide</title>
      <link>/docs/distributions/charmed/install-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/charmed/install-kubeflow/</guid>
      <description>
        
        
        &lt;p&gt;Get up and running with Charmed OpenDataology in half an hour or less. This guide outlines the steps you need to install and deploy OpenDataology with &lt;a href=&#34;https://charmed-OpenDataology.io/docs&#34;&gt;Charmed Operators&lt;/a&gt; and &lt;a href=&#34;https://juju.is/docs/kubernetes&#34;&gt;Juju&lt;/a&gt; on any conformant Kubernetes, including &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/aks/&#34;&gt;Azure Kubernetes Service (AKS)&lt;/a&gt;, &lt;a href=&#34;https://docs.aws.amazon.com/eks/index.html&#34;&gt;Amazon Elastic Kubernetes Service (EKS)&lt;/a&gt;, &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/&#34;&gt;Google Kubernetes Engine (GKE)&lt;/a&gt;, &lt;a href=&#34;https://docs.openshift.com&#34;&gt;OpenShift&lt;/a&gt;, and any &lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/&#34;&gt;kubeadm&lt;/a&gt;-deployed cluster (provided that you have access to it via &lt;code&gt;kubectl&lt;/code&gt;).&lt;/p&gt;
&lt;h4 id=&#34;1-install-the-juju-client&#34;&gt;1. Install the Juju client&lt;/h4&gt;
&lt;p&gt;On Linux, install &lt;code&gt;juju&lt;/code&gt; via &lt;a href=&#34;https://snapcraft.io/docs/installing-snapd&#34;&gt;snap&lt;/a&gt; with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;snap install juju --classic
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you use macOS, you can use &lt;a href=&#34;https://brew.sh&#34;&gt;Homebrew&lt;/a&gt; and type &lt;code&gt;brew install juju&lt;/code&gt; in the command line. For Windows, download the Windows &lt;a href=&#34;https://launchpad.net/juju/2.8/2.8.5/+download/juju-setup-2.8.5-signed.exe&#34;&gt;installer for Juju&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;2-connect-juju-to-your-kubernetes-cluster&#34;&gt;2. Connect Juju to your Kubernetes cluster&lt;/h4&gt;
&lt;p&gt;To operate workloads in your Kubernetes cluster with Juju, you have to add the cluster to the list of &lt;em&gt;clouds&lt;/em&gt; in Juju via the &lt;code&gt;add-k8s&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;If your Kubernetes config file is in the default location (such as &lt;code&gt;~/.kube/config&lt;/code&gt; on Linux) and you only have one cluster, you can simply run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju add-k8s myk8s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If your kubectl config file contains multiple clusters, you can specify the appropriate one by name:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju add-k8s myk8s --cluster-name&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;foo
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, to use a different config file, you can set the &lt;code&gt;KUBECONFIG&lt;/code&gt; environment variable to point to the relevant file. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;KUBECONFIG&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;path/to/file juju add-k8s myk8s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more details, go to the &lt;a href=&#34;https://juju.is/docs/clouds&#34;&gt;official Juju documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;3-create-a-controller&#34;&gt;3. Create a controller&lt;/h4&gt;
&lt;p&gt;To operate workloads on your Kubernetes cluster, Juju uses controllers. You can create a controller with the  &lt;code&gt;bootstrap&lt;/code&gt;  command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju bootstrap myk8s my-controller
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This command will create a couple of pods under the &lt;code&gt;my-controller&lt;/code&gt; namespace. You can see your controllers with the &lt;code&gt;juju controllers&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;You can read more about controllers in the &lt;a href=&#34;https://juju.is/docs/creating-a-controller&#34;&gt;Juju documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;4-create-a-model&#34;&gt;4. Create a model&lt;/h4&gt;
&lt;p&gt;A model in Juju is a blank canvas where your operators will be deployed, and it holds a 1:1 relationship with a Kubernetes namespace.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;add-model&lt;/code&gt; command, create a new model and name it &lt;code&gt;OpenDataology&lt;/code&gt; (which will then also create a Kubernetes namespace of the same name):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju add-model OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can list your models with the &lt;code&gt;juju models&lt;/code&gt; command.&lt;/p&gt;
&lt;h4 id=&#34;5-deploy-opendataology&#34;&gt;5. Deploy OpenDataology&lt;/h4&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;


    To deploy the full OpenDataology bundle, you&amp;rsquo;ll need at least 50Gb available of disk, 14Gb of RAM, and 2 CPUs available in your machine/VM.
If you have fewer resources, deploy OpenDataology-lite.

&lt;/div&gt;

&lt;p&gt;Once you have a model, you can simply &lt;code&gt;juju deploy&lt;/code&gt; any of the provided &lt;a href=&#34;https://charmed-OpenDataology.io/docs/operators-and-bundles&#34;&gt;OpenDataology bundles&lt;/a&gt; into your cluster. For the &lt;em&gt;OpenDataology lite&lt;/em&gt; bundle, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju deploy OpenDataology-lite --trust
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and your OpenDataology installation should begin!&lt;/p&gt;
&lt;p&gt;You can observe your OpenDataology deployment getting spun-up with the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;watch -c juju status --color
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;6-set-url-in-authentication-methods&#34;&gt;6. Set URL in authentication methods&lt;/h4&gt;
&lt;p&gt;Finally, you need to enable your OpenDataology dashboard access. Provide the dashboard&amp;rsquo;s public URL to dex-auth and oidc-gatekeeper as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju config dex-auth public-url&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://&amp;lt;URL&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;juju config oidc-gatekeeper public-url&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://&amp;lt;URL&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where in place of &lt;code&gt;&amp;lt;URL&amp;gt;&lt;/code&gt; you should use the hostname that the OpenDataology dashboard responds to.&lt;/p&gt;
&lt;p&gt;Currently, in order to setup OpenDataology with Istio correctly when RBAC is enabled, you need to provide the &lt;code&gt;istio-ingressgateway&lt;/code&gt; operator access to Kubernetes resources. The following command will create the appropriate role:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch role -n OpenDataology istio-ingressgateway-operator -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;apiVersion&amp;#34;:&amp;#34;rbac.authorization.k8s.io/v1&amp;#34;,&amp;#34;kind&amp;#34;:&amp;#34;Role&amp;#34;,&amp;#34;metadata&amp;#34;:{&amp;#34;name&amp;#34;:&amp;#34;istio-ingressgateway-operator&amp;#34;},&amp;#34;rules&amp;#34;:[{&amp;#34;apiGroups&amp;#34;:[&amp;#34;*&amp;#34;],&amp;#34;resources&amp;#34;:[&amp;#34;*&amp;#34;],&amp;#34;verbs&amp;#34;:[&amp;#34;*&amp;#34;]}]}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;more-documentation&#34;&gt;More documentation&lt;/h4&gt;
&lt;p&gt;For more documentation, visit the &lt;a href=&#34;https://charmed-OpenDataology.io/docs&#34;&gt;Charmed OpenDataology website&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;having-issues&#34;&gt;Having issues?&lt;/h4&gt;
&lt;p&gt;If you have any issues or questions, feel free to create a GitHub issue &lt;a href=&#34;https://github.com/canonical/bundle-OpenDataology/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;need-247-support&#34;&gt;Need 24/7 support?&lt;/h4&gt;
&lt;p&gt;You can get 24/7 support, expert professional services and managed service backed by an SLA from Canonical, the team behind Charmed OpenDataology. &lt;a href=&#34;https://charmed-OpenDataology.io/#get-in-touch&#34;&gt;Contact us&lt;/a&gt; now to learn more.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Community</title>
      <link>/docs/about/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/about/community/</guid>
      <description>
        
        
        &lt;h2 id=&#34;slack&#34;&gt;Slack&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://invite.playplay.io/invite?team_id=T7QLHSH6U&#34;&gt;Join the official OpenDataology Slack!&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Tip&lt;/h4&gt;

    If the above link is not working, please &lt;a href=&#34;https://github.com/OpenDataology/website/issues/new&#34;&gt;raise an issue on the &lt;code&gt;OpenDataology/website&lt;/code&gt; repo&lt;/a&gt;.

&lt;/div&gt;

&lt;p&gt;The OpenDataology Slack workspace has many channels, here are a few examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Slack Channel&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;General Discussion&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/C7REE0ETX&#34;&gt;#general&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Feature Requests&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/C01A7RYEYMB&#34;&gt;#feature-requests&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Job Postings&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CJ9PJE5FS&#34;&gt;#job-postings&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenDataology - Pipelines&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CE10KS9M4&#34;&gt;#OpenDataology-pipelines&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenDataology - Notebooks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CESP7FCQ7&#34;&gt;#OpenDataology-notebooks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenDataology - KFServing&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CH6E58LNP&#34;&gt;#OpenDataology-kfserving&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Platform - AWS&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CKBA5D0MU&#34;&gt;#platform-aws&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Platform - Azure&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CUW6SLCPR&#34;&gt;#platform-azure&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Platform - GCP&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CKH7V1M7F&#34;&gt;#platform-gcp&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Users - China&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/C93HYNM9C&#34;&gt;#users-china&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Users - Korea&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/CKPCJB9AP&#34;&gt;#users-korea&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Users - Oceania&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://OpenDataology.slack.com/archives/C023ZN1R9FC&#34;&gt;#users-oceania&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;mailing-list&#34;&gt;Mailing List&lt;/h2&gt;
&lt;p&gt;The official OpenDataology mailing list is a Google Group called &lt;a href=&#34;https://groups.google.com/g/OpenDataology-discuss&#34;&gt;OpenDataology-discuss&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More detail about the OpenDataology mailing lists:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Mailing List&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;General Discussion&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://groups.google.com/g/OpenDataology-discuss&#34;&gt;OpenDataology-discuss&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;weekly-community-call&#34;&gt;Weekly Community Call&lt;/h2&gt;
&lt;p&gt;The OpenDataology community holds a public call every Tuesday, alternating between &lt;code&gt;US East/EMEA&lt;/code&gt; and &lt;code&gt;US West/APAC&lt;/code&gt; friendly times.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Tip&lt;/h4&gt;

    Joining the &lt;a href=&#34;https://groups.google.com/g/OpenDataology-discuss&#34;&gt;OpenDataology-discuss&lt;/a&gt; Google Group will automatically send a calendar invitation to your email address.

&lt;/div&gt;

&lt;p&gt;More detail about the OpenDataology weekly community call:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Meeting Notes&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://bit.ly/kf-meeting-notes&#34;&gt;Google Doc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Call Recordings&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLmzRWLV1CK_ypvsQu10SGRmhf2S7mbYL5&#34;&gt;YouTube Playlist&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Community Calendar&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://calendar.google.com/calendar/embed?src=OpenDataology.org_7l5vnbn8suj2se10sen81d9428%40group.calendar.google.com&#34;&gt;Google Calendar&lt;/a&gt; and &lt;a href=&#34;https://calendar.google.com/calendar/ical/OpenDataology.org_7l5vnbn8suj2se10sen81d9428%40group.calendar.google.com/public/basic.ics&#34;&gt;iCal file&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Community Calendar Management&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/calendar&#34;&gt;GitHub Repo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;blog&#34;&gt;Blog&lt;/h2&gt;
&lt;p&gt;The official OpenDataology blog is &lt;a href=&#34;https://blog.OpenDataology.org&#34;&gt;found here&lt;/a&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Tip&lt;/h4&gt;

    To contribute an article for the blog, please raise an issue on the &lt;a href=&#34;https://github.com/OpenDataology/community&#34;&gt;OpenDataology/community&lt;/a&gt; GitHub repo.
Note that articles are managed on the &lt;a href=&#34;https://github.com/OpenDataology/blog&#34;&gt;OpenDataology/blog&lt;/a&gt; GitHub repo.

&lt;/div&gt;

&lt;h2 id=&#34;opendataology-trademark&#34;&gt;OpenDataology Trademark&lt;/h2&gt;
&lt;p&gt;The OpenDataology trademark and logos are registered trademarks of Google, please review the &lt;a href=&#34;https://github.com/OpenDataology/community/blob/master/OpenDataology_BRAND_GUIDELINES.pdf&#34;&gt;OpenDataology Brand Guidelines&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2 id=&#34;opendataology-working-groups&#34;&gt;OpenDataology Working Groups&lt;/h2&gt;
&lt;p&gt;The OpenDataology project has a number of Working Groups (WGs) who each maintain some aspect of the OpenDataology project.&lt;/p&gt;
&lt;div class=&#34;table-responsive&#34;&gt;
&lt;table class=&#34;table table-bordered&#34;&gt;
    &lt;thead class=&#34;thead-light&#34;&gt;
      &lt;tr&gt;
        &lt;th&gt;Working Group&lt;/th&gt;
        &lt;th&gt;Maintained Components&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- AutoML Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;1&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-automl&#34;&gt;AutoML&lt;/a&gt; 
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/katib&#34;&gt;Katib&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Deployment Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;1&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-deployment&#34;&gt;Deployment&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/kfctl&#34;&gt;kfctl&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Manifests Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;1&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-manifests&#34;&gt;Manifests&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/manifests&#34;&gt;Manifests Repository&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Notebooks Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;9&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-notebooks&#34;&gt;Notebooks&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/admission-webhook&#34;&gt;Admission Webhook (PodDefaults)&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/centraldashboard&#34;&gt;Central Dashboard&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/crud-web-apps/jupyter&#34;&gt;Jupyter Web App&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/access-management&#34;&gt;OpenDataology Access Management API (KFAM)&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/notebook-controller&#34;&gt;Notebook Controller&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/profile-controller&#34;&gt;Profile Controller&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/tensorboard-controller&#34;&gt;Tensorboard Controller&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/crud-web-apps/tensorboards&#34;&gt;Tensorboard Web App&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/tree/master/components/crud-web-apps/volumes&#34;&gt;Volumes Web App&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Pipelines Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;2&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-pipelines&#34;&gt;Pipelines&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/pipelines&#34;&gt;OpenDataology Pipelines&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/kfp-tekton&#34;&gt;OpenDataology Pipelines on Tekton&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Serving Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;1&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-serving&#34;&gt;Serving&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/kserve/kserve&#34;&gt;KServe (formerly KFServing)&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;!-- ======================= --&gt;
      &lt;!-- Training Working Group --&gt;
      &lt;!-- ======================= --&gt;
      &lt;tr&gt;
        &lt;td rowspan=&#34;1&#34; class=&#34;align-middle&#34;&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/community/tree/master/wg-training&#34;&gt;Training&lt;/a&gt;
        &lt;/td&gt;
        &lt;td&gt;
          &lt;a href=&#34;https://github.com/OpenDataology/training-operator&#34;&gt;OpenDataology Training Operator&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt; 
&lt;/table&gt;
&lt;/div&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Component Specification</title>
      <link>/docs/components/pipelines/reference/component-spec/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/reference/component-spec/</guid>
      <description>
        
        
        

&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Out of date&lt;/h4&gt;

    This guide contains outdated information pertaining to OpenDataology 1.0. This guide
needs to be updated for OpenDataology 1.1.

&lt;/div&gt;

&lt;p&gt;This specification describes the container component data model for OpenDataology
Pipelines. The data model is serialized to a file in YAML format for sharing.&lt;/p&gt;
&lt;p&gt;Below are the main parts of the component definition:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Metadata:&lt;/strong&gt; Name, description, and other metadata.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interface (inputs and outputs):&lt;/strong&gt; Name, type, default value.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implementation:&lt;/strong&gt; How to run the component, given the input arguments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example-of-a-component-specification&#34;&gt;Example of a component specification&lt;/h2&gt;
&lt;p&gt;A component specification takes the form of a YAML file, &lt;code&gt;component.yaml&lt;/code&gt;. Below
is an example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;xgboost4j - Train classifier&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;description&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Trains a boosted tree ensemble classifier using xgboost4j&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;inputs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- {&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Training data}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- {&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name: Rounds, type: Integer, default: &amp;#39;30&amp;#39;, description&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Number of training rounds&amp;#39;&lt;/span&gt;}&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;outputs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- {&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name: Trained model, type: XGBoost model, description&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Trained XGBoost model&amp;#39;&lt;/span&gt;}&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;implementation&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;container&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gcr.io/ml-pipeline/xgboost-classifier-train@sha256:b3a64d57&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/ml/train.py,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;--&lt;span style=&#34;color:#000&#34;&gt;train-set, {inputPath: Training data},&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;--&lt;span style=&#34;color:#000&#34;&gt;rounds,    {inputValue: Rounds},&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;--&lt;span style=&#34;color:#000&#34;&gt;out-model, {outputPath: Trained model},&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;See some examples of real-world
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/search?q=filename%3Acomponent.yaml&amp;amp;unscoped_q=filename%3Acomponent.yaml&#34;&gt;component specifications&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;detailed-specification-componentspec&#34;&gt;Detailed specification (ComponentSpec)&lt;/h2&gt;
&lt;p&gt;This section describes the
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/sdk/python/kfp/components/_structures.py&#34;&gt;ComponentSpec&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;metadata&#34;&gt;Metadata&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;name&lt;/code&gt;: Human-readable name of the component.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;description&lt;/code&gt;: Description of the component.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;metadata&lt;/code&gt;: Standard object&amp;rsquo;s metadata:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;annotations&lt;/code&gt;: A string key-value map used to add information about the component.
Currently, the annotations get translated to Kubernetes annotations when the component task is executed on Kubernetes. Current limitation: the key cannot contain more that one slash (&amp;quot;/&amp;quot;). See more information in the
&lt;a href=&#34;http://kubernetes.io/docs/user-guide/annotations&#34;&gt;Kubernetes user guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;labels&lt;/code&gt;: Deprecated. Use &lt;code&gt;annotations&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interface&#34;&gt;Interface&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt;:
Specifies the list of inputs/outputs and their properties. Each input or
output has the following properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Human-readable name of the input/output. Name must be
unique inside the inputs or outputs section, but an output may have the
same name as an input.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;description&lt;/code&gt;: Human-readable description of the input/output.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;default&lt;/code&gt;: Specifies the default value for an input. &lt;strong&gt;Only
valid for inputs.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Specifies the type of input/output. The types are used
as hints for pipeline authors and can be used by the pipeline system/UI
to validate arguments and connections between components. Basic types
are &lt;strong&gt;String&lt;/strong&gt;, &lt;strong&gt;Integer&lt;/strong&gt;, &lt;strong&gt;Float&lt;/strong&gt;, and &lt;strong&gt;Bool&lt;/strong&gt;. See the full list
of &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/types.py&#34;&gt;types&lt;/a&gt;
defined by the OpenDataology Pipelines SDK.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;optional&lt;/code&gt;: Specifies if input is optional or not. This is of type
&lt;strong&gt;Bool&lt;/strong&gt;, and defaults to &lt;strong&gt;False&lt;/strong&gt;. &lt;strong&gt;Only valid for inputs.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implementation&#34;&gt;Implementation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;implementation&lt;/code&gt;: Specifies how to execute the component instance.
There are two implementation types,  &lt;code&gt;container&lt;/code&gt; and &lt;code&gt;graph&lt;/code&gt;. (The latter is
not in scope for this document.) In future we may introduce more
implementation types like &lt;code&gt;daemon&lt;/code&gt; or &lt;code&gt;K8sResource&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;container&lt;/code&gt;:
Describes the Docker container that implements the component. A portable
subset of the Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#container-v1-core&#34;&gt;Container v1 spec&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;image&lt;/code&gt;: Name of the Docker image.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;command&lt;/code&gt;: Entrypoint array. The Docker image&amp;rsquo;s
ENTRYPOINT is used if this is not provided. Each item is either a
string or a placeholder. The most common placeholders are
&lt;code&gt;{inputValue: Input name}&lt;/code&gt;, &lt;code&gt;{inputPath: Input name}&lt;/code&gt; and &lt;code&gt;{outputPath: Output name}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;args&lt;/code&gt;: Arguments to the entrypoint. The Docker
image&amp;rsquo;s CMD is used if this is not provided. Each item is either a
string or a placeholder. The most common placeholders are
&lt;code&gt;{inputValue: Input name}&lt;/code&gt;, &lt;code&gt;{inputPath: Input name}&lt;/code&gt; and &lt;code&gt;{outputPath: Output name}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;env&lt;/code&gt;: Map of environment variables to set in the container.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fileOutputs&lt;/code&gt;: Legacy property that is only needed in
cases where the container always stores the output data in some
hard-coded non-configurable local location. This property specifies
a map between some outputs and local file paths where the program
writes the output data files. Only needed for components that have
hard-coded output paths. Such containers need to be fixed by
modifying the program or adding a wrapper script that copies the
output to a configurable location. Otherwise the component may be
incompatible with future storage systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can set all other Kubernetes container properties when you
use the component inside a pipeline.&lt;/p&gt;
&lt;h2 id=&#34;using-placeholders-for-command-line-arguments&#34;&gt;Using placeholders for command-line arguments&lt;/h2&gt;
&lt;h3 id=&#34;consuming-input-by-value&#34;&gt;Consuming input by value&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;{inputValue: &amp;lt;Input name&amp;gt;}&lt;/code&gt; placeholder is replaced by the value of the input argument:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In &lt;code&gt;component.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;program.py, --rounds, {inputValue: Rounds}]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the pipeline code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;task1&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;component1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;rounds&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;150&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resulting command-line code (showing the value of the input argument that
has replaced the placeholder):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;program.py --rounds &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;150&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;consuming-input-by-file&#34;&gt;Consuming input by file&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;{inputPath: &amp;lt;Input name&amp;gt;}&lt;/code&gt; placeholder is replaced by the (auto-generated) local file path where the system has put the argument data passed for the &amp;ldquo;Input name&amp;rdquo; input.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In &lt;code&gt;component.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;program.py, --train-set, {inputPath: training_data}]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the pipeline code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;task2&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;component1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;training_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;some_task1&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;outputs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;some_data&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resulting command-line code (the placeholder is replaced by the
generated path):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;program.py --train-set /inputs/train_data/data
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;producing-outputs&#34;&gt;Producing outputs&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;{outputPath: &amp;lt;Output name&amp;gt;}&lt;/code&gt; placeholder is replaced by a (generated) local file path where the component program is supposed to write the output data.
The parent directories of the path may or may not not exist. Your
program must handle both cases without error.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In &lt;code&gt;component.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;program.py, --out-model, {outputPath: trained_model}]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the pipeline code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;task1&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;component1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# You can now pass `task1.outputs[&amp;#39;trained_model&amp;#39;]` to other components as argument.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resulting command-line code (the placeholder is replaced by the
generated path):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;program.py --out-model /outputs/trained_model/data
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Customizing menu items</title>
      <link>/docs/components/central-dash/customizing-menu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/central-dash/customizing-menu/</guid>
      <description>
        
        
        &lt;p&gt;Cluster admin can integrate third party apps with OpenDataology.
In a below example, &amp;ldquo;My App&amp;rdquo; is added on the side menubar.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/customize-menu-add-app.png&#34; 
alt=&#34;Display third party app on a OpenDataology dashboard&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;add-shared-items&#34;&gt;Add shared items&lt;/h2&gt;
&lt;p&gt;The way to add items shared by all users is described in this section.&lt;/p&gt;
&lt;p&gt;First, the cluster admin should deploy the application as a microservice in Kubernetes.
The traffic to the app should be set as a VirtualService of Istio.&lt;/p&gt;
&lt;p&gt;Deploying with specific prefix and controlling the traffic by it is an instant way.
In this case, the new app can be accessed from the below URL.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;http(s)://gateway/_/myapp/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, the configuration of menubar can be opened as below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl edit cm centraldashboard-config -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You would see the current settings. Please add new item as you want.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  links: |-
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &amp;#34;menuLinks&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/jupyter/&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;Notebooks&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;book&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/pipeline/#/executions&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;Executions&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;av:play-arrow&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/myapp/&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;MyApp&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;social:mood&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ],
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&amp;ldquo;icon&amp;rdquo; can be chosen from iron-icons.
You can see the list of iron-icons in this &lt;a href=&#34;http://kevingleason.me/Polymer-Todo/bower_components/iron-icons/demo/index.html&#34;&gt;icon-demo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The change of configuration would be reflected soon.
If not, please rollout centraldashboard and reload the web browser.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl rollout restart deployment centraldashboard -n OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You would see a new item (in this case, it is MyApp) on the menubar.
By clicking that button, you can jump to &lt;code&gt;http(s)://gateway/_/myapp/&lt;/code&gt; and access the third party app through the OpenDataology dashboard.&lt;/p&gt;
&lt;h2 id=&#34;add-namespaced-items&#34;&gt;Add namespaced items&lt;/h2&gt;
&lt;p&gt;The way to split the resouce of additional apps is described in this section.&lt;/p&gt;
&lt;p&gt;Although OpenDataology has the functions for multi tenancy, some third party apps can&amp;rsquo;t interact with OpenDataology profiles or don&amp;rsquo;t support multi tenancy.&lt;/p&gt;
&lt;p&gt;The universal way to handle this problem is deploying the app for each namespace.
The cluster admin deploy the app for each namespace and URLs would be like below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;http(s)://gateway/_/myapp/profile1/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;http(s)://gateway/_/myapp/profile2/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this case, you can configure the central dashboard as below.
&lt;code&gt;{ns}&lt;/code&gt; should be replaced by the namespace when the user open the dashboard.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  links: |-
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &amp;#34;menuLinks&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/jupyter/&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;Notebooks&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;book&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/pipeline/#/executions&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;Executions&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;av:play-arrow&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;type&amp;#34;: &amp;#34;item&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;link&amp;#34;: &amp;#34;/myapp/{ns}&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;text&amp;#34;: &amp;#34;MyApp&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &amp;#34;icon&amp;#34;: &amp;#34;social:mood&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ],
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The users can see a new item (in this case, it is MyApp as well) on the menubar.
They can either jump to &lt;code&gt;http(s)://gateway/_/myapp/profile1/&lt;/code&gt; or &lt;code&gt;http(s)://gateway/_/myapp/profile2/&lt;/code&gt; based on the namespace selection.
The actual inside content of iframe is swiched by the namespace.&lt;/p&gt;
&lt;p&gt;If sidecar injection is enabled, the authorization to the app is done by istio.
e.g) The users who don&amp;rsquo;t belong to profile2 can&amp;rsquo;t access to &lt;code&gt;http(s)://gateway/_/myapp/profile2/&lt;/code&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install OpenDataology Fairing</title>
      <link>/docs/external-add-ons/fairing/install-fairing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/fairing/install-fairing/</guid>
      <description>
        
        
        

&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Out of date&lt;/h4&gt;

    This guide contains outdated information pertaining to OpenDataology 1.0. This guide
needs to be updated for OpenDataology 1.1.

&lt;/div&gt;

&lt;p&gt;You can use OpenDataology Fairing to build, train, and deploy machine learning (ML)
models in a hybrid cloud environment directly from Python code or a Jupyter
notebook. This guide describes how to install OpenDataology Fairing in your
development environment for &lt;a href=&#34;#set-up-OpenDataology-fairing-for-local-development&#34;&gt;local development&lt;/a&gt;, or &lt;a href=&#34;#set-up-OpenDataology-fairing-in-a-hosted-jupyter-notebook&#34;&gt;development in a
hosted notebook&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;using-opendataology-fairing-with-opendataology-notebooks&#34;&gt;Using OpenDataology Fairing with OpenDataology notebooks&lt;/h2&gt;
&lt;p&gt;OpenDataology notebook servers that are built from one of the standard Jupyter
Docker images include OpenDataology Fairing and come preconfigured for using
OpenDataology Fairing to run training jobs on your OpenDataology cluster.&lt;/p&gt;
&lt;p&gt;If you use a OpenDataology notebook server that was built from a custom Jupyter
Docker image as your development environment, follow the instruction on
&lt;a href=&#34;#set-up-OpenDataology-fairing-in-a-hosted-jupyter-notebook&#34;&gt;setting up OpenDataology Fairing in a hosted notebook environment&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;set-up-opendataology-fairing-for-local-development&#34;&gt;Set up OpenDataology Fairing for local development&lt;/h2&gt;
&lt;p&gt;Follow these instructions to set up OpenDataology Fairing for local development.
This guide has been tested on Linux and Mac OS X. Currently, this guide has
not been tested on Windows.&lt;/p&gt;
&lt;h3 id=&#34;set-up-python&#34;&gt;Set up Python&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You need &lt;strong&gt;Python 3.6&lt;/strong&gt; or later to use OpenDataology Fairing. To check if
you have Python 3.6 or later installed, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 -V
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Python 3.6.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you do not have Python 3.6 or later, you can &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;download
Python&lt;/a&gt; from the Python Software
Foundation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use virtualenv to create a virtual environment to install OpenDataology
Fairing in. To check if you have virtualenv installed, run the
following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;which virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/usr/bin/virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you do not have virtualenv, use pip3 to install virtualenv.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip3 install virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Create a new virtual environment, and activate it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;virtualenv venv --python&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;python3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-opendataology-fairing&#34;&gt;Install OpenDataology Fairing&lt;/h3&gt;
&lt;p&gt;Run the following command to install OpenDataology Fairing in your virtual
environment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the install is complete, the &lt;code&gt;fairing&lt;/code&gt; python package is
available. Run the following command to verify that OpenDataology Fairing
is installed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip show OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name: OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Version: 0.6.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Summary: OpenDataology Fairing Python SDK.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Home-page: https://github.com/OpenDataology/fairing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Author: OpenDataology Authors
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Author-email: hejinchi@cn.ibm.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;License: Apache License Version 2.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Location: &amp;lt;path-to-OpenDataology-fairing&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Requires: notebook, future, docker, tornado, cloudpickle, oauth2client, numpy, requests, setuptools, httplib2, google-auth, google-api-python-client, urllib3, boto3, azure, six, kubernetes, google-cloud-storage
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;docker-setup&#34;&gt;Docker setup&lt;/h3&gt;
&lt;p&gt;OpenDataology Fairing uses Docker to package your code. Run the following command
to verify if Docker is installed and running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker ps
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;If you receive the &lt;code&gt;docker: command not found&lt;/code&gt; message, &lt;a href=&#34;https://docs.docker.com/install/&#34;&gt;install
Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you receive the &lt;code&gt;Error response from daemon: Bad response from Docker engine&lt;/code&gt; message, &lt;a href=&#34;https://docs.docker.com/config/daemon/#start-the-daemon-manually&#34;&gt;restart your docker daemon&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you are using Linux and you use sudo to access Docker, follow these
steps to &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user&#34;&gt;add your user to the docker group&lt;/a&gt;. Note, the
docker group grants privileges equivalent to the root user. To learn more
about how this affects security in your system, see the guide to the
&lt;a href=&#34;https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface&#34;&gt;Docker daemon attack surface&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configure-opendataology-fairing&#34;&gt;Configure OpenDataology Fairing&lt;/h3&gt;
&lt;p&gt;To configure OpenDataology Fairing with access to an environment that you would like to
use for training and deployment, follow the instructions in the &lt;a href=&#34;/docs/external-add-ons/fairing/configure-fairing/&#34;&gt;guide to
configuring OpenDataology Fairing&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;set-up-opendataology-fairing-in-a-hosted-jupyter-notebook&#34;&gt;Set up OpenDataology Fairing in a hosted Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Follow these instructions to set up OpenDataology Fairing in a hosted Jupyter
notebook.&lt;/p&gt;
&lt;p&gt;If you are using a OpenDataology notebook server that was built from one of the
standard Jupyter Docker images, your notebooks environment has been
preconfigured for training and deploying ML models with OpenDataology Fairing and
no additional installation steps are required.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;Check the following prerequisites to verify that OpenDataology Fairing is compatible
with your hosted notebook environment.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In the Jupyter notebooks user interface, click &lt;strong&gt;File&lt;/strong&gt; &amp;gt; &lt;strong&gt;New&lt;/strong&gt; &amp;gt;
&lt;strong&gt;Terminal&lt;/strong&gt; in the menu to start a new terminal session in your notebook
environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You need &lt;strong&gt;Python 3.6&lt;/strong&gt; or later to use OpenDataology Fairing. To check if you
have Python 3.6 or later installed, run the following command in your
terminal session:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 -V
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Python 3.6.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenDataology Fairing uses Docker to package your code. Run the following
command in your terminal session to verify if Docker is installed and
running in your notebook environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker ps
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;If you receive the &lt;code&gt;docker: command not found&lt;/code&gt; message, &lt;a href=&#34;https://docs.docker.com/install/&#34;&gt;install
Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you receive the &lt;code&gt;Error response from daemon: Bad response from Docker engine&lt;/code&gt; message, &lt;a href=&#34;https://docs.docker.com/config/daemon/#start-the-daemon-manually&#34;&gt;restart your docker daemon&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you are using Linux and you use sudo to access Docker, follow these
steps to &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user&#34;&gt;add your user to the docker group&lt;/a&gt;. Note, the
docker group grants privileges equivalent to the root user. To learn
more about how this affects security in your system, see the guide to
the &lt;a href=&#34;https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface&#34;&gt;Docker daemon attack surface&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-opendataology-fairing-1&#34;&gt;Install OpenDataology Fairing&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In the Jupyter notebooks user interface, click &lt;strong&gt;File&lt;/strong&gt; &amp;gt; &lt;strong&gt;New&lt;/strong&gt; &amp;gt;
&lt;strong&gt;Terminal&lt;/strong&gt; in the menu to start a new terminal session in your notebook
environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to install OpenDataology Fairing.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip3 install OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After successful installation, the &lt;code&gt;fairing&lt;/code&gt; python package should be
available. Run the following command to verify that OpenDataology Fairing
is installed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip3 show OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name: OpenDataology-fairing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Version: 0.6.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Summary: OpenDataology Fairing Python SDK.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Home-page: https://github.com/OpenDataology/fairing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Author: OpenDataology Authors
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Author-email: hejinchi@cn.ibm.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;License: Apache License Version 2.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Location: &amp;lt;path-to-OpenDataology-fairing&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Requires: notebook, future, docker, tornado, cloudpickle, oauth2client, numpy, requests, setuptools, httplib2, google-auth, google-api-python-client, urllib3, boto3, azure, six, kubernetes, google-cloud-storage
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;configure-opendataology-fairing-1&#34;&gt;Configure OpenDataology Fairing&lt;/h3&gt;
&lt;p&gt;To configure OpenDataology Fairing with access to the environment you would like to
use for training and deployment, follow the instructions in the guide to
&lt;a href=&#34;/docs/external-add-ons/fairing/configure-fairing/&#34;&gt;configuring OpenDataology Fairing&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/external-add-ons/fairing/configure-fairing/&#34;&gt;Configure your OpenDataology Fairing development environment&lt;/a&gt; with access
to run training jobs remotely.&lt;/li&gt;
&lt;li&gt;Follow the &lt;a href=&#34;/docs/external-add-ons/fairing/tutorials/other-tutorials/&#34;&gt;samples and tutorials&lt;/a&gt; to learn more about how to run
training jobs remotely with OpenDataology Fairing.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installation Options</title>
      <link>/docs/components/pipelines/installation/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/overview/</guid>
      <description>
        
        
        &lt;p&gt;OpenDataology Pipelines offers a few installation options.
This page describes the options and the features available
with each option:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt; is the minimal
portable installation that only includes OpenDataology Pipelines.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines as &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;part of a full OpenDataology deployment&lt;/a&gt; provides
all OpenDataology components and more integration with each platform.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beta&lt;/strong&gt;: &lt;a href=&#34;#google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/a&gt; makes it easier to install and use OpenDataology Pipelines on Google Cloud by providing a management UI on &lt;a href=&#34;https://console.cloud.google.com/ai-platform/pipelines/clusters&#34;&gt;Google Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;/docs/components/pipelines/installation/localcluster-deployment&#34;&gt;local&lt;/a&gt; OpenDataology Pipelines deployment for testing purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;choosing-an-installation-option&#34;&gt;Choosing an installation option&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Do you want to use other OpenDataology components in addition to Pipelines?&lt;/p&gt;
&lt;p&gt;If yes, choose the &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology deployment&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Can you use a cloud/on-prem Kubernetes cluster?&lt;/p&gt;
&lt;p&gt;If you can&amp;rsquo;t, you should try using OpenDataology Pipelines on a local Kubernetes cluster for learning and testing purposes by following the steps in &lt;a href=&#34;/docs/components/pipelines/installation/localcluster-deployment&#34;&gt;Deploying OpenDataology Pipelines on a local cluster&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do you want to use OpenDataology Pipelines with &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/1223&#34;&gt;multi-user support&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;If yes, choose the &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology deployment&lt;/a&gt; with version &amp;gt;= v1.1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do you deploy on Google Cloud?&lt;/p&gt;
&lt;p&gt;If yes, deploy &lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt;. You can also
use &lt;a href=&#34;#google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/a&gt; to deploy OpenDataology Pipelines
using a user interface, but there are limitations in
customizability and upgradability. For details, please read corresponding
sections.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You deploy on other platforms.&lt;/p&gt;
&lt;p&gt;Please compare your platform specific &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology&lt;/a&gt; with the
&lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt; before making your decision.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; Choose your installation option with caution, there&amp;rsquo;s no current
supported path to migrate data between different installation options. Please
create &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/new/choose&#34;&gt;a GitHub issue&lt;/a&gt;
if that&amp;rsquo;s important for you.&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;standalone&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;opendataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/h2&gt;
&lt;p&gt;Use this option to deploy OpenDataology Pipelines to an on-premises, cloud
or even local Kubernetes cluster, without the other components of OpenDataology.
To deploy OpenDataology Pipelines Standalone, you use kustomize manifests only.
This process makes it simpler to customize your deployment and to integrate
OpenDataology Pipelines into an existing Kubernetes cluster.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/components/pipelines/installation/standalone-deployment/&#34;&gt;OpenDataology Pipelines Standalone deployment
guide&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenDataology Pipelines UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines API&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint is &lt;strong&gt;only auto-configured&lt;/strong&gt; for Google Cloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you wish to deploy OpenDataology Pipelines on other platforms, you can either access it through
&lt;code&gt;kubectl port-forward&lt;/code&gt; or configure your own platform specific auth-enabled
endpoint by yourself.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;OpenDataology Pipelines Standalone is available for every OpenDataology Pipelines release.
You will have access to the latest features.&lt;/dd&gt;
&lt;dt&gt;Upgrade Support (&lt;strong&gt;Beta&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/components/pipelines/installation/standalone-deployment/#upgrading-OpenDataology-pipelines&#34;&gt;Upgrading OpenDataology Pipelines Standalone&lt;/a&gt; introduces how to upgrade
in place.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you.&lt;/li&gt;
&lt;li&gt;Open the OpenDataology Pipelines UI via the &lt;strong&gt;Open Pipelines Dashboard&lt;/strong&gt; link in &lt;a href=&#34;https://console.cloud.google.com/ai-platform/pipelines/clusters&#34;&gt;the AI Platform Pipelines dashboard of Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;(Optional) You can choose to persist your data in Google Cloud managed storage (Cloud SQL and Cloud Storage).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/&#34;&gt;All options to authenticate to Google Cloud&lt;/a&gt; are supported.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster contains OpenDataology Pipelines only.
It does not include the other OpenDataology components.
For example, to use a Jupyter Notebook, you must use a local notebook or a
hosted notebook in a cloud service such as the &lt;a href=&#34;https://cloud.google.com/ai-platform/notebooks/docs/&#34;&gt;AI Platform
Notebooks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;not available&lt;/strong&gt; in standalone, because
multi-user support depends on other OpenDataology components.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id=&#34;full-OpenDataology&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;full-opendataology-deployment&#34;&gt;Full OpenDataology deployment&lt;/h2&gt;
&lt;p&gt;Use this option to deploy OpenDataology Pipelines to your local machine, on-premises,
or to a cloud, as part of a full OpenDataology installation.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/started/getting-started/&#34;&gt;OpenDataology installation guide&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenDataology UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines UI within or outside the OpenDataology UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines API&lt;/li&gt;
&lt;li&gt;Other OpenDataology APIs&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint is auto-configured with auth support for each platform&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;The full OpenDataology is released quarterly. It has significant delay in receiving
OpenDataology Pipelines updates.&lt;/dd&gt;
&lt;/dl&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OpenDataology Version&lt;/th&gt;
&lt;th&gt;OpenDataology Pipelines Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.7.0&lt;/td&gt;
&lt;td&gt;0.1.31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0.0&lt;/td&gt;
&lt;td&gt;0.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0.2&lt;/td&gt;
&lt;td&gt;0.2.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.1.0&lt;/td&gt;
&lt;td&gt;1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2.0&lt;/td&gt;
&lt;td&gt;1.0.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.3.0&lt;/td&gt;
&lt;td&gt;1.5.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.4.0&lt;/td&gt;
&lt;td&gt;1.7.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: Google Cloud, AWS, and IBM Cloud have supported OpenDataology Pipelines 1.0.0 with multi-user separation. Other platforms might not be up-to-date for now, refer to &lt;a href=&#34;https://github.com/OpenDataology/manifests/issues/1364#issuecomment-668415871&#34;&gt;this GitHub issue&lt;/a&gt; for status.&lt;/p&gt;
&lt;p&gt;Upgrade Support
:
Refer to &lt;a href=&#34;/docs/gke/pipelines/upgrade/#full-OpenDataology&#34;&gt;the full OpenDataology section of upgrading OpenDataology Pipelines on Google Cloud&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you using &lt;a href=&#34;https://cloud.google.com/iap&#34;&gt;Cloud Identity-Aware Proxy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s no current support for persisting your data in Google Cloud managed storage (Cloud SQL and Cloud Storage). Refer to &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/4356&#34;&gt;this GitHub issue&lt;/a&gt; for the latest status.&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/#workload-identity&#34;&gt;authenticate to Google Cloud with Workload Identity&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster includes all the
&lt;a href=&#34;/docs/components/&#34;&gt;OpenDataology components&lt;/a&gt;.
For example, you can use the Jupyter notebook services
&lt;a href=&#34;/docs/components/notebooks/&#34;&gt;deployed with OpenDataology&lt;/a&gt; to create one or more notebook
servers in your OpenDataology cluster.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;only available&lt;/strong&gt; in full OpenDataology. It supports
using a single OpenDataology Pipelines control plane to orchestrate user pipeline
runs in multiple user namespaces with authorization.&lt;/li&gt;
&lt;li&gt;Latest features and bug fixes may not be available soon because release
cadence is long.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id=&#34;marketplace&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/h2&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Beta release&lt;/h4&gt;

    &lt;p&gt;Google Cloud AI Platform Pipelines is currently in &lt;b&gt;Beta&lt;/b&gt; with
  limited support. The OpenDataology Pipelines team is interested in any feedback you may have,
  in particular on the usability of the feature.
&lt;p&gt;You can raise any issues or discussion items in the
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues&#34;&gt;OpenDataology Pipelines
issue tracker&lt;/a&gt;.&lt;/p&gt;&lt;/p&gt;


&lt;/div&gt;

&lt;p&gt;Use this option to deploy OpenDataology Pipelines to Google Kubernetes Engine (GKE)
from Google Cloud Marketplace. You can deploy OpenDataology Pipelines to an existing or new
GKE cluster and manage your cluster within Google Cloud.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/docs&#34;&gt;Google Cloud AI Platform Pipelines documentation&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Cloud Console for managing the OpenDataology Pipelines cluster and other Google Cloud
services&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines UI via the &lt;strong&gt;Open Pipelines Dashboard&lt;/strong&gt; link in the
Google Cloud Console&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK in Cloud Notebooks&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint of your instance is auto-configured for you&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;AI Platform Pipelines is available for a chosen set of stable OpenDataology
Pipelines releases. You will receive updates slightly slower than OpenDataology
Pipelines Standalone.&lt;/dd&gt;
&lt;dt&gt;Upgrade Support (&lt;strong&gt;Alpha&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;An in-place upgrade is not supported.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;To upgrade AI Platform Pipelines by reinstalling it (with existing data), refer to the &lt;a href=&#34;/docs/gke/pipelines/upgrade/#ai-platform-pipelines&#34;&gt;Upgrading AI Platform Pipelines&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can deploy AI Platform Pipelines on &lt;a href=&#34;https://console.cloud.google.com/marketplace/details/google-cloud-ai-platform/OpenDataology-pipelines&#34;&gt;Cloud Console UI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you.&lt;/li&gt;
&lt;li&gt;(Optional) You can choose to persist your data in Google Cloud managed storage services (Cloud SQL and Cloud Storage).&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/#compute-engine-default-service-account&#34;&gt;authenticate to Google Cloud with the Compute Engine default service account&lt;/a&gt;. However, this method may not be suitable if you need workload permission separation.&lt;/li&gt;
&lt;li&gt;You can deploy AI Platform Pipelines on both public and private GKE clusters as long as the cluster &lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/docs/configure-gke-cluster#ensure&#34;&gt;has sufficient resources for AI Platform Pipelines&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster contains OpenDataology Pipelines only.
It does not include the other OpenDataology components.
For example, to use a Jupyter Notebook, you can use &lt;a href=&#34;https://cloud.google.com/ai-platform/notebooks/docs/&#34;&gt;AI Platform
Notebooks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;not available&lt;/strong&gt; in AI Platform Pipelines, because
multi-user support depends on other OpenDataology components.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing OpenDataology</title>
      <link>/docs/distributions/operator/install-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/distributions/operator/install-kubeflow/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to use the OpenDataology Operator to deploy OpenDataology. As mentioned in the Operator &lt;a href=&#34;/docs/methods/operator/introduction.md&#34;&gt;introduction&lt;/a&gt;, the Operator also allows you to monitor and manage the OpenDataology installation beyond the initial installation.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenDataology Operator needs to be deployed on your cluster for rest of steps to work. Please follow the &lt;a href=&#34;/docs/methods/operator/install-operator&#34;&gt;&lt;code&gt;Install the OpenDataology Operator&lt;/code&gt;&lt;/a&gt; guide to install the OpenDataology Operator&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deployment-instructions&#34;&gt;Deployment Instructions&lt;/h2&gt;
&lt;p&gt;The OpenDataology Operator uses the KfDef as its custom resource. You can compose a KfDef configuration or pick a default KfDef from the OpenDataology &lt;a href=&#34;https://github.com/OpenDataology/manifests/tree/master/kfdef&#34;&gt;manifests&lt;/a&gt; repo. Keep in mind choosing the release that will work with the OpenDataology Operator.&lt;/p&gt;
&lt;h3 id=&#34;prepare-kfdef-configuration&#34;&gt;Prepare KfDef configuration&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;metadata.name&lt;/code&gt; field must be set for the KfDef manifests whether it is downloaded from the OpenDataology manifests repo or is originally written. Following example shows how to prepare the KfDef manifests&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# download a default KfDef configuration from remote repo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KFDEF_URL&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://raw.githubusercontent.com/OpenDataology/manifests/v1.1-branch/kfdef/kfctl_ibm.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF_URL&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; rev &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; cut -d/ -f1 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; rev&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -L &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF_URL&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &amp;gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# add metadata.name field&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Note: yq can be installed from https://github.com/mikefarah/yq&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;OpenDataology_DEPLOYMENT_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;yq w &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;metadata.name&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_DEPLOYMENT_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &amp;gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;.tmp &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mv &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;.tmp &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deploy-the-opendataology-with-the-opendataology-operator&#34;&gt;Deploy the OpenDataology with the OpenDataology Operator&lt;/h3&gt;
&lt;p&gt;OpenDataology Operator is watching on any KfDef resource in the Kubernetes cluster. Depends on how the operator is installed, there are a couple of ways to start the OpenDataology deployment. You can always manually run with following commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# create the namespace for OpenDataology deployment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create ns &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# create the KfDef custom resource&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create -f &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KFDEF&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: in the example above, ${KFDEF} points to a local KfDef configuration file, however, it can also points to a remote URL containing a valid KfDef configuration.&lt;/p&gt;
&lt;h3 id=&#34;watch-the-deployment-progress&#34;&gt;Watch the deployment progress&lt;/h3&gt;
&lt;p&gt;The OpenDataology deployment is carried on by the operator, you can watch the progress with this command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl logs deployment/OpenDataology-operator -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OPERATOR_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; -f
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify the OpenDataology deployment by monitoring the pods in the ${OpenDataology_NAMESPACE}&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get pod -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;OpenDataology_NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                                                     READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;admission-webhook-bootstrap-stateful-set-0               1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;          2m26s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;admission-webhook-deployment-5bc5f97cfd-chjnm            1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;application-controller-stateful-set-0                    1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          2m30s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;argo-ui-669bcd8bfc-5dk5c                                 1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          45s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-deployer-deployment-b75f5c5f6-42n6l                2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;          45s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-server-85bccd99bd-tfrnr                            2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          44s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;centraldashboard-8849f64cf-l45zc                         1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          44s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jupyter-web-app-deployment-6c568f4cbc-pd68m              1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          43s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OpenDataology-pipelines-profile-controller-846cc56f44-cmbbf   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          43s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metacontroller-0                                         1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          96s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata-writer-59d755696c-fh6px                         2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          43s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minio-d45d44d4f-rmxft                                    1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          42s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-6bc56cd86d-kn7zt                             1/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          42s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-persistenceagent-6f99b56974-x2f52            2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          41s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-scheduledworkflow-d596b8bd-qdz6m             2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          41s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-ui-8695cc6b46-hr8p5                          2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          40s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-viewer-crd-5998ff7f56-5rn4s                  2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;          40s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ml-pipeline-visualizationserver-cbbb5b5b-w7rbd           2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          39s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mysql-76597cf5b5-jpsrx                                   1/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          39s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;notebook-controller-deployment-756587d86-fffg8           1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          38s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;profiles-deployment-865b78d47f-pbgl4                     2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          38s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;workflow-controller-54dccb7dc4-hkg9s                     1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          37s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Introducing OpenDataology Pipelines SDK v2</title>
      <link>/docs/components/pipelines/sdk-v2/v2-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/sdk-v2/v2-compatibility/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
  &lt;h4 class=&#34;alert-heading&#34;&gt;Beta&lt;/h4&gt;
  This OpenDataology component has &lt;b&gt;beta&lt;/b&gt; status. See the
  &lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
  The OpenDataology team is interested in your   
  &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues&#34;&gt;feedback&lt;/a&gt;&lt;/h4&gt; 
  about the usability of the feature.
&lt;/div&gt;
&lt;p&gt;The OpenDataology Pipelines SDK provides a set of Python packages that you can use to specify and run your machine learning (ML) workflow as a pipeline. Version 2 of the SDK adds support for tracking pipeline runs and artifacts using ML Metadata. Starting with OpenDataology Pipelines 1.6, you can build and run pipelines in v2 compatibility mode.&lt;/p&gt;
&lt;p&gt;OpenDataology Pipelines SDK v2 compatibility mode lets you use the new pipeline semantics and gain the benefits of logging your metadata to ML Metadata. You can use ML Metadata to help answer questions about the lineage of your pipeline’s artifacts.&lt;/p&gt;
&lt;p&gt;To learn more about the work towards OpenDataology Pipelines v2, read the design documents for &lt;a href=&#34;http://bit.ly/kfp-v2&#34;&gt;OpenDataology Pipelines v2&lt;/a&gt; and &lt;a href=&#34;http://bit.ly/kfp-v2-compatible&#34;&gt;OpenDataology Pipelines v2 compatible
mode&lt;/a&gt;, or join the OpenDataology Pipelines community.&lt;/p&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before you begin&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;a href=&#34;/docs/components/pipelines/installation/standalone-deployment&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt; 1.7.0 or higher. Note, support for other distributions is under development, see &lt;a href=&#34;#current-caveats&#34;&gt;Current Caveats section&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to install OpenDataology Pipelines SDK v1.7.2 or higher. If you run this command in a Jupyter notebook, restart the kernel after installing the SDK.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install kfp --upgrade
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import the kfp and kfp.components packages.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create an instance of the kfp.Client class. To find your OpenDataology Pipelines cluster’s hostname and URL scheme, open the OpenDataology Pipelines user interface in your browser. The URL of the OpenDataology Pipelines user interface is something like &lt;a href=&#34;https://my-cluster.my-organization.com/pipelines&#34;&gt;https://my-cluster.my-organization.com/pipelines&lt;/a&gt;. In this case, the host name and URL scheme are &lt;a href=&#34;https://my-cluster.my-organization.com&#34;&gt;https://my-cluster.my-organization.com&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# If you run this command on a Jupyter notebook running on OpenDataology, you can&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# exclude the host parameter.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# client = kfp.Client()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Client&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;host&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;lt;your-OpenDataology-pipelines-host-name&amp;gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;building-pipelines-using-the-opendataology-pipelines-sdk-v2&#34;&gt;Building pipelines using the OpenDataology Pipelines SDK v2&lt;/h2&gt;
&lt;p&gt;If you are new to building pipelines, read the following guides to learn more about
using OpenDataology Pipelines SDK v2 to build pipelines and components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/pipelines/sdk-v2/build-pipeline/&#34;&gt;Get started building pipelines using Pipelines SDK v2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/pipelines/sdk-v2/component-development/&#34;&gt;Learn how to build pipeline components using Pipelines SDK v2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/pipelines/sdk-v2/python-function-components/&#34;&gt;Build lightweight Python function-based components using Pipelines SDK
v2&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are familiar with building OpenDataology pipelines, the OpenDataology Pipelines SDK v2
introduces the following changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The following changes affect how you build components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;All component inputs and outputs must be annotated with their data type.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The OpenDataology Pipelines SDK v2 makes a distinction between inputs and outputs that
are &lt;em&gt;parameters&lt;/em&gt; and those that are &lt;em&gt;artifacts&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Parameters are inputs or outputs of type &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;dict&lt;/code&gt;, or &lt;code&gt;list&lt;/code&gt;
that typically are used to change the behavior of a pipeline. Input parameters
are always passed by value, which means that they are inserted into the
command used to execute the component. Parameters are stored in ML Metadata.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py&#34;&gt;Artifacts&lt;/a&gt;
are larger inputs or outputs, such as datasets or models. Input
artifacts are always passed as a reference to a path.&lt;/p&gt;
&lt;p&gt;You can also access an artifact&amp;rsquo;s metadata. For input artifacts, you can
read the artifact&amp;rsquo;s metadata. For output artifacts, you can write key/value
pairs to the metadata dictionary.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The following changes affect how you define a pipeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pipeline functions must be decorated with
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/_pipeline.py&#34;&gt;&lt;code&gt;@kfp.dsl.pipeline&lt;/code&gt;&lt;/a&gt;. Specify the following arguments for the
&lt;code&gt;@pipeline&lt;/code&gt; annotation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;name&lt;/code&gt;: The pipeline name is used when querying MLMD to store or lookup
component parameters and artifacts. Reusing pipeline names may result in unexpected behaviors. You can override this name when you run the pipeline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;description&lt;/code&gt;: (Optional.) A user friendly description of this pipeline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;pipeline_root&lt;/code&gt;: (Optional.) The root path where this pipeline&amp;rsquo;s outputs
are stored. This can be a MinIO, Google Cloud Storage, or Amazon Web Services
S3 URI. You can override the pipeline root when you run the pipeline.&lt;/p&gt;
&lt;p&gt;If you do not specify the &lt;code&gt;pipeline_root&lt;/code&gt;, OpenDataology Pipelines stores your
artifacts using MinIO.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The OpenDataology Pipelines SDK v2 compiler checks that data types are used correctly in pipelines,
and that parameters outputs are not passed to artifact inputs and vice versa&lt;/p&gt;
&lt;p&gt;You might need to modify existing pipelines to run them in v2 compatibility mode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is not longer supported to pass constants to artifact inputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All pipeline parameters must be annotated with their data type.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;compiling-and-running-pipelines-in-v2-compatibility-mode&#34;&gt;Compiling and running pipelines in v2 compatibility mode&lt;/h2&gt;
&lt;p&gt;First we define a v2 compatible pipeline:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp.dsl&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp.v2.dsl&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;component&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#5c35cc;font-weight:bold&#34;&gt;@component&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&amp;#39;&amp;#39;Calculates sum of two arguments&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#5c35cc;font-weight:bold&#34;&gt;@dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;addition-pipeline&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#000&#34;&gt;description&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;An example pipeline that performs addition calculations.&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# pipeline_root=&amp;#39;gs://my-pipeline-root/example-pipeline&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;add_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#000&#34;&gt;add_task&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To compile your pipeline in v2 compatibility mode, specify that
&lt;code&gt;mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE&lt;/code&gt; when you initiate the compiler:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;compiler&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;compiler&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Compiler&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;mode&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PipelineExecutionMode&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;V2_COMPATIBLE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;compile&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline_func&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;add_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;package_path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;pipeline.yaml&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To run your pipeline in v2 compatibility mode:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an instance of the &lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client&#34;&gt;&lt;code&gt;kfp.Client&lt;/code&gt; class&lt;/a&gt; following steps in &lt;a href=&#34;/docs/components/pipelines/sdk/connect-api/&#34;&gt;connecting to OpenDataology Pipelines using the SDK client&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Specify that &lt;code&gt;mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE&lt;/code&gt; when you create a pipeline
run using &lt;code&gt;create_run_from_pipeline_func&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following example demonstrates how to run a pipeline using v2 compatibility mode.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Client&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# run the pipeline in v2 compatibility mode&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;create_run_from_pipeline_func&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;add_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;arguments&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;7&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;mode&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kfp&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PipelineExecutionMode&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;V2_COMPATIBLE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;current-caveats&#34;&gt;Current Caveats&lt;/h2&gt;
&lt;p&gt;OpenDataology Pipelines v2 compatible mode is currently in Beta stage. It is under active development and some features may not be complete. To find out its current caveats, refer to &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6133&#34;&gt;v2 compatible mode &amp;ndash; known caveats &amp;amp; breaking changes #6133&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction</title>
      <link>/docs/components/pipelines/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/introduction/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
This OpenDataology component has &lt;b&gt;stable&lt;/b&gt; status. See the
&lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
&lt;/div&gt;
&lt;p&gt;OpenDataology Pipelines is a platform for building and deploying portable,
scalable machine learning (ML) workflows based on Docker containers.&lt;/p&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;Quickstart&lt;/h2&gt;
&lt;p&gt;Run your first pipeline by following the
&lt;a href=&#34;/docs/components/pipelines/overview/quickstart&#34;&gt;pipelines quickstart guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;what-is-opendataology-pipelines&#34;&gt;What is OpenDataology Pipelines?&lt;/h2&gt;
&lt;p&gt;The OpenDataology Pipelines platform consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A user interface (UI) for managing and tracking experiments, jobs, and runs.&lt;/li&gt;
&lt;li&gt;An engine for scheduling multi-step ML workflows.&lt;/li&gt;
&lt;li&gt;An SDK for defining and manipulating pipelines and components.&lt;/li&gt;
&lt;li&gt;Notebooks for interacting with the system using the SDK.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following are the goals of OpenDataology Pipelines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;End-to-end orchestration: enabling and simplifying the orchestration of
machine learning pipelines.&lt;/li&gt;
&lt;li&gt;Easy experimentation: making it easy for you to try numerous ideas and
techniques and manage your various trials/experiments.&lt;/li&gt;
&lt;li&gt;Easy re-use: enabling you to re-use components and pipelines to quickly
create end-to-end solutions without having to rebuild each time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OpenDataology Pipelines is available as a core component of OpenDataology or as a standalone installation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/started/getting-started/&#34;&gt;Learn more about installing OpenDataology&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/components/pipelines/installation/overview/&#34;&gt;Learn more about installing OpenDataology Pipelines standalone&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Due to &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/1700&#34;&gt;OpenDataology/pipelines#1700&lt;/a&gt;, the container builder in OpenDataology Pipelines currently prepares credentials for Google Cloud Platform (GCP) only. As a result, the container builder supports only Google Container Registry. However, you can store the container images on other registries, provided you set up the credentials correctly to fetch the image.&lt;/i&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pipeline&#34;&gt;What is a pipeline?&lt;/h2&gt;
&lt;p&gt;A &lt;em&gt;pipeline&lt;/em&gt; is a description of an ML workflow, including all of the components
in the workflow and how they combine in the form of a graph. (See the
screenshot below showing an example of a pipeline graph.) The pipeline
includes the definition of the inputs (parameters) required to run the pipeline
and the inputs and outputs of each component.&lt;/p&gt;
&lt;p&gt;After developing your pipeline, you can upload and share it on the
OpenDataology Pipelines UI.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;pipeline component&lt;/em&gt; is a self-contained set of user code, packaged as a
&lt;a href=&#34;https://docs.docker.com/get-started/&#34;&gt;Docker image&lt;/a&gt;, that
performs one step in the pipeline. For example, a component can be responsible
for data preprocessing, data transformation, model training, and so on.&lt;/p&gt;
&lt;p&gt;See the conceptual guides to &lt;a href=&#34;/docs/components/pipelines/concepts/pipeline/&#34;&gt;pipelines&lt;/a&gt;
and &lt;a href=&#34;/docs/components/pipelines/concepts/component/&#34;&gt;components&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;example-of-a-pipeline&#34;&gt;Example of a pipeline&lt;/h2&gt;
&lt;p&gt;The screenshots and code below show the &lt;code&gt;xgboost-training-cm.py&lt;/code&gt; pipeline, which
creates an XGBoost model using structured data in CSV format. You can see the
source code and other information about the pipeline on
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/samples/core/xgboost_training_cm&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-runtime-execution-graph-of-the-pipeline&#34;&gt;The runtime execution graph of the pipeline&lt;/h3&gt;
&lt;p&gt;The screenshot below shows the example pipeline&amp;rsquo;s runtime execution graph in the
OpenDataology Pipelines UI:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/pipelines-xgboost-graph.png&#34; 
alt=&#34;XGBoost results on the pipelines UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-python-code-that-represents-the-pipeline&#34;&gt;The Python code that represents the pipeline&lt;/h3&gt;
&lt;p&gt;Below is an extract from the Python code that defines the
&lt;code&gt;xgboost-training-cm.py&lt;/code&gt; pipeline. You can see the full code on
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/samples/core/xgboost_training_cm&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#5c35cc;font-weight:bold&#34;&gt;@dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;XGBoost Trainer&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;description&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;A trainer that does end-to-end distributed training for XGBoost models.&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;xgb_train_pipeline&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;gs://your-gcs-bucket&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;your-gcp-project&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;xgb-&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;RUN_ID_PLACEHOLDER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;us-central1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;gs://ml-pipeline-playground/sfpd/train.csv&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;eval_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;gs://ml-pipeline-playground/sfpd/eval.csv&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;schema&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;gs://ml-pipeline-playground/sfpd/schema.json&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;resolution&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;rounds&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;200&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;true_label&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;ACTION&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;str&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;RUN_ID_PLACEHOLDER&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;/data&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Current GCP pyspark/spark op do not provide outputs as return values, instead,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# we need to use strings to pass the uri around.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;analyze_output&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;transform_output_train&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;part-*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;transform_output_eval&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;eval&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;part-*&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;train_output&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;train_output&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;predict_output&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;predict_output&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;with&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ExitHandler&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;exit_op&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dataproc_delete_cluster_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;project_id&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_create_cluster_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dataproc_create_cluster_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;project_id&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;initialization_actions&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              &lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_PYSRC_PREFIX&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                           &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;initialization_actions.sh&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;image_version&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;1.2&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_analyze_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dataproc_analyze_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;schema&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;schema&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_create_cluster_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;set_display_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Analyzer&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_transform_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dataproc_transform_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;eval_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;eval_data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;analysis&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;analyze_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_analyze_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;set_display_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Transformer&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_train_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dataproc_train_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;train_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;transform_output_train&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;eval_data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;transform_output_eval&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;analysis&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;analyze_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;rounds&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;rounds&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;train_output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_transform_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;set_display_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Trainer&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_predict_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;dataproc_predict_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;project&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cluster_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;transform_output_eval&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;train_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;analysis&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;analyze_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;predict_output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_train_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;set_display_name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Predictor&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_cm_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;confusion_matrix_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;predictions&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;predict_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;part-*.csv&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output_dir&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_predict_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;_roc_op&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;roc_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;predictions_dir&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;os&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;path&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;join&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;predict_output&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;part-*.csv&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;true_class&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;true_label&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;true_score_column&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;true_label&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#000&#34;&gt;output_dir&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;output_template&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;after&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;_predict_op&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;dsl&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;get_pipeline_conf&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;()&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;add_op_transformer&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#000&#34;&gt;gcp&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;use_gcp_secret&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;user-gcp-sa&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pipeline-input-data-on-the-opendataology-pipelines-ui&#34;&gt;Pipeline input data on the OpenDataology Pipelines UI&lt;/h3&gt;
&lt;p&gt;The partial screenshot below shows the OpenDataology Pipelines UI for kicking off a
run of the pipeline. The pipeline definition in your code determines which
parameters appear in the UI form. The pipeline definition can also set default
values for the parameters:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/pipelines-start-xgboost-run.png&#34; 
alt=&#34;Starting the XGBoost run on the pipelines UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;outputs-from-the-pipeline&#34;&gt;Outputs from the pipeline&lt;/h3&gt;
&lt;p&gt;The following screenshots show examples of the pipeline output visible on
the OpenDataology Pipelines UI.&lt;/p&gt;
&lt;p&gt;Prediction results:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/predict.png&#34; 
alt=&#34;Prediction output&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;Confusion matrix:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/cm.png&#34; 
alt=&#34;Confusion matrix&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;Receiver operating characteristics (ROC) curve:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/roc.png&#34; 
alt=&#34;ROC&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;architectural-overview&#34;&gt;Architectural overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/docs/images/pipelines-architecture.png&#34; 
alt=&#34;Pipelines architectural diagram&#34;
class=&#34;mt-3 mb-3 p-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;At a high level, the execution of a pipeline proceeds as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Python SDK&lt;/strong&gt;: You create components or specify a pipeline using the OpenDataology
Pipelines domain-specific language
(&lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/sdk/python/kfp/dsl&#34;&gt;DSL&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DSL compiler&lt;/strong&gt;: The
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/sdk/python/kfp/compiler&#34;&gt;DSL compiler&lt;/a&gt;
transforms your pipeline&amp;rsquo;s Python code into a static configuration (YAML).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipeline Service&lt;/strong&gt;: You call the Pipeline Service to create a
pipeline run from the static configuration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kubernetes resources&lt;/strong&gt;: The Pipeline Service calls the Kubernetes API server to create
the necessary Kubernetes resources
(&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;CRDs&lt;/a&gt;)
to run the pipeline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Orchestration controllers&lt;/strong&gt;: A set of orchestration controllers
execute the containers needed to complete the pipeline.
The containers execute within Kubernetes Pods on virtual machines.
An example controller is the
&lt;strong&gt;&lt;a href=&#34;https://github.com/argoproj/argo-workflows&#34;&gt;Argo Workflow&lt;/a&gt;&lt;/strong&gt; controller,
which orchestrates task-driven workflows.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Artifact storage&lt;/strong&gt;: The Pods store two kinds of data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Metadata:&lt;/strong&gt; Experiments, jobs, pipeline runs, and single scalar metrics.
Metric data is aggregated for the purpose of sorting and filtering.
OpenDataology Pipelines stores the metadata in a MySQL database.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Artifacts:&lt;/strong&gt; Pipeline packages, views, and large-scale metrics (time series).
Use large-scale metrics to debug a pipeline run or investigate an individual run’s performance.
OpenDataology Pipelines stores the artifacts in an artifact store like
&lt;a href=&#34;https://docs.minio.io/&#34;&gt;Minio server&lt;/a&gt; or
&lt;a href=&#34;https://cloud.google.com/storage/docs/&#34;&gt;Cloud Storage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The MySQL database and the Minio server are both backed by the Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes&#34;&gt;PersistentVolume&lt;/a&gt;
subsystem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Persistence agent and ML metadata&lt;/strong&gt;: The Pipeline Persistence Agent
watches the Kubernetes resources created by the Pipeline Service and
persists the state of these resources in the ML Metadata Service. The
Pipeline Persistence Agent records the set of containers that executed as
well as their inputs and outputs. The input/output consists of either
container parameters or data artifact URIs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipeline web server&lt;/strong&gt;: The Pipeline web server gathers data from various
services to display relevant views: the list of pipelines currently running,
the history of pipeline execution, the list of data artifacts, debugging
information about individual pipeline runs, execution status about individual
pipeline runs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Follow the
&lt;a href=&#34;/docs/components/pipelines/overview/quickstart&#34;&gt;pipelines quickstart guide&lt;/a&gt; to
deploy OpenDataology and run a sample pipeline directly from the
OpenDataology Pipelines UI.&lt;/li&gt;
&lt;li&gt;Build machine-learning pipelines with the &lt;a href=&#34;/docs/components/pipelines/sdk/sdk-overview/&#34;&gt;OpenDataology Pipelines
SDK&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Follow the full guide to experimenting with
&lt;a href=&#34;/docs/components/pipelines/tutorials/build-pipeline/&#34;&gt;the OpenDataology Pipelines samples&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction to Feast</title>
      <link>/docs/external-add-ons/feature-store/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/external-add-ons/feature-store/overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
  &lt;h4 class=&#34;alert-heading&#34;&gt;Alpha&lt;/h4&gt;
  This OpenDataology component has &lt;b&gt;alpha&lt;/b&gt; status with limited support. See the
  &lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
  The OpenDataology team is interested in your   
  &lt;a href=&#34;https://github.com/feast-dev/feast/issues&#34;&gt;feedback&lt;/a&gt;&lt;/h4&gt; 
  about the usability of the feature.
&lt;/div&gt;
&lt;p&gt;Use &lt;a href=&#34;http://feast.dev/&#34;&gt;Feast&lt;/a&gt; for defining, managing, discovering, validating, and serving features to your models during training and inference.&lt;/p&gt;
&lt;p&gt;This page introduces feature store concepts as well as Feast as a component of OpenDataology.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-feature-stores&#34;&gt;Introduction to feature stores&lt;/h2&gt;
&lt;p&gt;Feature stores are systems that help to address some of the key challenges that ML teams face when productionizing features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature sharing and reuse&lt;/strong&gt;: Engineering features is one of the most time consuming activities in building an end-to-end ML system, yet many teams continue to develop features in silos. This leads to a high amount of re-development and duplication of work across teams and projects.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Serving features at scale&lt;/strong&gt;: Models need data that can come from a variety of sources, including event streams, data lakes, warehouses, or notebooks. ML teams need to be able to store and serve all these data sources to their models in a performant and reliable way. The challenge is scalably producing massive datasets of features for model training, and providing access to real-time feature data at low latency and high throughput in serving.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Consistency between training and serving&lt;/strong&gt;: The separation between data scientists and engineering teams often lead to the re-development of feature transformations when moving from training to online serving. Inconsistencies that arise due to discrepancies between training and serving implementations frequently leads to a drop in model performance in production.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Point-in-time correctness&lt;/strong&gt;:  General purpose data systems are not built with ML use cases in mind and by extension don&amp;rsquo;t provide point-in-time correct lookups of feature data. Without a point-in-time correct view of data, models are trained on datasets that are not representative of what is found in production, leading to a drop in accuracy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data quality and validation&lt;/strong&gt;: Features are business critical inputs to ML systems. Teams need to be confident in the quality of data that is served in production and need to be able to react when there is any drift in the underlying data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;feast-as-a-feature-store&#34;&gt;Feast as a feature store&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://feast.dev/&#34;&gt;Feast&lt;/a&gt; is an &lt;a href=&#34;https://github.com/feast-dev/feast&#34;&gt;open-source&lt;/a&gt; feature store that helps teams operate ML systems at scale by allowing them to define, manage, validate, and serve features to models in production.&lt;/p&gt;
&lt;p&gt;Feast provides the following functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load streaming and batch data&lt;/strong&gt;: Feast is built to be able to ingest data from a variety of bounded or unbounded sources. Feast allows users to ingest data from streams, object stores, databases, or notebooks. Data that is ingested into Feast is persisted in both online store and historical stores, which in turn is used for the creation of training datasets and serving features to online systems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Standardized definitions&lt;/strong&gt;: Feast becomes the single source of truth for all feature definitions and data within an organization. Teams are able to capture documentation, metadata, and metrics about features. This allows teams to communicate clearly about features, test feature data, and determine if a feature is both safe and relevant to their use cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Historical serving&lt;/strong&gt;: Features that are persisted in Feast can be retrieved through its feature serving APIs to produce training datasets. Feast is able to produce massive training datasets that are agnostics of the data source that was used to ingest the data originally. Feast is also able to ensure point-in-time correctness when joining these data sources, which in turn ensures the quality and consistency of features reaching models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Online serving&lt;/strong&gt;: Feast exposes low latency serving APIs for all data that has been ingested into the system. This allows all production ML systems to use Feast as the primary data source when looking up real-time features.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Consistency between training and serving&lt;/strong&gt;: Feast provides a consistent view of feature data through the use of a unified ingestion layer, unified serving API and canonical feature references. By building ML systems on feature references, teams abstract away the underlying data infrastructure and make it possible to safely move models between training and serving without a drop in data consistency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature sharing and reuse&lt;/strong&gt;: Feast provides a discovery and metadata API that allows teams to track, share, and reuse features across projects. Feast also decouples the process of creating features from the process of consumption, meaning teams that start new projects can begin by simply consuming features that already exist in the store, instead of starting from scratch.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Statistics and validation&lt;/strong&gt;: Feast allows for the generation of statistics based on features within the systems. Feast has compatibility with TFDV, meaning statistics that are generated by Feast can be validated using TFDV. Feast also allows teams to capture TFDV schemas as part of feature definitions, allowing domain experts to define data properties that can be used for validating these features in other production settings like training, ingestion, or serving.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;Please follow the &lt;a href=&#34;/docs/external-add-ons/feature-store/getting-started/&#34;&gt;Getting Started with Feast&lt;/a&gt; guide to set up Feast and run walk through our tutorials.&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.feast.dev/&#34;&gt;Feast: Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/feast-dev/feast&#34;&gt;Feast: Source Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning&#34;&gt;Google Cloud - Introducing Feast: An open source feature store for machine learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.gojekengineering.com/feast-bridging-ml-models-and-data-efd06b7d1644&#34;&gt;Medium - Feast: Bridging ML Models and Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction to Katib</title>
      <link>/docs/components/katib/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/katib/overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
  &lt;h4 class=&#34;alert-heading&#34;&gt;Beta&lt;/h4&gt;
  This OpenDataology component has &lt;b&gt;beta&lt;/b&gt; status. See the
  &lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
  The OpenDataology team is interested in your   
  &lt;a href=&#34;https://github.com/OpenDataology/katib/issues&#34;&gt;feedback&lt;/a&gt;&lt;/h4&gt; 
  about the usability of the feature.
&lt;/div&gt;
&lt;p&gt;This guide introduces the concepts of hyperparameter tuning, neural
architecture search, and the Katib system as a component of OpenDataology.&lt;/p&gt;
&lt;p&gt;Katib is a Kubernetes-native project for automated machine learning (AutoML).
Katib supports hyperparameter tuning, early stopping and
neural architecture search (NAS).
Learn more about AutoML at &lt;a href=&#34;https://www.fast.ai/2018/07/16/auto-ml2/&#34;&gt;fast.ai&lt;/a&gt;,
&lt;a href=&#34;https://cloud.google.com/automl&#34;&gt;Google Cloud&lt;/a&gt;,
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#automl-in-azure-machine-learning&#34;&gt;Microsoft Azure&lt;/a&gt; or
&lt;a href=&#34;https://aws.amazon.com/blogs/aws/amazon-sagemaker-autopilot-fully-managed-automatic-machine-learning/&#34;&gt;Amazon SageMaker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Katib is the project which is agnostic to machine learning (ML) frameworks.
It can tune hyperparameters of applications written in any language
of the users&amp;rsquo; choice and natively supports many ML frameworks,
such as TensorFlow, MXNet, PyTorch, XGBoost, and others.&lt;/p&gt;
&lt;p&gt;Katib supports a lot of various AutoML algorithms, such as
&lt;a href=&#34;https://arxiv.org/pdf/1012.2599.pdf&#34;&gt;Bayesian optimization&lt;/a&gt;,
&lt;a href=&#34;https://papers.nips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf&#34;&gt;Tree of Parzen Estimators&lt;/a&gt;,
&lt;a href=&#34;https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search&#34;&gt;Random Search&lt;/a&gt;,
&lt;a href=&#34;https://en.wikipedia.org/wiki/CMA-ES&#34;&gt;Covariance Matrix Adaptation Evolution Strategy&lt;/a&gt;,
&lt;a href=&#34;https://arxiv.org/pdf/1603.06560.pdf&#34;&gt;Hyperband&lt;/a&gt;,
&lt;a href=&#34;https://arxiv.org/abs/1802.03268&#34;&gt;Efficient Neural Architecture Search&lt;/a&gt;,
&lt;a href=&#34;https://arxiv.org/abs/1806.09055&#34;&gt;Differentiable Architecture Search&lt;/a&gt;
and many more. Additional algorithm support is coming soon.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/OpenDataology/katib&#34;&gt;Katib project&lt;/a&gt; is open source.
The &lt;a href=&#34;https://github.com/OpenDataology/katib/blob/master/docs/developer-guide.md&#34;&gt;developer guide&lt;/a&gt;
is a good starting point for developers who want to contribute to the project.&lt;/p&gt;
&lt;h2 id=&#34;hyperparameters-and-hyperparameter-tuning&#34;&gt;Hyperparameters and hyperparameter tuning&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Hyperparameters&lt;/em&gt; are the variables that control the model training process.
They include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The learning rate.&lt;/li&gt;
&lt;li&gt;The number of layers in a neural network.&lt;/li&gt;
&lt;li&gt;The number of nodes in each layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hyperparameter values are not &lt;em&gt;learned&lt;/em&gt;. In other words, in contrast to the
node weights and other training &lt;em&gt;parameters&lt;/em&gt;, the model training process does
not adjust the hyperparameter values.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hyperparameter tuning&lt;/em&gt; is the process of optimizing the hyperparameter values
to maximize the predictive accuracy of the model. If you don&amp;rsquo;t use Katib or a
similar system for hyperparameter tuning, you need to run many training jobs
yourself, manually adjusting the hyperparameters to find the optimal values.&lt;/p&gt;
&lt;p&gt;Automated hyperparameter tuning works by optimizing a target variable,
also called the &lt;em&gt;objective metric&lt;/em&gt;, that you specify in the configuration for
the hyperparameter tuning job. A common metric is the model&amp;rsquo;s accuracy
in the validation pass of the training job (&lt;em&gt;validation-accuracy&lt;/em&gt;). You also
specify whether you want the hyperparameter tuning job to &lt;em&gt;maximize&lt;/em&gt; or
&lt;em&gt;minimize&lt;/em&gt; the metric.&lt;/p&gt;
&lt;p&gt;For example, the following graph from Katib shows the level of validation accuracy
for various combinations of hyperparameter values (the learning rate, the number of
layers, and the optimizer):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/components/katib/images/random-example-graph.png&#34;
alt=&#34;Graph produced by the random example&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(To run the example that produced this graph, follow the &lt;a href=&#34;/docs/components/katib/hyperparameter/&#34;&gt;getting-started
guide&lt;/a&gt;.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Katib runs several training jobs (known as &lt;em&gt;trials&lt;/em&gt;) within each
hyperparameter tuning job (&lt;em&gt;experiment&lt;/em&gt;). Each trial tests a different set of
hyperparameter configurations. At the end of the experiment, Katib outputs
the optimized values for the hyperparameters.&lt;/p&gt;
&lt;p&gt;You can improve your hyperparameter tunning experiments by using
&lt;a href=&#34;https://en.wikipedia.org/wiki/Early_stopping&#34;&gt;early stopping&lt;/a&gt; techniques.
Follow the &lt;a href=&#34;/docs/components/katib/early-stopping/&#34;&gt;early stopping guide&lt;/a&gt;
for the details.&lt;/p&gt;
&lt;h2 id=&#34;neural-architecture-search&#34;&gt;Neural architecture search&lt;/h2&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Alpha version&lt;/h4&gt;

    NAS is currently in &lt;b&gt;alpha&lt;/b&gt; with limited support. The OpenDataology team is
interested in any feedback you may have, in particular with regards to usability
of the feature. You can log issues and comments in
the &lt;a href=&#34;https://github.com/OpenDataology/katib/issues&#34;&gt;Katib issue tracker&lt;/a&gt;.

&lt;/div&gt;

&lt;p&gt;In addition to hyperparameter tuning, Katib offers a &lt;em&gt;neural architecture
search&lt;/em&gt; feature. You can use the NAS to design
your artificial neural network, with a goal of maximizing the predictive
accuracy and performance of your model.&lt;/p&gt;
&lt;p&gt;NAS is closely related to hyperparameter tuning. Both are subsets of AutoML.
While hyperparameter tuning optimizes the model&amp;rsquo;s hyperparameters, a NAS system
optimizes the model&amp;rsquo;s structure, node weights and hyperparameters.&lt;/p&gt;
&lt;p&gt;NAS technology in general uses various techniques to find the optimal neural
network design.&lt;/p&gt;
&lt;p&gt;You can submit Katib jobs from the command line or from the UI. (Learn more
about the Katib interfaces later on this page.) The following screenshot shows
part of the form for submitting a NAS job from the Katib UI:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/components/katib/images/nas-parameters.png&#34;
alt=&#34;Submitting a neural architecture search from the Katib UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;katib-interfaces&#34;&gt;Katib interfaces&lt;/h2&gt;
&lt;p&gt;You can use the following interfaces to interact with Katib:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A web UI that you can use to submit experiments and to monitor your results.
Check the &lt;a href=&#34;/docs/components/katib/hyperparameter/#katib-ui&#34;&gt;getting-started
guide&lt;/a&gt;
for information on how to access the UI.
The Katib home page within OpenDataology looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/docs/components/katib/images/home-page.png&#34;
alt=&#34;The Katib home page within the OpenDataology UI&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A gRPC API. Check the &lt;a href=&#34;https://github.com/OpenDataology/katib/blob/master/pkg/apis/manager/v1beta1/gen-doc/api.md&#34;&gt;API reference on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Command-line interfaces (CLIs):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Kubernetes CLI, &lt;strong&gt;kubectl&lt;/strong&gt;, is useful for running commands against your
OpenDataology cluster. Learn about kubectl in the &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34;&gt;Kubernetes
documentation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Katib Python SDK. Check the &lt;a href=&#34;https://github.com/OpenDataology/katib/tree/master/sdk/python/v1beta1&#34;&gt;Katib Python SDK documentation on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;katib-concepts&#34;&gt;Katib concepts&lt;/h2&gt;
&lt;p&gt;This section describes the terms used in Katib.&lt;/p&gt;
&lt;h3 id=&#34;experiment&#34;&gt;Experiment&lt;/h3&gt;
&lt;p&gt;An &lt;em&gt;experiment&lt;/em&gt; is a single tuning run, also called an optimization run.&lt;/p&gt;
&lt;p&gt;You specify configuration settings to define the experiment. The following are
the main configurations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: What you want to optimize. This is the objective metric, also
called the target variable. A common metric is the model&amp;rsquo;s accuracy
in the validation pass of the training job (&lt;em&gt;validation-accuracy&lt;/em&gt;). You also
specify whether you want the hyperparameter tuning job to &lt;em&gt;maximize&lt;/em&gt; or
&lt;em&gt;minimize&lt;/em&gt; the metric.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search space&lt;/strong&gt;: The set of all possible hyperparameter values that the
hyperparameter tuning job should consider for optimization, and the
constraints for each hyperparameter. Other names for search space include
&lt;em&gt;feasible set&lt;/em&gt; and &lt;em&gt;solution space&lt;/em&gt;. For example, you may provide the
names of the hyperparameters that you want to optimize. For each
hyperparameter, you may provide a &lt;em&gt;minimum&lt;/em&gt; and &lt;em&gt;maximum&lt;/em&gt; value or a &lt;em&gt;list&lt;/em&gt;
of allowable values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search algorithm&lt;/strong&gt;: The algorithm to use when searching for the optimal
hyperparameter values.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Katib experiment is defined as a
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Kubernetes CRD&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;For details of how to define your experiment, follow the guide to &lt;a href=&#34;/docs/components/katib/experiment/&#34;&gt;running an
experiment&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;suggestion&#34;&gt;Suggestion&lt;/h3&gt;
&lt;p&gt;A &lt;em&gt;suggestion&lt;/em&gt; is a set of hyperparameter values that the hyperparameter
tuning process has proposed. Katib creates a trial to evaluate the suggested
set of values.&lt;/p&gt;
&lt;p&gt;Katib suggestion is defined as a
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Kubernetes CRD&lt;/a&gt; .&lt;/p&gt;
&lt;h3 id=&#34;trial&#34;&gt;Trial&lt;/h3&gt;
&lt;p&gt;A &lt;em&gt;trial&lt;/em&gt; is one iteration of the hyperparameter tuning process. A trial
corresponds to one worker job instance with a list of parameter assignments.
The list of parameter assignments corresponds to a suggestion.&lt;/p&gt;
&lt;p&gt;Each experiment runs several trials. The experiment runs the trials until it
reaches either the objective or the configured maximum number of trials.&lt;/p&gt;
&lt;p&gt;Katib trial is defined as a
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Kubernetes CRD&lt;/a&gt; .&lt;/p&gt;
&lt;h3 id=&#34;worker-job&#34;&gt;Worker job&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;worker job&lt;/em&gt; is the process that runs to evaluate a trial and calculate
its objective value.&lt;/p&gt;
&lt;p&gt;The worker job can be any type of Kubernetes resource or
&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Kubernetes CRD&lt;/a&gt;.
Follow the
&lt;a href=&#34;/docs/components/katib/trial-template/#custom-resource&#34;&gt;trial template guide&lt;/a&gt;
to check how to support your own Kubernetes resource in Katib.&lt;/p&gt;
&lt;p&gt;Katib has these CRD examples in upstream:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/job/&#34;&gt;Kubernetes &lt;code&gt;Job&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/training/tftraining/&#34;&gt;OpenDataology &lt;code&gt;TFJob&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/training/pytorch/&#34;&gt;OpenDataology &lt;code&gt;PyTorchJob&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/training/mxnet&#34;&gt;OpenDataology &lt;code&gt;MXJob&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/training/xgboost&#34;&gt;OpenDataology &lt;code&gt;XGBoostJob&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/training/mpi&#34;&gt;OpenDataology &lt;code&gt;MPIJob&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenDataology/katib/tree/master/examples/v1beta1/tekton&#34;&gt;Tekton &lt;code&gt;Pipelines&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenDataology/katib/tree/master/examples/v1beta1/argo&#34;&gt;Argo &lt;code&gt;Workflows&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By offering the above worker job types, Katib supports multiple ML frameworks.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;Follow the &lt;a href=&#34;/docs/components/katib/hyperparameter/&#34;&gt;getting-started guide&lt;/a&gt;
to set up Katib and run some hyperparameter tuning examples.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction to Multi-user Isolation</title>
      <link>/docs/components/multi-tenancy/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/multi-tenancy/overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
This OpenDataology component has &lt;b&gt;stable&lt;/b&gt; status. See the
&lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
&lt;/div&gt;
&lt;p&gt;In OpenDataology clusters, users often need to be isolated into a group, where a group includes one or more users.   Additionally, a user may need to belong to multiple groups.  OpenDataology’s multi-user isolation simplifies user operations because each user only views and edited\s the OpenDataology components and model artifacts defined in their configuration.  A user’s view is not cluttered by components or model artifacts that are not in their configuration. This isolation also provides for efficient infrastructure and operations i.e. a single cluster supports multiple isolated users, and does not require the administrator to operate different clusters to isolate users.&lt;/p&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key concepts&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Administrator&lt;/strong&gt;: An Administrator is someone who creates and maintains the OpenDataology cluster. This person configures permissions (i.e. view, edit) for other users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;User&lt;/strong&gt;: A User is someone who has access to some set of resources in the cluster. A user needs to be granted access permissions by the administrator.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Profile&lt;/strong&gt;: A Profile is a unique configuration for a user, which determines their access privileges and is defined by the Administrator.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Isolation&lt;/strong&gt;: Isolation uses Kubernetes Namespaces.  Namespaces isolate users or a group of users i.e. Bob’s namespace or ML Eng namespace that is shared by Bob and Sara.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: Authentication is provided by an integration of Istio and OIDC and is secured by mTLS.  More details can be found &lt;a href=&#34;https://journal.arrikto.com/OpenDataology-authentication-with-istio-dex-5eafdfac4782&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Authorization&lt;/strong&gt;: Authorization is provided by an integration with Kubernetes RBAC.&lt;/p&gt;
&lt;p&gt;OpenDataology multi-user isolation is configured by OpenDataology administrators.   Administrators configure OpenDataology User Profiles for each user.  After the configuration is created and applied, a User can only access the OpenDataology components that the Administrator has configured for them.  The configuration limits non-authorized UI users from viewing or accidentally deleting model artifacts.&lt;/p&gt;
&lt;p&gt;With multi-user isolation, Users are authenticated and authorized, and then provided with a time-based token i.e. a json web token (JWT).   The access token is carried as a web header in user requests, and authorizes the user to access the resources configured in their Profile.  The Profile configures several items including the User’s namespace(s), RBAC RoleBinding, Istio ServiceRole and ServiceRoleBindings along with Resource Quotas and Custom Plug-ins.   More information on the Profile definition and related CRD can be found &lt;a href=&#34;https://github.com/OpenDataology/OpenDataology/blob/master/components/profile-controller/README.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;current-integration&#34;&gt;Current integration&lt;/h2&gt;
&lt;p&gt;These OpenDataology Components can support multi-user isolation: Central Dashboard, Notebooks, Pipelines, AutoML (Katib), KFServing.  Furthermore, resources created by the notebooks (for example, training jobs and deployments) also inherit the same access.&lt;/p&gt;
&lt;p&gt;Important notes: Multi-user isolation has several configurable dependencies, especially those related to how OpenDataology is configured with the underlying Kubernetes cluster’s identity management system.   Additionally, OpenDataology multi-user isolation doesn’t provide hard security guarantees against malicious attempts to infiltrate another user’s profile.&lt;/p&gt;
&lt;p&gt;When configuring multi-user isolation along with your security and identity management requirements, it is recommended that you consult with your &lt;a href=&#34;https://www.OpenDataology.org/docs/distributions/&#34;&gt;distribution provider&lt;/a&gt;.   This KubeCon &lt;a href=&#34;https://www.youtube.com/watch?v=U8yWOKOhzes&#34;&gt;presentation&lt;/a&gt; provides a detailed review of the architecture and implementation.   For on-premise deployments, OpenDataology uses Dex as a federated OpenID connection provider and can be integrated with LDAP or Active Directory to provide authentication and identity services.   This can be an advanced configuration and it is recommended that you consult with a distribution provider, or a team that provides advanced technical support for on-premise OpenDataology.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn more about &lt;a href=&#34;/docs/components/multi-tenancy/design/&#34;&gt;multi-user isolation design&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Introduction to the Pipelines SDK</title>
      <link>/docs/components/pipelines/sdk/sdk-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/sdk/sdk-overview/</guid>
      <description>
        
        
        &lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
This OpenDataology component has &lt;b&gt;stable&lt;/b&gt; status. See the
&lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
&lt;/div&gt;
&lt;p&gt;The &lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.html&#34;&gt;OpenDataology Pipelines
SDK&lt;/a&gt;
provides a set of Python packages that you can use to specify and run your
machine learning (ML) workflows. A &lt;em&gt;pipeline&lt;/em&gt; is a description of an ML
workflow, including all of the &lt;em&gt;components&lt;/em&gt; that make up the steps in the
workflow and how the components interact with each other.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The SDK documentation here refers to &lt;a href=&#34;https://github.com/OpenDataology/pipelines&#34;&gt;OpenDataology Pipelines with Argo&lt;/a&gt; which is the default.
If you are running &lt;a href=&#34;https://github.com/OpenDataology/kfp-tekton&#34;&gt;OpenDataology Pipelines with Tekton&lt;/a&gt; instead,
please follow the &lt;a href=&#34;/docs/components/pipelines/sdk/pipelines-with-tekton&#34;&gt;OpenDataology Pipelines SDK for Tekton&lt;/a&gt; documentation.&lt;/p&gt;
&lt;h2 id=&#34;sdk-packages&#34;&gt;SDK packages&lt;/h2&gt;
&lt;p&gt;The OpenDataology Pipelines SDK includes the following packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.compiler.html&#34;&gt;&lt;code&gt;kfp.compiler&lt;/code&gt;&lt;/a&gt;
includes classes and methods for compiling pipeline Python DSL into a workflow yaml spec
Methods in this package include, but are not limited
to, the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kfp.compiler.Compiler.compile&lt;/code&gt; compiles your Python DSL code into a single
static configuration (in YAML format) that the OpenDataology Pipelines service
can process. The OpenDataology Pipelines service converts the static
configuration into a set of Kubernetes resources for execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.components.html&#34;&gt;&lt;code&gt;kfp.components&lt;/code&gt;&lt;/a&gt;
includes classes and methods for interacting with pipeline components.
Methods in this package include, but are not limited to, the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.components.func_to_container_op&lt;/code&gt; converts a Python function to a
pipeline component and returns a factory function.
You can then call the factory function to construct an instance of a
pipeline task
(&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp&#34;&gt;&lt;code&gt;ContainerOp&lt;/code&gt;&lt;/a&gt;)
that runs the original function in a container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.components.load_component_from_file&lt;/code&gt; loads a pipeline component from
a file and returns a factory function.
You can then call the factory function to construct an instance of a
pipeline task
(&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp&#34;&gt;&lt;code&gt;ContainerOp&lt;/code&gt;&lt;/a&gt;)
that runs the component container image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.components.load_component_from_url&lt;/code&gt; loads a pipeline component from
a URL and returns a factory function.
You can then call the factory function to construct an instance of a
pipeline task
(&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp&#34;&gt;&lt;code&gt;ContainerOp&lt;/code&gt;&lt;/a&gt;)
that runs the component container image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html&#34;&gt;&lt;code&gt;kfp.dsl&lt;/code&gt;&lt;/a&gt;
contains the domain-specific language (DSL) that you can use to define and
interact with pipelines and components.
Methods, classes, and modules in this package include, but are not limited to,
the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.dsl.PipelineParam&lt;/code&gt; represents a pipeline parameter that you can pass
from one pipeline component to another. See the guide to
&lt;a href=&#34;/docs/components/pipelines/sdk/parameters/&#34;&gt;pipeline parameters&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.dsl.component&lt;/code&gt; is a decorator for DSL functions that returns a
pipeline component.
(&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp&#34;&gt;&lt;code&gt;ContainerOp&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.dsl.pipeline&lt;/code&gt; is a decorator for Python functions that returns a
pipeline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp.dsl.python_component&lt;/code&gt; is a decorator for Python functions that adds
pipeline component metadata to the function object.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.types.html&#34;&gt;&lt;code&gt;kfp.dsl.types&lt;/code&gt;&lt;/a&gt;
contains a list of types defined by the OpenDataology Pipelines SDK. Types
include basic types like &lt;code&gt;String&lt;/code&gt;, &lt;code&gt;Integer&lt;/code&gt;, &lt;code&gt;Float&lt;/code&gt;, and &lt;code&gt;Bool&lt;/code&gt;, as well
as domain-specific types like &lt;code&gt;GCPProjectID&lt;/code&gt; and &lt;code&gt;GCRPath&lt;/code&gt;.
See the guide to
&lt;a href=&#34;/docs/components/pipelines/sdk/static-type-checking&#34;&gt;DSL static type checking&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ResourceOp&#34;&gt;&lt;code&gt;kfp.dsl.ResourceOp&lt;/code&gt;&lt;/a&gt;
represents a pipeline task (op) which lets you directly manipulate
Kubernetes resources (&lt;code&gt;create&lt;/code&gt;, &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;apply&lt;/code&gt;, &amp;hellip;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.VolumeOp&#34;&gt;&lt;code&gt;kfp.dsl.VolumeOp&lt;/code&gt;&lt;/a&gt;
represents a pipeline task (op) which creates a new &lt;code&gt;PersistentVolumeClaim&lt;/code&gt;
(PVC). It aims to make the common case of creating a &lt;code&gt;PersistentVolumeClaim&lt;/code&gt;
fast.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.VolumeSnapshotOp&#34;&gt;&lt;code&gt;kfp.dsl.VolumeSnapshotOp&lt;/code&gt;&lt;/a&gt;
represents a pipeline task (op) which creates a new &lt;code&gt;VolumeSnapshot&lt;/code&gt;. It
aims to make the common case of creating a &lt;code&gt;VolumeSnapshot&lt;/code&gt; fast.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.PipelineVolume&#34;&gt;&lt;code&gt;kfp.dsl.PipelineVolume&lt;/code&gt;&lt;/a&gt;
represents a volume used to pass data between pipeline steps. &lt;code&gt;ContainerOp&lt;/code&gt;s
can mount a &lt;code&gt;PipelineVolume&lt;/code&gt; either via the constructor&amp;rsquo;s argument
&lt;code&gt;pvolumes&lt;/code&gt; or &lt;code&gt;add_pvolumes()&lt;/code&gt; method.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ParallelFor&#34;&gt;&lt;code&gt;kfp.dsl.ParallelFor&lt;/code&gt;&lt;/a&gt;
represents a parallel for loop over a static or dynamic set of items in a pipeline.
Each iteration of the for loop is executed in parallel.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ExitHandler&#34;&gt;&lt;code&gt;kfp.dsl.ExitHandler&lt;/code&gt;&lt;/a&gt;
represents an exit handler that is invoked upon exiting a pipeline. A typical
usage of &lt;code&gt;ExitHandler&lt;/code&gt; is garbage collection.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.Condition&#34;&gt;&lt;code&gt;kfp.dsl.Condition&lt;/code&gt;&lt;/a&gt;
represents a group of ops, that will only be executed when a certain condition is met.
The condition specified need to be determined at runtime, by incorporating at least one task output,
or PipelineParam in the boolean expression.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.client.html&#34;&gt;&lt;code&gt;kfp.Client&lt;/code&gt;&lt;/a&gt;
contains the Python client libraries for the &lt;a href=&#34;/docs/components/pipelines/reference/api/OpenDataology-pipeline-api-spec/&#34;&gt;OpenDataology Pipelines
API&lt;/a&gt;.
Methods in this package include, but are not limited to, the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.create_experiment&lt;/code&gt; creates a pipeline
&lt;a href=&#34;/docs/components/pipelines/concepts/experiment/&#34;&gt;experiment&lt;/a&gt; and returns an
experiment object.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.run_pipeline&lt;/code&gt; runs a pipeline and returns a run object.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.create_run_from_pipeline_func&lt;/code&gt; compiles a pipeline function and submits it
for execution on OpenDataology Pipelines.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.create_run_from_pipeline_package&lt;/code&gt; runs a local pipeline package on OpenDataology Pipelines.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.upload_pipeline&lt;/code&gt; uploads a local file to create a new pipeline in OpenDataology Pipelines.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.Client.upload_pipeline_version&lt;/code&gt; uploads a local file to create a pipeline version. &lt;a href=&#34;/docs/components/pipelines/tutorials/sdk-examples&#34;&gt;Follow an example to learn more about creating a pipeline version&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://OpenDataology-pipelines.readthedocs.io/en/stable/source/kfp.extensions.html&#34;&gt;OpenDataology Pipelines extension modules&lt;/a&gt;
include classes and functions for specific platforms on which you can use
OpenDataology Pipelines. Examples include utility functions for on premises,
Google Cloud Platform (GCP), Amazon Web Services (AWS), and Microsoft Azure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/sdk/python/kfp/cli/diagnose_me&#34;&gt;OpenDataology Pipelines diagnose_me modules&lt;/a&gt; include classes and functions that help with environment diagnostic tasks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kfp.cli.diagnose_me.dev_env&lt;/code&gt; reports on diagnostic metadata from your development environment, such as your python library version.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.cli.diagnose_me.kubernetes_cluster&lt;/code&gt; reports on diagnostic data from your Kubernetes cluster, such as Kubernetes secrets.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfp.cli.diagnose_me.gcp&lt;/code&gt; reports on diagnostic data related to your GCP environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opendataology-pipelines-cli-tool&#34;&gt;OpenDataology Pipelines CLI tool&lt;/h2&gt;
&lt;p&gt;The OpenDataology Pipelines CLI tool enables you to use a subset of the OpenDataology Pipelines SDK directly from the command line. The OpenDataology Pipelines CLI tool provides the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp diagnose_me&lt;/code&gt; runs environment diagnostic with specified parameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--json&lt;/code&gt; - Indicates that this command must return its results as JSON. Otherwise, results are returned in human readable format.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--namespace TEXT&lt;/code&gt; - Specifies the Kubernetes namespace to use. all-namespaces is the default value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--project-id TEXT&lt;/code&gt; - For GCP deployments, this value specifies the GCP project to use. If this value is not specified, the environment default is used.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp pipeline &amp;lt;COMMAND&amp;gt;&lt;/code&gt; provides the following commands to help you manage pipelines.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get&lt;/code&gt;  - Gets detailed information about a OpenDataology pipeline from your OpenDataology Pipelines cluster.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;list&lt;/code&gt; - Lists the pipelines that have been uploaded to your OpenDataology Pipelines cluster.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;upload&lt;/code&gt; - Uploads a pipeline to your OpenDataology Pipelines cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp run &amp;lt;COMMAND&amp;gt;&lt;/code&gt; provides the following commands to help you manage pipeline runs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get&lt;/code&gt; - Displays the details of a pipeline run.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;list&lt;/code&gt; - Lists recent pipeline runs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;submit&lt;/code&gt; - Submits a pipeline run.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;kfp --endpoint &amp;lt;ENDPOINT&amp;gt;&lt;/code&gt; - Specifies the endpoint that the OpenDataology Pipelines CLI should connect to.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installing-the-sdk&#34;&gt;Installing the SDK&lt;/h2&gt;
&lt;p&gt;Follow the guide to
&lt;a href=&#34;/docs/components/pipelines/sdk/install-sdk/&#34;&gt;installing the OpenDataology Pipelines SDK&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;building-pipelines-and-components&#34;&gt;Building pipelines and components&lt;/h2&gt;
&lt;p&gt;This section summarizes the ways you can use the SDK to build pipelines and
components.&lt;/p&gt;
&lt;p&gt;A OpenDataology &lt;em&gt;pipeline&lt;/em&gt; is a portable and scalable definition of an ML workflow.
Each step in your ML workflow, such as preparing data or training a model,
is an instance of a pipeline component.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/pipelines/sdk/build-pipeline&#34;&gt;Learn more about building pipelines&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A pipeline &lt;em&gt;component&lt;/em&gt; is a self-contained set of code that performs one step
in your ML workflow. Components are defined in a component specification, which
defines the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The component’s interface, its inputs and outputs.&lt;/li&gt;
&lt;li&gt;The component’s implementation, the container image and the command to
execute.&lt;/li&gt;
&lt;li&gt;The component’s metadata, such as the name and description of the
component.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the following options to create or reuse pipeline components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can build components by defining a component specification for a
containerized application.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/pipelines/sdk/component-development&#34;&gt;Learn more about building pipeline components&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lightweight Python function-based components make it easier to build a
component by using the OpenDataology Pipelines SDK to generate the component
specification for a Python function.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/docs/components/pipelines/sdk/python-function-components&#34;&gt;Learn how to build a Python function-based component&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can reuse prebuilt components in your pipeline.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/docs/examples/shared-resources/&#34;&gt;Learn more about reusing prebuilt components&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to &lt;a href=&#34;/docs/components/pipelines/sdk/dsl-recursion&#34;&gt;write recursive functions in the
DSL&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Build a &lt;a href=&#34;/docs/components/pipelines/sdk/component-development/&#34;&gt;pipeline component&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Find out how to use the DSL to &lt;a href=&#34;/docs/components/pipelines/sdk/manipulate-resources/&#34;&gt;manipulate Kubernetes resources dynamically
as steps of your pipeline&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Notebook (v1)</title>
      <link>/docs/components/notebooks/api-reference/notebook-v1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/notebooks/api-reference/notebook-v1/</guid>
      <description>
        
        
        &lt;p&gt;Packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#OpenDataology.org%2fv1&#34;&gt;OpenDataology.org/v1&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;OpenDataology.org/v1&#34;&gt;OpenDataology.org/v1&lt;/h2&gt;
&lt;p&gt;
&lt;p&gt;Package v1 contains API Schema definitions for the OpenDataology.org v1 API group&lt;/p&gt;
&lt;/p&gt;
Resource Types:
&lt;ul&gt;&lt;/ul&gt;
&lt;h3 id=&#34;OpenDataology.org/v1.Notebook&#34;&gt;Notebook
&lt;/h3&gt;
&lt;p&gt;
&lt;p&gt;Notebook is the Schema for the notebooks API&lt;/p&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Field&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;metadata&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#objectmeta-v1-meta&#34;&gt;
Kubernetes meta/v1.ObjectMeta
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
Refer to the Kubernetes API documentation for the fields of the
&lt;code&gt;metadata&lt;/code&gt; field.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;spec&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookSpec&#34;&gt;
NotebookSpec
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;template&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookTemplateSpec&#34;&gt;
NotebookTemplateSpec
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
Important: Run &amp;ldquo;make&amp;rdquo; to regenerate code after modifying this file&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;status&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookStatus&#34;&gt;
NotebookStatus
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;OpenDataology.org/v1.NotebookCondition&#34;&gt;NotebookCondition
&lt;/h3&gt;
&lt;p&gt;
(&lt;em&gt;Appears on:&lt;/em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookStatus&#34;&gt;NotebookStatus&lt;/a&gt;)
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Field&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;type&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;Type is the type of the condition. Possible values are Running|Waiting|Terminated&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;lastProbeTime&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#time-v1-meta&#34;&gt;
Kubernetes meta/v1.Time
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Last time we probed the condition.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;reason&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;(brief) reason the container is in the current state&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;message&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Message regarding why the container is in the current state.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;OpenDataology.org/v1.NotebookSpec&#34;&gt;NotebookSpec
&lt;/h3&gt;
&lt;p&gt;
(&lt;em&gt;Appears on:&lt;/em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.Notebook&#34;&gt;Notebook&lt;/a&gt;)
&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;NotebookSpec defines the desired state of Notebook&lt;/p&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Field&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;template&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookTemplateSpec&#34;&gt;
NotebookTemplateSpec
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
Important: Run &amp;ldquo;make&amp;rdquo; to regenerate code after modifying this file&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;OpenDataology.org/v1.NotebookStatus&#34;&gt;NotebookStatus
&lt;/h3&gt;
&lt;p&gt;
(&lt;em&gt;Appears on:&lt;/em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.Notebook&#34;&gt;Notebook&lt;/a&gt;)
&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;NotebookStatus defines the observed state of Notebook&lt;/p&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Field&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;conditions&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookCondition&#34;&gt;
[]NotebookCondition
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;Conditions is an array of current conditions&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;readyReplicas&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
int32
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;ReadyReplicas is the number of Pods created by the StatefulSet controller that have a Ready Condition.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;containerState&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#containerstate-v1-core&#34;&gt;
Kubernetes core/v1.ContainerState
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;ContainerState is the state of underlying container.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;OpenDataology.org/v1.NotebookTemplateSpec&#34;&gt;NotebookTemplateSpec
&lt;/h3&gt;
&lt;p&gt;
(&lt;em&gt;Appears on:&lt;/em&gt;
&lt;a href=&#34;#OpenDataology.org/v1.NotebookSpec&#34;&gt;NotebookSpec&lt;/a&gt;)
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Field&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;spec&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#podspec-v1-core&#34;&gt;
Kubernetes core/v1.PodSpec
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;volumes&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core&#34;&gt;
[]Kubernetes core/v1.Volume
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;List of volumes that can be mounted by containers belonging to the pod.
More info: &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes&#34;&gt;https://kubernetes.io/docs/concepts/storage/volumes&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;initContainers&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core&#34;&gt;
[]Kubernetes core/v1.Container
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;List of initialization containers belonging to the pod.
Init containers are executed in order prior to containers being started. If any
init container fails, the pod is considered to have failed and is handled according
to its restartPolicy. The name for an init container or normal container must be
unique among all containers.
Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes.
The resourceRequirements of an init container are taken into account during scheduling
by finding the highest request/limit for each resource type, and then using the max of
of that value or the sum of the normal containers. Limits are applied to init containers
in a similar fashion.
Init containers cannot currently be added or removed.
Cannot be updated.
More info: &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/init-containers/&#34;&gt;https://kubernetes.io/docs/concepts/workloads/pods/init-containers/&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;containers&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core&#34;&gt;
[]Kubernetes core/v1.Container
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;List of containers belonging to the pod.
Containers cannot currently be added or removed.
There must be at least one container in a Pod.
Cannot be updated.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;ephemeralContainers&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#ephemeralcontainer-v1-core&#34;&gt;
[]Kubernetes core/v1.EphemeralContainer
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing
pod to perform user-initiated actions such as debugging. This list cannot be specified when
creating a pod, and it cannot be modified by updating the pod spec. In order to add an
ephemeral container to an existing pod, use the pod&amp;rsquo;s ephemeralcontainers subresource.
This field is alpha-level and is only honored by servers that enable the EphemeralContainers feature.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;restartPolicy&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Restart policy for all containers within the pod.
One of Always, OnFailure, Never.
Default to Always.
More info: &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy&#34;&gt;https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;terminationGracePeriodSeconds&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
int64
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Optional duration in seconds the pod needs to terminate gracefully. May be decreased in delete request.
Value must be non-negative integer. The value zero indicates delete immediately.
If this value is nil, the default grace period will be used instead.
The grace period is the duration in seconds after the processes running in the pod are sent
a termination signal and the time when the processes are forcibly halted with a kill signal.
Set this value longer than the expected cleanup time for your process.
Defaults to 30 seconds.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;activeDeadlineSeconds&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
int64
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Optional duration in seconds the pod may be active on the node relative to
StartTime before the system will actively try to mark it failed and kill associated containers.
Value must be a positive integer.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;dnsPolicy&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Set DNS policy for the pod.
Defaults to &amp;ldquo;ClusterFirst&amp;rdquo;.
Valid values are &amp;lsquo;ClusterFirstWithHostNet&amp;rsquo;, &amp;lsquo;ClusterFirst&amp;rsquo;, &amp;lsquo;Default&amp;rsquo; or &amp;lsquo;None&amp;rsquo;.
DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy.
To have DNS options set along with hostNetwork, you have to specify DNS policy
explicitly to &amp;lsquo;ClusterFirstWithHostNet&amp;rsquo;.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;nodeSelector&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
map[string]string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;NodeSelector is a selector which must be true for the pod to fit on a node.
Selector which must match a node&amp;rsquo;s labels for the pod to be scheduled on that node.
More info: &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/&#34;&gt;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;serviceAccountName&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;ServiceAccountName is the name of the ServiceAccount to use to run this pod.
More info: &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;serviceAccount&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;DeprecatedServiceAccount is a depreciated alias for ServiceAccountName.
Deprecated: Use serviceAccountName instead.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;automountServiceAccountToken&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;AutomountServiceAccountToken indicates whether a service account token should be automatically mounted.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;nodeName&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;NodeName is a request to schedule this pod onto a specific node. If it is non-empty,
the scheduler simply schedules this pod onto that node, assuming that it fits resource
requirements.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;hostNetwork&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Host networking requested for this pod. Use the host&amp;rsquo;s network namespace.
If this option is set, the ports that will be used must be specified.
Default to false.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;hostPID&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Use the host&amp;rsquo;s pid namespace.
Optional: Default to false.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;hostIPC&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Use the host&amp;rsquo;s ipc namespace.
Optional: Default to false.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;shareProcessNamespace&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Share a single process namespace between all of the containers in a pod.
When this is set containers will be able to view and signal processes from other containers
in the same pod, and the first process in each container will not be assigned PID 1.
HostPID and ShareProcessNamespace cannot both be set.
Optional: Default to false.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;securityContext&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#podsecuritycontext-v1-core&#34;&gt;
Kubernetes core/v1.PodSecurityContext
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;SecurityContext holds pod-level security attributes and common container settings.
Optional: Defaults to empty.  See type description for default values of each field.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;imagePullSecrets&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#localobjectreference-v1-core&#34;&gt;
[]Kubernetes core/v1.LocalObjectReference
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec.
If specified, these secrets will be passed to individual puller implementations for them to use. For example,
in the case of docker, only DockerConfig type secrets are honored.
More info: &lt;a href=&#34;https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod&#34;&gt;https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;hostname&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Specifies the hostname of the Pod
If not specified, the pod&amp;rsquo;s hostname will be set to a system-defined value.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;subdomain&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, the fully qualified Pod hostname will be &amp;ldquo;&lt;hostname&gt;.&lt;subdomain&gt;.&lt;pod namespace&gt;.svc.&lt;cluster domain&gt;&amp;rdquo;.
If not specified, the pod will not have a domainname at all.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;affinity&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#affinity-v1-core&#34;&gt;
Kubernetes core/v1.Affinity
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, the pod&amp;rsquo;s scheduling constraints&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;schedulerName&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, the pod will be dispatched by specified scheduler.
If not specified, the pod will be dispatched by default scheduler.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;tolerations&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#toleration-v1-core&#34;&gt;
[]Kubernetes core/v1.Toleration
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, the pod&amp;rsquo;s tolerations.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;hostAliases&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#hostalias-v1-core&#34;&gt;
[]Kubernetes core/v1.HostAlias
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;HostAliases is an optional list of hosts and IPs that will be injected into the pod&amp;rsquo;s hosts
file if specified. This is only valid for non-hostNetwork pods.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;priorityClassName&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, indicates the pod&amp;rsquo;s priority. &amp;ldquo;system-node-critical&amp;rdquo; and
&amp;ldquo;system-cluster-critical&amp;rdquo; are two special keywords which indicate the
highest priorities with the former being the highest priority. Any other
name must be defined by creating a PriorityClass object with that name.
If not specified, the pod priority will be default or zero if there is no
default.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;priority&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
int32
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;The priority value. Various system components use this field to find the
priority of the pod. When Priority Admission Controller is enabled, it
prevents users from setting this field. The admission controller populates
this field from PriorityClassName.
The higher the value, the higher the priority.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;dnsConfig&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#poddnsconfig-v1-core&#34;&gt;
Kubernetes core/v1.PodDNSConfig
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Specifies the DNS parameters of a pod.
Parameters specified here will be merged to the generated DNS
configuration based on DNSPolicy.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;readinessGates&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#podreadinessgate-v1-core&#34;&gt;
[]Kubernetes core/v1.PodReadinessGate
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;If specified, all readiness gates will be evaluated for pod readiness.
A pod is ready when all its containers are ready AND
all conditions specified in the readiness gates have status equal to &amp;ldquo;True&amp;rdquo;
More info: &lt;a href=&#34;https://git.k8s.io/enhancements/keps/sig-network/0007-pod-ready%2B%2B.md&#34;&gt;https://git.k8s.io/enhancements/keps/sig-network/0007-pod-ready%2B%2B.md&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;runtimeClassName&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used
to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run.
If unset or empty, the &amp;ldquo;legacy&amp;rdquo; RuntimeClass will be used, which is an implicit class with an
empty definition that uses the default runtime handler.
More info: &lt;a href=&#34;https://git.k8s.io/enhancements/keps/sig-node/runtime-class.md&#34;&gt;https://git.k8s.io/enhancements/keps/sig-node/runtime-class.md&lt;/a&gt;
This is a beta feature as of Kubernetes v1.14.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;enableServiceLinks&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
bool
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;EnableServiceLinks indicates whether information about services should be injected into pod&amp;rsquo;s
environment variables, matching the syntax of Docker links.
Optional: Defaults to true.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;preemptionPolicy&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
string
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;PreemptionPolicy is the Policy for preempting pods with lower priority.
One of Never, PreemptLowerPriority.
Defaults to PreemptLowerPriority if unset.
This field is alpha-level and is only honored by servers that enable the NonPreemptingPriority feature.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;overhead&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
object
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;Overhead represents the resource overhead associated with running a pod for a given RuntimeClass.
This field will be autopopulated at admission time by the RuntimeClass admission controller. If
the RuntimeClass admission controller is enabled, overhead must not be set in Pod create requests.
The RuntimeClass admission controller will reject Pod create requests which have the overhead already
set. If RuntimeClass is configured and selected in the PodSpec, Overhead will be set to the value
defined in the corresponding RuntimeClass, otherwise it will remain unset and treated as zero.
More info: &lt;a href=&#34;https://git.k8s.io/enhancements/keps/sig-node/20190226-pod-overhead.md&#34;&gt;https://git.k8s.io/enhancements/keps/sig-node/20190226-pod-overhead.md&lt;/a&gt;
This field is alpha-level as of Kubernetes v1.16, and is only honored by servers that enable the PodOverhead feature.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;topologySpreadConstraints&lt;/code&gt;&lt;/br&gt;
&lt;em&gt;
&lt;a href=&#34;https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#topologyspreadconstraint-v1-core&#34;&gt;
[]Kubernetes core/v1.TopologySpreadConstraint
&lt;/a&gt;
&lt;/em&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;(Optional)&lt;/em&gt;
&lt;p&gt;TopologySpreadConstraints describes how a group of pods ought to spread across topology
domains. Scheduler will schedule pods in a way which abides by the constraints.
This field is alpha-level and is only honored by clusters that enables the EvenPodsSpread
feature.
All topologySpreadConstraints are ANDed.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;em&gt;
Generated with &lt;code&gt;gen-crd-api-reference-docs&lt;/code&gt;
on git commit &lt;code&gt;3b35937&lt;/code&gt;.
&lt;/em&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
