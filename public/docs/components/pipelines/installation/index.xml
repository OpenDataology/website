<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenDataology – Installation</title>
    <link>/docs/components/pipelines/installation/</link>
    <description>Recent content in Installation on OpenDataology</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/components/pipelines/installation/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Installation Options</title>
      <link>/docs/components/pipelines/installation/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/overview/</guid>
      <description>
        
        
        &lt;p&gt;OpenDataology Pipelines offers a few installation options.
This page describes the options and the features available
with each option:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt; is the minimal
portable installation that only includes OpenDataology Pipelines.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines as &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;part of a full OpenDataology deployment&lt;/a&gt; provides
all OpenDataology components and more integration with each platform.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beta&lt;/strong&gt;: &lt;a href=&#34;#google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/a&gt; makes it easier to install and use OpenDataology Pipelines on Google Cloud by providing a management UI on &lt;a href=&#34;https://console.cloud.google.com/ai-platform/pipelines/clusters&#34;&gt;Google Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;/docs/components/pipelines/installation/localcluster-deployment&#34;&gt;local&lt;/a&gt; OpenDataology Pipelines deployment for testing purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;choosing-an-installation-option&#34;&gt;Choosing an installation option&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Do you want to use other OpenDataology components in addition to Pipelines?&lt;/p&gt;
&lt;p&gt;If yes, choose the &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology deployment&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Can you use a cloud/on-prem Kubernetes cluster?&lt;/p&gt;
&lt;p&gt;If you can&amp;rsquo;t, you should try using OpenDataology Pipelines on a local Kubernetes cluster for learning and testing purposes by following the steps in &lt;a href=&#34;/docs/components/pipelines/installation/localcluster-deployment&#34;&gt;Deploying OpenDataology Pipelines on a local cluster&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do you want to use OpenDataology Pipelines with &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/1223&#34;&gt;multi-user support&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;If yes, choose the &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology deployment&lt;/a&gt; with version &amp;gt;= v1.1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do you deploy on Google Cloud?&lt;/p&gt;
&lt;p&gt;If yes, deploy &lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt;. You can also
use &lt;a href=&#34;#google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/a&gt; to deploy OpenDataology Pipelines
using a user interface, but there are limitations in
customizability and upgradability. For details, please read corresponding
sections.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You deploy on other platforms.&lt;/p&gt;
&lt;p&gt;Please compare your platform specific &lt;a href=&#34;#full-OpenDataology-deployment&#34;&gt;full OpenDataology&lt;/a&gt; with the
&lt;a href=&#34;#OpenDataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt; before making your decision.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; Choose your installation option with caution, there&amp;rsquo;s no current
supported path to migrate data between different installation options. Please
create &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/new/choose&#34;&gt;a GitHub issue&lt;/a&gt;
if that&amp;rsquo;s important for you.&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;standalone&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;opendataology-pipelines-standalone&#34;&gt;OpenDataology Pipelines Standalone&lt;/h2&gt;
&lt;p&gt;Use this option to deploy OpenDataology Pipelines to an on-premises, cloud
or even local Kubernetes cluster, without the other components of OpenDataology.
To deploy OpenDataology Pipelines Standalone, you use kustomize manifests only.
This process makes it simpler to customize your deployment and to integrate
OpenDataology Pipelines into an existing Kubernetes cluster.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/components/pipelines/installation/standalone-deployment/&#34;&gt;OpenDataology Pipelines Standalone deployment
guide&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenDataology Pipelines UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines API&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint is &lt;strong&gt;only auto-configured&lt;/strong&gt; for Google Cloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you wish to deploy OpenDataology Pipelines on other platforms, you can either access it through
&lt;code&gt;kubectl port-forward&lt;/code&gt; or configure your own platform specific auth-enabled
endpoint by yourself.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;OpenDataology Pipelines Standalone is available for every OpenDataology Pipelines release.
You will have access to the latest features.&lt;/dd&gt;
&lt;dt&gt;Upgrade Support (&lt;strong&gt;Beta&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/components/pipelines/installation/standalone-deployment/#upgrading-OpenDataology-pipelines&#34;&gt;Upgrading OpenDataology Pipelines Standalone&lt;/a&gt; introduces how to upgrade
in place.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you.&lt;/li&gt;
&lt;li&gt;Open the OpenDataology Pipelines UI via the &lt;strong&gt;Open Pipelines Dashboard&lt;/strong&gt; link in &lt;a href=&#34;https://console.cloud.google.com/ai-platform/pipelines/clusters&#34;&gt;the AI Platform Pipelines dashboard of Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;(Optional) You can choose to persist your data in Google Cloud managed storage (Cloud SQL and Cloud Storage).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/&#34;&gt;All options to authenticate to Google Cloud&lt;/a&gt; are supported.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster contains OpenDataology Pipelines only.
It does not include the other OpenDataology components.
For example, to use a Jupyter Notebook, you must use a local notebook or a
hosted notebook in a cloud service such as the &lt;a href=&#34;https://cloud.google.com/ai-platform/notebooks/docs/&#34;&gt;AI Platform
Notebooks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;not available&lt;/strong&gt; in standalone, because
multi-user support depends on other OpenDataology components.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id=&#34;full-OpenDataology&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;full-opendataology-deployment&#34;&gt;Full OpenDataology deployment&lt;/h2&gt;
&lt;p&gt;Use this option to deploy OpenDataology Pipelines to your local machine, on-premises,
or to a cloud, as part of a full OpenDataology installation.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;/docs/started/getting-started/&#34;&gt;OpenDataology installation guide&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenDataology UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines UI within or outside the OpenDataology UI&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines API&lt;/li&gt;
&lt;li&gt;Other OpenDataology APIs&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint is auto-configured with auth support for each platform&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;The full OpenDataology is released quarterly. It has significant delay in receiving
OpenDataology Pipelines updates.&lt;/dd&gt;
&lt;/dl&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OpenDataology Version&lt;/th&gt;
&lt;th&gt;OpenDataology Pipelines Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.7.0&lt;/td&gt;
&lt;td&gt;0.1.31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0.0&lt;/td&gt;
&lt;td&gt;0.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0.2&lt;/td&gt;
&lt;td&gt;0.2.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.1.0&lt;/td&gt;
&lt;td&gt;1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2.0&lt;/td&gt;
&lt;td&gt;1.0.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.3.0&lt;/td&gt;
&lt;td&gt;1.5.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.4.0&lt;/td&gt;
&lt;td&gt;1.7.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: Google Cloud, AWS, and IBM Cloud have supported OpenDataology Pipelines 1.0.0 with multi-user separation. Other platforms might not be up-to-date for now, refer to &lt;a href=&#34;https://github.com/OpenDataology/manifests/issues/1364#issuecomment-668415871&#34;&gt;this GitHub issue&lt;/a&gt; for status.&lt;/p&gt;
&lt;p&gt;Upgrade Support
:
Refer to &lt;a href=&#34;/docs/gke/pipelines/upgrade/#full-OpenDataology&#34;&gt;the full OpenDataology section of upgrading OpenDataology Pipelines on Google Cloud&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you using &lt;a href=&#34;https://cloud.google.com/iap&#34;&gt;Cloud Identity-Aware Proxy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s no current support for persisting your data in Google Cloud managed storage (Cloud SQL and Cloud Storage). Refer to &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/4356&#34;&gt;this GitHub issue&lt;/a&gt; for the latest status.&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/#workload-identity&#34;&gt;authenticate to Google Cloud with Workload Identity&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster includes all the
&lt;a href=&#34;/docs/components/&#34;&gt;OpenDataology components&lt;/a&gt;.
For example, you can use the Jupyter notebook services
&lt;a href=&#34;/docs/components/notebooks/&#34;&gt;deployed with OpenDataology&lt;/a&gt; to create one or more notebook
servers in your OpenDataology cluster.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;only available&lt;/strong&gt; in full OpenDataology. It supports
using a single OpenDataology Pipelines control plane to orchestrate user pipeline
runs in multiple user namespaces with authorization.&lt;/li&gt;
&lt;li&gt;Latest features and bug fixes may not be available soon because release
cadence is long.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id=&#34;marketplace&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;google-cloud-ai-platform-pipelines&#34;&gt;Google Cloud AI Platform Pipelines&lt;/h2&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Beta release&lt;/h4&gt;

    &lt;p&gt;Google Cloud AI Platform Pipelines is currently in &lt;b&gt;Beta&lt;/b&gt; with
  limited support. The OpenDataology Pipelines team is interested in any feedback you may have,
  in particular on the usability of the feature.
&lt;p&gt;You can raise any issues or discussion items in the
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues&#34;&gt;OpenDataology Pipelines
issue tracker&lt;/a&gt;.&lt;/p&gt;&lt;/p&gt;


&lt;/div&gt;

&lt;p&gt;Use this option to deploy OpenDataology Pipelines to Google Kubernetes Engine (GKE)
from Google Cloud Marketplace. You can deploy OpenDataology Pipelines to an existing or new
GKE cluster and manage your cluster within Google Cloud.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Installation guide&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/docs&#34;&gt;Google Cloud AI Platform Pipelines documentation&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Interfaces
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Cloud Console for managing the OpenDataology Pipelines cluster and other Google Cloud
services&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines UI via the &lt;strong&gt;Open Pipelines Dashboard&lt;/strong&gt; link in the
Google Cloud Console&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines SDK in Cloud Notebooks&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines endpoint of your instance is auto-configured for you&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;Release Schedule&lt;/dt&gt;
&lt;dd&gt;AI Platform Pipelines is available for a chosen set of stable OpenDataology
Pipelines releases. You will receive updates slightly slower than OpenDataology
Pipelines Standalone.&lt;/dd&gt;
&lt;dt&gt;Upgrade Support (&lt;strong&gt;Alpha&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;An in-place upgrade is not supported.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;To upgrade AI Platform Pipelines by reinstalling it (with existing data), refer to the &lt;a href=&#34;/docs/gke/pipelines/upgrade/#ai-platform-pipelines&#34;&gt;Upgrading AI Platform Pipelines&lt;/a&gt; guide.&lt;/p&gt;
&lt;p&gt;Google Cloud Integrations
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can deploy AI Platform Pipelines on &lt;a href=&#34;https://console.cloud.google.com/marketplace/details/google-cloud-ai-platform/OpenDataology-pipelines&#34;&gt;Cloud Console UI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A OpenDataology Pipelines public endpoint with auth support is &lt;strong&gt;auto-configured&lt;/strong&gt; for you.&lt;/li&gt;
&lt;li&gt;(Optional) You can choose to persist your data in Google Cloud managed storage services (Cloud SQL and Cloud Storage).&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/#compute-engine-default-service-account&#34;&gt;authenticate to Google Cloud with the Compute Engine default service account&lt;/a&gt;. However, this method may not be suitable if you need workload permission separation.&lt;/li&gt;
&lt;li&gt;You can deploy AI Platform Pipelines on both public and private GKE clusters as long as the cluster &lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/docs/configure-gke-cluster#ensure&#34;&gt;has sufficient resources for AI Platform Pipelines&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on specific features
:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After deployment, your Kubernetes cluster contains OpenDataology Pipelines only.
It does not include the other OpenDataology components.
For example, to use a Jupyter Notebook, you can use &lt;a href=&#34;https://cloud.google.com/ai-platform/notebooks/docs/&#34;&gt;AI Platform
Notebooks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;OpenDataology Pipelines multi-user support is &lt;strong&gt;not available&lt;/strong&gt; in AI Platform Pipelines, because
multi-user support depends on other OpenDataology components.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Local Deployment</title>
      <link>/docs/components/pipelines/installation/localcluster-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/localcluster-deployment/</guid>
      <description>
        
        
        &lt;p&gt;This guide shows how to deploy OpenDataology Pipelines standalone on a local
Kubernetes cluster using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kind&lt;/li&gt;
&lt;li&gt;K3s&lt;/li&gt;
&lt;li&gt;K3s on Windows Subsystem for Linux (WSL)&lt;/li&gt;
&lt;li&gt;K3ai [&lt;em&gt;alpha&lt;/em&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Such deployment methods can be part of your local environment using the supplied
kustomize manifests for test purposes. This guide is an alternative to&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/docs/started/getting-started/#installing-OpenDataology&#34;&gt;Deploying OpenDataology Pipelines
(KFP)&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;before-you-get-started&#34;&gt;Before you get started&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You should be familiar with &lt;a href=&#34;https://kubernetes.io/docs/home/&#34;&gt;Kubernetes&lt;/a&gt;,
&lt;a href=&#34;https://kubernetes.io/docs/reference/kubectl/overview/&#34;&gt;kubectl&lt;/a&gt;, and
&lt;a href=&#34;https://kustomize.io/&#34;&gt;kustomize&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For native support of kustomize, you will need kubectl v1.14 or higher. You
can download and install kubectl by following the &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34;&gt;kubectl installation
guide&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kind&#34;&gt;kind&lt;/h2&gt;
&lt;h3 id=&#34;1-installing-kind&#34;&gt;1. Installing kind&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://kind.sigs.k8s.io&#34;&gt;kind&lt;/a&gt; is a tool for running local Kubernetes clusters
using Docker container nodes. &lt;code&gt;kind&lt;/code&gt; was primarily designed for testing
Kubernetes itself. It can also be used for local development or CI.&lt;/p&gt;
&lt;p&gt;You can install and configure kind by following the
&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start/&#34;&gt;official quick start&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with kind:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On Linux:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Download and move the &lt;code&gt;kind&lt;/code&gt; executable to your directory in your PATH by
running the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -Lo ./kind https://kind.sigs.k8s.io/dl/&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;KIND_VERSION&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;/kind-linux-amd64 &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;chmod +x ./kind &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;mv ./kind /&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;YOUR_KIND_DIRECTORY&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;/kind
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Replace the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{KIND_VERSION}&lt;/code&gt;: the kind version; for example, &lt;code&gt;v0.8.1&lt;/code&gt; as of the date this
guide was written&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{YOUR_KIND_DIRECTORY}&lt;/code&gt;: your directory in PATH&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;On macOS:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can use &lt;a href=&#34;https://brew.sh&#34;&gt;Homebrew&lt;/a&gt; to install kind:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install kind
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;On Windows:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can use the administrative PowerShell console to run the following
commands to download and move the &lt;code&gt;kind&lt;/code&gt; executable to a directory in your
PATH:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PowerShell:&lt;/strong&gt; Run these commands to download and move the &lt;code&gt;kind&lt;/code&gt; executable
to a directory in your PATH:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;curl&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;exe&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;-Lo&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;kind-windows&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;-amd64&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;exe&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;https&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;//&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;sigs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;k8s&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;io&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;dl&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;/{&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KIND_VERSION&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}/&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;kind-windows&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;-amd64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;Move-Item&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.\&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;kind-windows&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;-amd64&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;exe&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;c:&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;\{&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;YOUR_KIND_DIRECTORY&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}\&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;exe&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Replace the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{KIND_VERSION}&lt;/code&gt;: the kind version - for example, &lt;code&gt;v0.9&lt;/code&gt; (check the latest
stable binary versions on the &lt;a href=&#34;https://github.com/kubernetes-sigs/kind/releases&#34;&gt;kind releases
pages&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{YOUR_KIND_DIRECTORY}&lt;/code&gt;: your directory for kind in PATH&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{KIND_VERSION}&lt;/code&gt;: the kind version; for example, &lt;code&gt;v0.8.1&lt;/code&gt; as of the date this
guide was written&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{YOUR_KIND_DIRECTORY}&lt;/code&gt;: your directory in PATH&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Alternatively, you can use Chocolatey &lt;a href=&#34;https://chocolatey.org/packages/kind&#34;&gt;https://chocolatey.org/packages/kind&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;choco install kind
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; kind uses containerd as a default container-runtime hence you cannot
use the standard OpenDataology pipeline manifests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start/&#34;&gt;kind: Quick Start Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/known-issues/&#34;&gt;kind: Known Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/working-offline/&#34;&gt;kind: Working Offline&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-creating-a-cluster-on-kind&#34;&gt;2. Creating a cluster on kind&lt;/h3&gt;
&lt;p&gt;Having installed kind, you can create a Kubernetes cluster on kind with this
command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind create cluster
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will bootstrap a Kubernetes cluster using a pre-built node image. You can
find that image on the Docker Hub &lt;code&gt;kindest/node&lt;/code&gt;
&lt;a href=&#34;https://hub.docker.com/r/kindest/node&#34;&gt;here&lt;/a&gt;. If you wish to build the node
image yourself, you can use the &lt;code&gt;kind build node-image&lt;/code&gt; command—see the official
&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start/#building-images&#34;&gt;building
image&lt;/a&gt; section
for more details. And, to specify another image, use the &lt;code&gt;--image&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;By default, the cluster will be given the name kind. Use the &lt;code&gt;--name&lt;/code&gt; flag to
assign the cluster a different context name.&lt;/p&gt;
&lt;h2 id=&#34;k3s&#34;&gt;K3s&lt;/h2&gt;
&lt;h3 id=&#34;1-setting-up-a-cluster-on-k3s&#34;&gt;1. Setting up a cluster on K3s&lt;/h3&gt;
&lt;p&gt;K3s is a fully compliant Kubernetes distribution with the following
enhancements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Packaged as a single binary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lightweight storage backend based on sqlite3 as the default storage mechanism.
etcd3, MySQL, Postgres also still available.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wrapped in simple launcher that handles a lot of the complexity of TLS and
options.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Secure by default with reasonable defaults for lightweight environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simple but powerful “batteries-included” features have been added, such as: a
local storage provider, a service load balancer, a Helm controller, and the
Traefik ingress controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Operation of all Kubernetes control plane components is encapsulated in a
single binary and process. This allows K3s to automate and manage complex
cluster operations like distributing certificates.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;External dependencies have been minimized (just a modern kernel and cgroup
mounts needed). K3s packages required dependencies, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;containerd&lt;/li&gt;
&lt;li&gt;Flannel&lt;/li&gt;
&lt;li&gt;CoreDNS&lt;/li&gt;
&lt;li&gt;CNI&lt;/li&gt;
&lt;li&gt;Host utilities (iptables, socat, etc)&lt;/li&gt;
&lt;li&gt;Ingress controller (traefik)&lt;/li&gt;
&lt;li&gt;Embedded service loadbalancer&lt;/li&gt;
&lt;li&gt;Embedded network policy controller&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find the the official K3s installation script to install it as a service
on systemd- or openrc-based systems on the official
&lt;a href=&#34;https://get.k3s.io&#34;&gt;K3s website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To install K3s using that method, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -sfL https://get.k3s.io &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; sh -
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rancher.com/docs/k3s/latest/en/quick-start/&#34;&gt;K3s: Quick Start Guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rancher.com/docs/k3s/latest/en/known-issues/&#34;&gt;K3s: Known Issues&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rancher.com/docs/k3s/latest/en/faq/&#34;&gt;K3s: FAQ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-creating-a-cluster-on-k3s&#34;&gt;2. Creating a cluster on K3s&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To create a Kubernetes cluster on K3s, use the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo k3s server &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will bootstrap a Kubernetes cluster kubeconfig is written to
&lt;code&gt;/etc/rancher/k3s/k3s.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Optional) Check your cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo k3s kubectl get node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;K3s embeds the popular kubectl command directly in the binaries, so you may
immediately interact with the cluster through it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Optional) Run the below command on a different node. &lt;code&gt;NODE_TOKEN&lt;/code&gt; comes from
&lt;code&gt;/var/lib/rancher/k3s/server/node-token&lt;/code&gt; on your server:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo k3s agent --server https://myserver:6443 --token &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;YOUR_NODE_TOKEN&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k3s-on-windows-subsystem-for-linux-wsl&#34;&gt;K3s on Windows Subsystem for Linux (WSL)&lt;/h2&gt;
&lt;h3 id=&#34;1-setting-up-a-cluster-on-k3s-on-windows-subsystem-for-linux-wsl&#34;&gt;1. Setting up a cluster on K3s on Windows Subsystem for Linux (WSL)&lt;/h3&gt;
&lt;p&gt;The Windows Subsystem for Linux (WSL) lets developers run a GNU/Linux
environment—including most command-line tools, utilities, and applications—
directly on Windows, unmodified, without the overhead of a traditional virtual
machine or dualboot setup.&lt;/p&gt;
&lt;p&gt;The full instructions for installing WSL can be found on the
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-win10&#34;&gt;official Windows site&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following steps summarize what you&amp;rsquo;ll need to set up WSL and then K3s on
WSL.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install [WSL] by following the official &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-win10&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As per the official instructions, update WSL and download your preferred
distibution:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/store/apps/9PN498VPMF3Z&#34;&gt;SUSE Linux Enterprise Server 15
SP1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/store/apps/9MZD0N9Z4M4H&#34;&gt;openSUSE Leap 15.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/store/apps/9N9TNGVNDL3Q&#34;&gt;Ubuntu 18.04 LTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/store/apps/9MSVKQC78PK6&#34;&gt;Debian GNU/Linux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/ibuildthecloud/1b7d6940552ada6d37f54c71a89f7d00&#34;&gt;K3s on WSL: Quick Start Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-creating-a-cluster-on-k3s-on-wsl&#34;&gt;2. Creating a cluster on K3s on WSL&lt;/h3&gt;
&lt;p&gt;Below are the steps to create a cluster on K3s in WSL&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To create a Kubernetes cluster on K3s on WSL, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ./k3s server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will bootstrap a Kubernetes cluster but you will cannot yet access from
your Windows machine to the cluster itself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can&amp;rsquo;t install K3s using the curl script because there is no
supervisor (systemd or openrc) in WSL.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the K3s binary from &lt;a href=&#34;https://github.com/rancher/k3s/releases/latest&#34;&gt;https://github.com/rancher/k3s/releases/latest&lt;/a&gt;.
Then, inside the directory where you download the K3s binary to, run this
command to add execute permission to the K3s binary:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod +x k3s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start K3s:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ./k3s server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-setting-up-access-to-wsl-instance&#34;&gt;3. Setting up access to WSL instance&lt;/h3&gt;
&lt;p&gt;To set up access to your WSL instance:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Copy &lt;code&gt;/etc/rancher/k3s/k3s.yaml&lt;/code&gt; from WSL to &lt;code&gt;$HOME/.kube/config&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit the copied file by changing the server URL from &lt;code&gt;https://localhost:6443&lt;/code&gt;
to the IP of the your WSL instance (&lt;code&gt;ip addr show dev eth0&lt;/code&gt;) (For example,
&lt;code&gt;https://192.168.170.170:6443&lt;/code&gt;.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run kubectl in a Windows terminal. If you don&amp;rsquo;t kubectl installed, follow the
official &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-windows&#34;&gt;Kubernetes on Windows instructions&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k3ai-alpha&#34;&gt;K3ai [&lt;em&gt;alpha&lt;/em&gt;]&lt;/h2&gt;
&lt;p&gt;K3ai is a lightweight &amp;ldquo;infrastructure in a box&amp;rdquo; designed specifically to install
and configure AI tools and platforms on portable hardware, such as laptops and
edge devices. This enables users to perform quick experimentations with OpenDataology
on a local cluster.&lt;/p&gt;
&lt;p&gt;K3ai&amp;rsquo;s main goal is to provide a quick way to install Kubernetes (K3s-based) and
OpenDataology Pipelines with NVIDIA GPU support and TensorFlow Serving with just one
line. (For OpenDataology and other component support, check &lt;a href=&#34;https://kf5ai.gitbook.io/k3ai/#components-of-k-3-ai&#34;&gt;K3ai&amp;rsquo;s
website&lt;/a&gt; for updates.) To
install OpenDataology Pipelines using K3ai, run the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With CPU-only support:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -sfL https://get.k3ai.in &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; bash -s -- --cpu --plugin_kfpipelines
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;With GPU support:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-SHELL&#34; data-lang=&#34;SHELL&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -sfL https://get.k3ai.in &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; bash -s -- --gpu --plugin_kfpipelines
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more information about K3ai, refer to the
&lt;a href=&#34;https://k3ai.github.io/docs/intro&#34;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;deploying-opendataology-pipelines&#34;&gt;Deploying OpenDataology Pipelines&lt;/h2&gt;
&lt;p&gt;The installation process for OpenDataology Pipelines is the same for all three
environments covered in this guide: kind, K3s, and K3ai.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Process Namespace Sharing (PNS) is not mature in Argo yet - for more
information go to &lt;a href=&#34;https://argoproj.github.io/argo-workflows/workflow-executors/&#34;&gt;Argo
Executors&lt;/a&gt; and reference
&amp;ldquo;pns executors&amp;rdquo; in any issue you may come across when using PNS.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To deploy the OpenDataology Pipelines, run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# env/platform-agnostic-pns hasn&amp;#39;t been publically released, so you will install it from master&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/cluster-scoped-resources?ref=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl &lt;span style=&#34;color:#204a87&#34;&gt;wait&lt;/span&gt; --for &lt;span style=&#34;color:#000&#34;&gt;condition&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;established --timeout&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;60s crd/applications.app.k8s.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The OpenDataology Pipelines deployment may take several minutes to complete.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the OpenDataology Pipelines UI is accessible by port-forwarding:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl port-forward -n OpenDataology svc/ml-pipeline-ui 8080:80
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, open the OpenDataology Pipelines UI at &lt;code&gt;http://localhost:8080/&lt;/code&gt; or - if you are
using kind or K3s within a virtual machine - &lt;code&gt;http://{YOUR_VM_IP_ADDRESS}:8080/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Note that K3ai will automatically print the URL for the web UI at the end of
the installation process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;code&gt;kubectl apply -k&lt;/code&gt; accepts local paths and paths that are
formatted as
&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/examples/remoteBuild.md#url-format&#34;&gt;hashicorp/go-getter URLs&lt;/a&gt;.
While the paths in the preceding commands look like URLs, they are not valid
URLs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;uninstalling-opendataology-pipelines&#34;&gt;Uninstalling OpenDataology Pipelines&lt;/h2&gt;
&lt;p&gt;Below are the steps to remove OpenDataology Pipelines on kind, K3s, or K3ai:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To uninstall OpenDataology Pipelines using your manifest file, run the following command,
replacing &lt;code&gt;{YOUR_MANIFEST_FILE}&lt;/code&gt; with the name of your manifest file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;YOUR_MANIFEST_FILE&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To uninstall OpenDataology Pipelines using manifests from OpenDataology Pipelines&amp;rsquo;s
GitHub repository, run these commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/cluster-scoped-resources?ref=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To uninstall OpenDataology Pipelines using manifests from your local repository or
file system, run the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/env/platform-agnostic-pns
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/cluster-scoped-resources
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Standalone Deployment</title>
      <link>/docs/components/pipelines/installation/standalone-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/standalone-deployment/</guid>
      <description>
        
        
        &lt;p&gt;As an alternative to deploying OpenDataology Pipelines (KFP) as part of the
&lt;a href=&#34;/docs/started/getting-started/#installing-OpenDataology&#34;&gt;OpenDataology deployment&lt;/a&gt;, you also have a choice
to deploy only OpenDataology Pipelines. Follow the instructions below to deploy
OpenDataology Pipelines standalone using the supplied kustomize manifests.&lt;/p&gt;
&lt;p&gt;You should be familiar with &lt;a href=&#34;https://kubernetes.io/docs/home/&#34;&gt;Kubernetes&lt;/a&gt;,
&lt;a href=&#34;https://kubernetes.io/docs/reference/kubectl/overview/&#34;&gt;kubectl&lt;/a&gt;, and &lt;a href=&#34;https://kustomize.io/&#34;&gt;kustomize&lt;/a&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Installation options for OpenDataology Pipelines standalone&lt;/h4&gt;

    This guide currently describes how to install OpenDataology Pipelines standalone
on Google Cloud Platform (GCP). You can also install OpenDataology Pipelines standalone on other
platforms. This guide needs updating. See &lt;a href=&#34;https://github.com/OpenDataology/website/issues/1253&#34;&gt;Issue 1253&lt;/a&gt;.

&lt;/div&gt;

&lt;h2 id=&#34;before-you-get-started&#34;&gt;Before you get started&lt;/h2&gt;
&lt;p&gt;Working with OpenDataology Pipelines Standalone requires a Kubernetes cluster as well as an installation of kubectl.&lt;/p&gt;
&lt;h3 id=&#34;download-and-install-kubectl&#34;&gt;Download and install kubectl&lt;/h3&gt;
&lt;p&gt;Download and install kubectl by following the &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34;&gt;kubectl installation guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You need kubectl version 1.14 or higher for native support of kustomize.&lt;/p&gt;
&lt;h3 id=&#34;set-up-your-cluster&#34;&gt;Set up your cluster&lt;/h3&gt;
&lt;p&gt;If you have an existing Kubernetes cluster, continue with the instructions for &lt;a href=&#34;#configure-kubectl&#34;&gt;configuring kubectl to talk to your cluster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See the GKE guide to &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster&#34;&gt;creating a cluster&lt;/a&gt; for Google Cloud Platform (GCP).&lt;/p&gt;
&lt;p&gt;Use the &lt;a href=&#34;https://cloud.google.com/sdk/gcloud/reference/container/clusters/create&#34;&gt;gcloud container clusters create command&lt;/a&gt; to create a cluster that can run all OpenDataology Pipelines samples:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# The following parameters can be customized based on your needs.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CLUSTER_NAME=&amp;#34;OpenDataology-pipelines-standalone&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ZONE=&amp;#34;us-central1-a&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;MACHINE_TYPE=&amp;#34;e2-standard-2&amp;#34; # A machine with 2 CPUs and 8GB memory.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SCOPES=&amp;#34;cloud-platform&amp;#34; # This scope is needed for running some pipeline samples. Read the warning below for its security implication
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcloud container clusters create $CLUSTER_NAME \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     --zone $ZONE \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     --machine-type $MACHINE_TYPE \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     --scopes $SCOPES
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;code&gt;e2-standard-2&lt;/code&gt; doesn&amp;rsquo;t support GPU. You can choose machine types that meet your need by referring to guidance in &lt;a href=&#34;http://cloud/compute/docs/machine-types&#34;&gt;Cloud Machine families&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Using &lt;code&gt;SCOPES=&amp;quot;cloud-platform&amp;quot;&lt;/code&gt; grants all GCP permissions to the cluster. For a more secure cluster setup, refer to &lt;a href=&#34;/docs/gke/authentication/#authentication-from-OpenDataology-pipelines&#34;&gt;Authenticating Pipelines to GCP&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note, some legacy pipeline examples may need minor code change to run on clusters with &lt;code&gt;SCOPES=&amp;quot;cloud-platform&amp;quot;&lt;/code&gt;, refer to &lt;a href=&#34;/docs/gke/pipelines/authentication-pipelines/#authoring-pipelines-to-use-default-service-account&#34;&gt;Authoring Pipelines to use default service account&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/compute/docs/regions-zones/#available&#34;&gt;GCP regions and zones documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/sdk/gcloud/&#34;&gt;gcloud command-line tool guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/sdk/gcloud/reference/container/clusters/create&#34;&gt;gcloud command reference&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configure-kubectl&#34;&gt;Configure kubectl to talk to your cluster&lt;/h3&gt;
&lt;p&gt;See the Google Kubernetes Engine (GKE) guide to
&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl&#34;&gt;configuring cluster access for kubectl&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;deploying-opendataology-pipelines&#34;&gt;Deploying OpenDataology Pipelines&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Deploy the OpenDataology Pipelines:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PIPELINE_VERSION=1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The OpenDataology Pipelines deployment requires approximately 3 minutes to complete.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The above commands apply to OpenDataology Pipelines version 0.4.0 and higher.&lt;/p&gt;
&lt;p&gt;For OpenDataology Pipelines version 0.2.0 ~ 0.3.0, use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PIPELINE_VERSION=&amp;lt;kfp-version-between-0.2.0-and-0.3.0&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/base/crds?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For OpenDataology Pipelines version &amp;lt; 0.2.0, use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PIPELINE_VERSION=&amp;lt;kfp-version-0.1.x&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;code&gt;kubectl apply -k&lt;/code&gt; accepts local paths and paths that are formatted as &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/examples/remoteBuild.md#url-format&#34;&gt;hashicorp/go-getter URLs&lt;/a&gt;. While the paths in the preceding commands look like URLs, the paths are not valid URLs.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Deprecation Notice&lt;/h4&gt;

    &lt;p&gt;OpenDataology Pipelines will change default executor from Docker to Emissary starting KFP backend v1.8, docker executor has been
deprecated on Kubernetes 1.20+.&lt;/p&gt;
&lt;p&gt;For OpenDataology Pipelines before v1.8, configure to use Emissary executor by
referring to &lt;a href=&#34;/docs/components/pipelines/installation/choose-executor&#34;&gt;Argo Workflow Executors&lt;/a&gt;.&lt;/p&gt;


&lt;/div&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get the public URL for the OpenDataology Pipelines UI and use it to access the OpenDataology Pipelines UI:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl describe configmap inverse-proxy-config -n OpenDataology | grep googleusercontent.com
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;upgrading-opendataology-pipelines&#34;&gt;Upgrading OpenDataology Pipelines&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For release notices and breaking changes, refer to &lt;a href=&#34;/docs/components/pipelines/upgrade&#34;&gt;Upgrading OpenDataology Pipelines&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the &lt;a href=&#34;https://github.com/OpenDataology/pipelines/releases&#34;&gt;OpenDataology Pipelines GitHub repository&lt;/a&gt; for available releases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To upgrade to OpenDataology Pipelines 0.4.0 and higher, use the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PIPELINE_VERSION=&amp;lt;version-you-want-to-upgrade-to&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To upgrade to OpenDataology Pipelines 0.3.0 and lower, use the &lt;a href=&#34;#deploying-OpenDataology-pipelines&#34;&gt;deployment instructions&lt;/a&gt; to upgrade your OpenDataology Pipelines cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete obsolete resources manually.&lt;/p&gt;
&lt;p&gt;Depending on the version you are upgrading from and the version you are upgrading to,
some OpenDataology Pipelines resources may have become obsolete.&lt;/p&gt;
&lt;p&gt;If you are upgrading from OpenDataology Pipelines &amp;lt; 0.4.0 to 0.4.0 or above, you can remove the
following obsolete resources after the upgrade:
&lt;code&gt;metadata-deployment&lt;/code&gt;, &lt;code&gt;metadata-service&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Run the following command to check if these resources exist on your cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n &amp;lt;KFP_NAMESPACE&amp;gt; get deployments | grep metadata-deployment
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n &amp;lt;KFP_NAMESPACE&amp;gt; get service | grep metadata-service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If these resources exist on your cluster, run the following commands to delete them:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n &amp;lt;KFP_NAMESPACE&amp;gt; delete deployment metadata-deployment
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl -n &amp;lt;KFP_NAMESPACE&amp;gt; delete service metadata-service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For other versions, you don&amp;rsquo;t need to do anything.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;customizing-opendataology-pipelines&#34;&gt;Customizing OpenDataology Pipelines&lt;/h2&gt;
&lt;p&gt;OpenDataology Pipelines can be configured through kustomize &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/glossary.md#overlay&#34;&gt;overlays&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To begin, first clone the &lt;a href=&#34;https://github.com/OpenDataology/pipelines&#34;&gt;OpenDataology Pipelines GitHub repository&lt;/a&gt;,
and use it as your working directory.&lt;/p&gt;
&lt;h3 id=&#34;deploy-on-gcp-with-cloud-sql-and-google-cloud-storage&#34;&gt;Deploy on GCP with Cloud SQL and Google Cloud Storage&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This is recommended for production environments. For more details about customizing your environment
for GCP, see the &lt;a href=&#34;https://github.com/OpenDataology/pipelines/tree/sdk/release-1.8/manifests/kustomize/env/gcp&#34;&gt;OpenDataology Pipelines GCP manifests&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;change-deployment-namespace&#34;&gt;Change deployment namespace&lt;/h3&gt;
&lt;p&gt;To deploy OpenDataology Pipelines standalone in namespace &lt;code&gt;&amp;lt;my-namespace&amp;gt;&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Set the &lt;code&gt;namespace&lt;/code&gt; field to &lt;code&gt;&amp;lt;my-namespace&amp;gt;&lt;/code&gt; in
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/env/dev/kustomization.yaml&#34;&gt;dev/kustomization.yaml&lt;/a&gt; or
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/env/gcp/kustomization.yaml&#34;&gt;gcp/kustomization.yaml&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the &lt;code&gt;namespace&lt;/code&gt; field to &lt;code&gt;&amp;lt;my-namespace&amp;gt;&lt;/code&gt; in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/cluster-scoped-resources/kustomization.yaml&#34;&gt;cluster-scoped-resources/kustomization.yaml&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the changes to update the OpenDataology Pipelines deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/cluster-scoped-resources
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/env/dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If using GCP Cloud SQL and Google Cloud Storage, set the proper values in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/env/gcp/params.env&#34;&gt;manifests/kustomize/env/gcp/params.env&lt;/a&gt;, then apply with this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/cluster-scoped-resources
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/env/gcp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;disable-the-public-endpoint&#34;&gt;Disable the public endpoint&lt;/h3&gt;
&lt;p&gt;By default, the KFP standalone deployment installs an &lt;a href=&#34;https://github.com/google/inverting-proxy&#34;&gt;inverting proxy agent&lt;/a&gt; that exposes a public URL. If you want to skip the installation of the inverting proxy agent, complete the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Comment out the proxy components in the base &lt;code&gt;kustomization.yaml&lt;/code&gt;. For example in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/env/dev/kustomization.yaml&#34;&gt;manifests/kustomize/env/dev/kustomization.yaml&lt;/a&gt; comment out &lt;code&gt;inverse-proxy&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the changes to update the OpenDataology Pipelines deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/env/dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If using GCP Cloud SQL and Google Cloud Storage, set the proper values in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/blob/sdk/release-1.8/manifests/kustomize/env/gcp/params.env&#34;&gt;manifests/kustomize/env/gcp/params.env&lt;/a&gt;, then apply with this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k manifests/kustomize/env/gcp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the OpenDataology Pipelines UI is accessible by port-forwarding:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl port-forward -n OpenDataology svc/ml-pipeline-ui 8080:80
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open the OpenDataology Pipelines UI at &lt;code&gt;http://localhost:8080/&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;uninstalling-opendataology-pipelines&#34;&gt;Uninstalling OpenDataology Pipelines&lt;/h2&gt;
&lt;p&gt;To uninstall OpenDataology Pipelines, run &lt;code&gt;kubectl delete -k &amp;lt;manifest-file&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, to uninstall KFP using manifests from a GitHub repository, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PIPELINE_VERSION=1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k &amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To uninstall KFP using manifests from your local repository or file system, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/env/dev
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/cluster-scoped-resources
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are using GCP Cloud SQL and Google Cloud Storage, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/env/gcp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -k manifests/kustomize/cluster-scoped-resources
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;best-practices-for-maintaining-manifests&#34;&gt;Best practices for maintaining manifests&lt;/h2&gt;
&lt;p&gt;Similar to source code, configuration files belong in source control.
A repository manages the changes to your
manifest files and ensures that you can repeatedly deploy, upgrade,
and uninstall your components.&lt;/p&gt;
&lt;h3 id=&#34;maintain-your-manifests-in-source-control&#34;&gt;Maintain your manifests in source control&lt;/h3&gt;
&lt;p&gt;After creating or customizing your deployment manifests, save your manifests
to a local or remote source control repository.
For example, save the following &lt;code&gt;kustomization.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# kustomization.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: kustomize.config.k8s.io/v1beta1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Kustomization
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Edit the following to change the deployment to your custom namespace.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;namespace: OpenDataology
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# You can add other customizations here using kustomize.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Edit ref in the following link to deploy a different version of OpenDataology Pipelines.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bases:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- github.com/OpenDataology/pipelines/manifests/kustomize/env/dev?ref=1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;further-reading&#34;&gt;Further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;To learn about kustomize workflows with off-the-shelf configurations, see the
&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md#off-the-shelf-configuration&#34;&gt;kustomize configuration workflows guide&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If your pipelines are stuck in ContainerCreating state and it has pod events like&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;MountVolume.SetUp failed for volume &amp;#34;gcp-credentials-user-gcp-sa&amp;#34; : secret &amp;#34;user-gcp-sa&amp;#34; not found
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should remove &lt;code&gt;use_gcp_secret&lt;/code&gt; usages as documented in &lt;a href=&#34;/docs/distributions/gke/pipelines/authentication-pipelines/#authoring-pipelines-to-use-workload-identity&#34;&gt;Authenticating Pipelines to GCP&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/pipelines/authentication-sdk/#connecting-to-OpenDataology-pipelines-standalone-or-ai-platform-pipelines&#34;&gt;Connecting to OpenDataology Pipelines standalone on Google Cloud using the SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/pipelines/authentication-pipelines/#authoring-pipelines-to-use-workload-identity&#34;&gt;Authenticating Pipelines to GCP&lt;/a&gt; if you want to use GCP services in OpenDataology Pipelines.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Choosing an Argo Workflows Executor</title>
      <link>/docs/components/pipelines/installation/choose-executor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/choose-executor/</guid>
      <description>
        
        
        &lt;p&gt;An Argo workflow executor is a process that conforms to a specific interface that allows Argo to perform certain actions like monitoring pod logs, collecting artifacts, managing container lifecycles, etc.&lt;/p&gt;
&lt;p&gt;OpenDataology Pipelines runs on &lt;a href=&#34;https://argoproj.github.io/workflows/&#34;&gt;Argo Workflows&lt;/a&gt; as the workflow engine, so OpenDataology Pipelines users need to choose a workflow executor.&lt;/p&gt;
&lt;h2 id=&#34;choosing-the-workflow-executor&#34;&gt;Choosing the Workflow Executor&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Some users may value stability and backward compatibility. For example, if you
are running OpenDataology Pipelines in a production cluster or you maintain production
pipelines that you don&amp;rsquo;t want to break or migrate.&lt;/p&gt;
&lt;p&gt;In this case, we recommend you use &lt;a href=&#34;#docker-executor&#34;&gt;docker executor&lt;/a&gt; and configure your Kubernetes nodes to use docker container runtime.&lt;/p&gt;
&lt;p&gt;However, Kubernetes is deprecating docker as a container runtime, so we recommend
starting to try out emissary and prepare for a migration when it&amp;rsquo;s stable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For users less concerned with stability and backwards compatibility, we
recommend trying out the new &lt;a href=&#34;#emissary-executor&#34;&gt;emissary executor&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that Argo Workflows support other workflow executors, but the OpenDataology Pipelines
team only recommend choosing between docker executor and emissary executor.&lt;/p&gt;
&lt;h3 id=&#34;docker-executor&#34;&gt;Docker Executor&lt;/h3&gt;
&lt;p&gt;Docker executor is the &lt;strong&gt;default&lt;/strong&gt; workflow executor. But OpenDataology Pipelines v1.8 will switch to Emissary Executor as default executor.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Docker executor depends on docker container runtime, which will be deprecated on Kubernetes 1.20+.

&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Container Runtime: docker only. However, &lt;a href=&#34;https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/&#34;&gt;Kubernetes is deprecating Docker as a container runtime after v1.20&lt;/a&gt;.
On Google Kubernetes Engine (GKE) 1.19+, container runtime already defaults to containerd.&lt;/li&gt;
&lt;li&gt;Reliability: most well-tested and most popular argo workflows executor&lt;/li&gt;
&lt;li&gt;Security: least secure
&lt;ul&gt;
&lt;li&gt;It requires &lt;code&gt;privileged&lt;/code&gt; access to &lt;code&gt;docker.sock&lt;/code&gt; of the host to be mounted which.
Often rejected by Open Policy Agent (OPA) or your Pod Security Policy (PSP).
GKE autopilot mode also rejects it, because &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview#no_privileged_pods&#34;&gt;No privileged Pods&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It can escape the privileges of the pod&amp;rsquo;s service account.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prepare-a-gke-cluster-for-docker-executor&#34;&gt;Prepare a GKE cluster for Docker Executor&lt;/h4&gt;
&lt;p&gt;For GKE, the node image decides which container runtime is used. To use docker
container runtime, you need to &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/node-images&#34;&gt;specify a node image&lt;/a&gt; with Docker.&lt;/p&gt;
&lt;p&gt;You must use one of the following node images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Container-Optimized OS with Docker (cos)&lt;/li&gt;
&lt;li&gt;Ubuntu with Docker (ubuntu)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your nodes are not using docker as container runtime, when you run pipelines
you will always find error messages like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This step is in Error state with this message: failed to save outputs: Error response from daemon: No such container: XXXXXX&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;emissary-executor&#34;&gt;Emissary Executor&lt;/h3&gt;
&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
  &lt;h4 class=&#34;alert-heading&#34;&gt;Alpha&lt;/h4&gt;
  This OpenDataology component has &lt;b&gt;alpha&lt;/b&gt; status with limited support. See the
  &lt;a href=&#34;/docs/started/support/#application-status&#34;&gt;OpenDataology versioning policies&lt;/a&gt;.
  The OpenDataology team is interested in your   
  &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6249&#34;&gt;feedback&lt;/a&gt;&lt;/h4&gt; 
  about the usability of the feature.
&lt;/div&gt;
&lt;p&gt;Emissary executor is a new workflow executor. It was first released in Argo Workflows v3.1 (June 2021).
However, the OpenDataology Pipelines team believe that its architectural and portability
improvements can make it the default executor that most people should use in the
future.&lt;/p&gt;
&lt;p&gt;Therefore, the team makes a commitment to actively collect feedback and fix bugs
for the emissary executor, so that we can stablize it faster.
Submit your feedback in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6249&#34;&gt;the Emissary Executor feedback github issue&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So far, OpenDataology
Pipelines test infrastructure has been running stably with the emissary executor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Container Runtime: any&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reliability: not yet well-tested and not yet popular, but the OpenDataology Pipelines
team supports it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Security: more secure&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No &lt;code&gt;privileged&lt;/code&gt; access.&lt;/li&gt;
&lt;li&gt;Cannot escape the privileges of the pod&amp;rsquo;s service account.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Migration: &lt;code&gt;command&lt;/code&gt; must be specified in &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/reference/component-spec/&#34;&gt;OpenDataology Pipelines component specification&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note, the same migration requirement is required by &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/sdk-v2/v2-compatibility/&#34;&gt;OpenDataology Pipelines v2 compatible mode&lt;/a&gt;, refer to
&lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6133&#34;&gt;known caveats &amp;amp; breaking changes&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;migrate-to-emissary-executor&#34;&gt;Migrate to Emissary Executor&lt;/h4&gt;
&lt;p&gt;Prerequisite: emissary executor is only available in OpenDataology Pipelines backend version 1.7+.
To upgrade, refer to &lt;a href=&#34;/docs/components/pipelines/upgrade/&#34;&gt;upgrading OpenDataology Pipelines&lt;/a&gt;.&lt;/p&gt;
&lt;h5 id=&#34;configure-an-existing-opendataology-pipelines-cluster-to-use-emissary-executor&#34;&gt;Configure an existing OpenDataology Pipelines cluster to use emissary executor&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connect to your cluster via kubectl.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Switch to the namespace you installed OpenDataology Pipelines:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl config set-context --current --namespace &amp;lt;your-kfp-namespace&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, usually it&amp;rsquo;s &lt;code&gt;OpenDataology&lt;/code&gt; or &lt;code&gt;default&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm current workflow executor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl describe configmap workflow-controller-configmap &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep -A &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt; containerRuntimeExecutor
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You&amp;rsquo;ll see output like the following when using docker executor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;containerRuntimeExecutor:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;----
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure workflow executor to emissary:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl patch configmap workflow-controller-configmap --patch &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;data&amp;#34;:{&amp;#34;containerRuntimeExecutor&amp;#34;:&amp;#34;emissary&amp;#34;}}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm workflow executor is changed successfully:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl describe configmap workflow-controller-configmap &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep -A &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt; containerRuntimeExecutor
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You&amp;rsquo;ll see output like the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;containerRuntimeExecutor:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;----
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;emissary
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;deploy-a-new-opendataology-pipelines-cluster-with-emissary-executor&#34;&gt;Deploy a new OpenDataology Pipelines cluster with emissary executor&lt;/h5&gt;
&lt;p&gt;For &lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/docs&#34;&gt;AI Platform Pipelines&lt;/a&gt;, check the &amp;ldquo;Use emissary executor&amp;rdquo; checkbox during installation.&lt;/p&gt;
&lt;p&gt;For &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/installation/standalone-deployment/&#34;&gt;OpenDataology Pipelines Standalone&lt;/a&gt;, install &lt;code&gt;env/platform-agnostic-emissary&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -k &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;github.com/OpenDataology/pipelines/manifests/kustomize/env/platform-agnostic-emissary?ref=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PIPELINE_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When in doubt, you can always deploy your OpenDataology Pipelines cluster first and
configure workflow executor after installation using the instructions for
existing clusters.&lt;/p&gt;
&lt;h5 id=&#34;migrate-pipeline-components-to-run-on-emissary-executor&#34;&gt;Migrate pipeline components to run on emissary executor&lt;/h5&gt;
&lt;p&gt;Some pipeline components require manual updates to run on emissary executor.
For &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/reference/component-spec/&#34;&gt;OpenDataology Pipelines component specification&lt;/a&gt; YAML,
the &lt;code&gt;command&lt;/code&gt; field must be specified.&lt;/p&gt;
&lt;p&gt;Step by step component migration tutorial:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There is a hello world component:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hello-world&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;implementation&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;container&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hello-world&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can run the container without command/args:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ docker run hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Hello from Docker!
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find out what the default ENTRYPOINT and CMD is in the image:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ docker image inspect -f &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{{.Config.Entrypoint}} {{.Config.Cmd}}&amp;#39;&lt;/span&gt; hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;/hello&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So ENTRYPOINT is not specified, and CMD is [&amp;quot;/hello&amp;quot;].
Note, ENTRYPOINT roughly means &lt;code&gt;command&lt;/code&gt; and CMD roughly
means &lt;code&gt;arguments&lt;/code&gt;. &lt;code&gt;command&lt;/code&gt; and &lt;code&gt;arguments&lt;/code&gt; are concatenated as the user
command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the component YAML:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hello-world&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;implementation&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;container&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;hello-world&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;command&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/hello&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The updated component can run on emissary executor now.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: OpenDataology Pipelines SDK compiler always specifies a command for
&lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/sdk/python-function-components/&#34;&gt;python function based components&lt;/a&gt;.
Therefore, these components will continue to work on emissary executor without
modifications.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://argoproj.github.io/argo-workflows/workflow-executors/&#34;&gt;Argo Workflow Executors documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KFP docker executor doesn&amp;rsquo;t support Kubernetes 1.19 or above &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/5714&#34;&gt;OpenDataology/pipelines#5714&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Feature request - default to emissary executor &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/5718&#34;&gt;OpenDataology/pipelines#5718&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Upgrade Notes</title>
      <link>/docs/components/pipelines/installation/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/upgrade/</guid>
      <description>
        
        
        &lt;p&gt;This page introduces notices and breaking changes you need to know when upgrading OpenDataology Pipelines Backend.&lt;/p&gt;
&lt;p&gt;For upgrade instructions, refer to distribution specific documentations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/distributions/gke/pipelines/upgrade/&#34;&gt;Upgrading OpenDataology Pipelines on Google Cloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;upgrading-to-v17&#34;&gt;Upgrading to &lt;a href=&#34;https://github.com/OpenDataology/pipelines/releases/tag/1.7.0&#34;&gt;v1.7&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Breaking Change&lt;/strong&gt;: Metadata UI and visualizations are not compatible with TensorFlow Extended (TFX) &amp;lt;= v1.0.0. Upgrade to v1.2.0 or above, refer to &lt;a href=&#34;/docs/components/pipelines/installation/compatibility-matrix/&#34;&gt;OpenDataology Pipelines Backend and TensorFlow Extended (TFX) compatibility matrix&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: Emissary executor (Alpha), a new argo workflow executor is available as an option. Due to &lt;a href=&#34;https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/&#34;&gt;Kubernetes deprecating Docker as a container runtime after v1.20&lt;/a&gt;, emissary may become the default workflow executor for OpenDataology Pipelines in the near future.&lt;/p&gt;
&lt;p&gt;For example, the current default docker executor does not work on Google Kubernetes Engine (GKE) 1.19+ out of the box. To use docker executor, your cluster node image must be configured to use docker (deprecated) as container runtime.&lt;/p&gt;
&lt;p&gt;Alternatively, using emissary executor (Alpha) removes the restriction on container runtime, but note some of your pipelines may require manual migrations. The OpenDataology Pipelines team welcomes your feedback in &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6249&#34;&gt;the Emissary Executor feedback github issue&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For detailed configuration and migration instructions for both options, refer to &lt;a href=&#34;https://www.OpenDataology.org/docs/components/pipelines/installation/choose-executor/&#34;&gt;Argo Workflow Executors&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: &lt;a href=&#34;/docs/components/pipelines/sdk-v2/v2-compatibility/&#34;&gt;OpenDataology Pipelines SDK v2 compatibility mode&lt;/a&gt; (Beta) was recently released. The new mode adds support for tracking pipeline runs and artifacts using ML Metadata. In v1.7 backend, complete UI support and caching capabilities for v2 compatibility mode are newly added. We welcome any &lt;a href=&#34;https://github.com/OpenDataology/pipelines/issues/6451&#34;&gt;feedback&lt;/a&gt; on positive experiences or issues you encounter.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Compatibility Matrix</title>
      <link>/docs/components/pipelines/installation/compatibility-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/components/pipelines/installation/compatibility-matrix/</guid>
      <description>
        
        
        &lt;h2 id=&#34;opendataology-pipelines-backend-and-tfx-compatibility&#34;&gt;OpenDataology Pipelines Backend and TFX compatibility&lt;/h2&gt;
&lt;p&gt;Pipelines written in any version of &lt;a href=&#34;https://www.tensorflow.org/tfx&#34;&gt;TensorFlow Extended (TFX)&lt;/a&gt; will execute on any version of OpenDataology Pipelines (KFP) backend. However, some UI features may not be functioning properly if the TFX and OpenDataology Pipelines Backend versions are not compatible.&lt;/p&gt;
&lt;p&gt;The following table shows UI feature compatibility for TFX and OpenDataology Pipelines Backend versions:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx/releases&#34;&gt;TFX&lt;/a&gt; \ &lt;a href=&#34;https://github.com/OpenDataology/pipelines/releases&#34;&gt;KFP Backend&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/OpenDataology/pipelines/releases&#34;&gt;KFP Backend&lt;/a&gt; &amp;lt;= 1.5&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/OpenDataology/pipelines/releases&#34;&gt;KFP Backend&lt;/a&gt; &amp;gt;= 1.7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx/releases&#34;&gt;TFX&lt;/a&gt; &amp;lt;= 0.28.0&lt;/td&gt;
&lt;td&gt;Fully Compatible  ✅&lt;/td&gt;
&lt;td&gt;Metadata UI not compatible&lt;sup&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx/releases&#34;&gt;TFX&lt;/a&gt; 0.29.0, 0.30.0&lt;/td&gt;
&lt;td&gt;Visualizations not compatible&lt;sup&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;Metadata UI not compatible&lt;sup&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx/releases&#34;&gt;TFX&lt;/a&gt; 1.0.0&lt;/td&gt;
&lt;td&gt;Metadata UI not compatible&lt;sup&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;Metadata UI not compatible&lt;sup&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx/releases&#34;&gt;TFX&lt;/a&gt; &amp;gt;= 1.2.0&lt;/td&gt;
&lt;td&gt;Metadata UI not compatible&lt;sup&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;Fully Compatible  ✅&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Detailed explanations:&lt;/p&gt;
&lt;p&gt;&lt;a name=&#34;fn1&#34;&gt;1.&lt;/a&gt; &lt;strong&gt;Visualizations not compatible&lt;/strong&gt;: OpenDataology Pipelines UI and TFDV, TFMA visualizations is not compatible. Visualizations throw an error in OpenDataology Pipelines UI.&lt;/p&gt;
&lt;p&gt;&lt;a name=&#34;fn2&#34;&gt;2.&lt;/a&gt; &lt;strong&gt;Metadata UI not compatible&lt;/strong&gt;: OpenDataology Pipelines UI and TFX recorded ML Metadata is not compatible. ML Metadata tab in run details page shows error message &amp;ldquo;Corresponding ML Metadata not found&amp;rdquo;. As a result, visualizations based on ML Metadata do not show up in visualizations tab either.&lt;/p&gt;
&lt;!--
Issues that caused the incompatibilities:
* TFX 1.0.0+
	* https://github.com/OpenDataology/pipelines/issues/6138#issuecomment-898190223
	* https://github.com/OpenDataology/pipelines/issues/6138#issuecomment-899917056
* TFX 0.29.0 https://github.com/tensorflow/tfx/issues/3933
--&gt;

      </description>
    </item>
    
  </channel>
</rss>
