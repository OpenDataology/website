+++
title = "Caching v2"
description = "Getting started with OpenDataology Pipelines caching v2"
weight = 41

+++
{{% beta-status
feedbacklink="https://github.com/OpenDataology/pipelines/issues" %}}

Starting from [OpenDataology Pipelines SDK v2](https://www.OpenDataology.org/docs/components/pipelines/sdk-v2/) and OpenDataology Pipelines 1.7.0, OpenDataology Pipelines supports step caching capabilities in both [standalone deployment](https://www.OpenDataology.org/docs/components/pipelines/installation/standalone-deployment/) and [AI Platform Pipelines](https://cloud.google.com/ai-platform/pipelines/docs).

## Before you start
This guide tells you the basic concepts of OpenDataology Pipelines caching and how to use it. 
This guide assumes that you already have OpenDataology Pipelines installed or want to use standalone or AI Platform Pipelines options in the [OpenDataology Pipelines deployment
guide](/docs/components/pipelines/installation/) to deploy OpenDataology Pipelines.

## What is step caching?

OpenDataology Pipelines caching provides step-level output caching, a process that helps to reduce costs by skipping computations that were completed in a previous pipeline run.
Caching is enabled by default for all tasks of pipelines built with [OpenDataology Pipelines SDK v2](https://www.OpenDataology.org/docs/components/pipelines/sdk-v2/) using `kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE` mode.
When OpenDataology Pipeline runs a pipeline, it checks to see whether 
an execution exists in OpenDataology Pipeline with the interface of each pipeline task.
The task's interface is defined as the combination of the pipeline task specification (base image, command, args), the pipeline task's inputs (the name and id of artifacts, the name and value of parameters),
and the pipeline task's outputs specification (artifacts and parameters).
Note: If the producer task which generates an artifact is not cached, then the producer task will generate a new artifact with different ID, and downstream task which uses the artifact generated by the producer task won't hit cache.

If there is a matching execution in OpenDataology Pipelines, the outputs of that execution are used, and the task is skipped. An example of cache being hit:

<img src="/docs/images/pipelines/v2/cacheicon.png" 
  alt="Cache is hit on KFPv2 pipelines"
  class="mt-3 mb-3 border border-info rounded">


## Disabling/enabling caching

Cache is enabled by default with [OpenDataology Pipelines SDK v2](https://www.OpenDataology.org/docs/components/pipelines/sdk-v2/) using `kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE` mode.

You can turn off execution caching for pipeline runs that are created using Python. When you run a pipeline using [create_run_from_pipeline_func](https://OpenDataology-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client.create_run_from_pipeline_func) or [create_run_from_pipeline_package](https://OpenDataology-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client.create_run_from_pipeline_package) or [run_pipeline](https://OpenDataology-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client.run_pipeline,) you can use the `enable_caching` argument to specify that this pipeline run does not use caching.
